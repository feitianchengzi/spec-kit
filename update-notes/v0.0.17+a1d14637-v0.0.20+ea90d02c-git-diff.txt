diff --git a/.cursor/commands/update-learn.md b/.cursor/commands/update-learn.md
deleted file mode 100644
index 10ccf99..0000000
--- a/.cursor/commands/update-learn.md
+++ /dev/null
@@ -1,17 +0,0 @@
----
-description: 更新学习教程
----
-
-根据提供的客户需求参数，执行以下操作：
-
-1. 从 update-notes 中读取最新的升级文档，以了解升级内容
-   - *-git-diff.txt
-   - *-update-notes.md
-   - git-diff 中提到的文件内容细节
-
-2. 对 @learn-spec-kit/ 的内容进行更新
-   - 先制定具体的计划，再逐个文件进行更新
-   - 不要偏离每篇学习文档本身的设置目的
-   - 确保更新后的学习文档符合当前项目的实际现状
-   - 遵守最小改动原则，不要过度修改，该有的要有，不该有的不要刻意发挥
-   - 注意学习的是 spec-kit 原有文档的内容，不包括自定义添加文档（test-env/、learn-spec-kit/、update-notes/）
\ No newline at end of file
diff --git a/.cursor/commands/update-notes.md b/.cursor/commands/update-notes.md
deleted file mode 100644
index 920bcce..0000000
--- a/.cursor/commands/update-notes.md
+++ /dev/null
@@ -1,78 +0,0 @@
----
-description: 生成 origin/main 更新说明文档
----
-
-根据提供的客户需求参数，执行以下操作：
-
-1. fetch origin/main，获取必要信息，注意版本号以 pyproject.toml 为准
-   - **当前版本号**，**当前CommitID**
-   - **更新版本号**，**更新CommitID**
-
-2. 检查版本号是否有更新，如果和本地版本号一致则停止
-
-3. 定义 **更新内容唯一性标识**，格式为 `v[当前版本号]+[当前CommitID]-v[更新版本号]+[更新CommitID`
-
-4. 使用 `git diff HEAD origin/main` 获取完整代码差异，保存到文件 `update-notes/[更新内容唯一性标识]-git-diff.txt`
-   
-5. 分析 `update-notes/[更新内容唯一性标识]-git-diff.txt` 的内容：
-   - 先找出所有增删改的文件，分析文件的作用
-   - 生成分析报告，为文档生成做准备
-
-6. 基于分析结果，参考模板文件 `update-notes/update-notes-template.md` 生成更新说明文档：
-   - 文档内容使用简体中文
-   - 遵循内容生成最佳实践
-   - 更新说明文档保存到 `update-notes/[更新内容唯一性标识]-update-notes.md` 文件中
-   
-   **内容生成最佳实践**：
-
-   **通用原则**
-   - 用词要准确，注意区分重构和扩展的差异
-   - 功能点罗列不要用"等"，应该完整罗列
-   - 对于关键概念，确保要有必要的、精炼的一句话详情做补充说明
-
-   **更新概览设计**：
-   - 概览中突出最重要的功能改进，避免重复内容
-   - 如果有AI代理或命令系统的变更，则必须包含相关说明
-  
-   **主要内容优化**：
-   - AI代理支持：
-     - 代理要说明具体开发公司、技术特点和用途，不要简单的说"支持""
-     - 新增代理和优化现有代理要分开说明，不能遗漏
-   - 命令系统：
-     - 命令说明虽然只占一行，但要包含重要的技术细节和使用场景，不要过于简洁
-     - 新增命令和优化现有命令要分开说明，不能遗漏
-
-   **总结部分精炼**：
-   - 突出核心记忆点、关键改进、升级建议
-   - 让用户在30秒内抓住所有重点
-
-7. 检查更新说明文档的内容，和完整代码差异做比对
-   - 补充遗漏项
-   - 修复事实性错误
-
-   **验证检查清单**：
-   
-   **数据一致性验证**
-   - 文件数量统计：新增、删除、修改文件数量与 git diff 统计一致
-   - 版本号验证：确认版本号变更准确（如 0.0.4 → 0.0.17）
-   - 关键变更验证：重要功能变更与代码差异内容匹配
-   
-   **内容完整性检查**
-   - 新增功能：所有新增文件都有对应的功能说明
-   - 删除功能：所有删除文件都有对应的移除说明
-   - 修改功能：重要修改都有对应的改进说明
-   - 配置变更：依赖、环境、配置变更都有说明
-   
-   **技术准确性验证**
-   - API变更：函数签名、参数、返回值变更准确描述
-   - 依赖更新：新增、删除、升级的依赖包准确列出
-   - 配置格式：配置文件的格式变更准确说明
-   - 兼容性：破坏性变更和兼容性变更准确分类
-   
-   **用户体验检查**
-   - 升级路径：提供清晰的升级步骤和建议
-   - 影响评估：准确描述对现有用户的影响
-   - 新功能亮点：突出用户最关心的新功能
-   - 问题解决：提供常见问题的解决方案
-
-8. 跟人类做确认，修复反馈问题
diff --git a/.devcontainer/devcontainer.json b/.devcontainer/devcontainer.json
new file mode 100644
index 0000000..caf184c
--- /dev/null
+++ b/.devcontainer/devcontainer.json
@@ -0,0 +1,77 @@
+// For format details, see https://aka.ms/devcontainer.json. For config options, see the
+// README at: https://github.com/devcontainers/templates/tree/main/src/python
+{
+	"name": "SpecKitDevContainer",
+	// Or use a Dockerfile or Docker Compose file. More info: https://containers.dev/guide/dockerfile
+	"image": "mcr.microsoft.com/devcontainers/python:3.13-trixie", // based on Debian "Trixie" (13)
+	"features": {
+		"ghcr.io/devcontainers/features/common-utils:2": {
+			"installZsh": true,
+			"installOhMyZsh": true,
+			"installOhMyZshConfig": true,
+			"upgradePackages": true,
+			"username": "devcontainer",
+			"userUid": "automatic",
+			"userGid": "automatic"
+		},
+		"ghcr.io/devcontainers/features/dotnet:2": {
+			"version": "lts"
+		},
+		"ghcr.io/devcontainers/features/git:1": {
+			"ppa": true,
+			"version": "latest"
+		},
+		"ghcr.io/devcontainers/features/node": {
+			"version": "lts"
+		}
+	},
+
+	// Use 'forwardPorts' to make a list of ports inside the container available locally.
+  "forwardPorts": [
+	8080 // for Spec-Kit documentation site
+  ],
+  "containerUser": "devcontainer",
+  "updateRemoteUserUID": true,
+  "postCreateCommand": "chmod +x ./.devcontainer/post-create.sh && ./.devcontainer/post-create.sh",
+  "postStartCommand": "git config --global --add safe.directory ${containerWorkspaceFolder}",
+  "customizations": {
+    "vscode": {
+      "extensions": [
+		"mhutchie.git-graph",
+		"eamodio.gitlens",
+		"anweber.reveal-button",
+		"chrisdias.promptboost",
+		// Github Copilot
+		"GitHub.copilot",
+		"GitHub.copilot-chat",
+		// Codex
+		"openai.chatgpt",
+		// Kilo Code
+		"kilocode.Kilo-Code",
+		// Roo Code
+		"RooVeterinaryInc.roo-cline",
+		// Amazon Developer Q
+		"AmazonWebServices.amazon-q-vscode",
+		// Claude Code
+		"anthropic.claude-code"
+	],
+      "settings": {
+		"debug.javascript.autoAttachFilter": "disabled", // fix running commands in integrated terminal
+
+		// Specify settings for Github Copilot
+		"git.autofetch": true,
+		"chat.promptFilesRecommendations": {
+			"speckit.constitution": true,
+			"speckit.specify": true,
+			"speckit.plan": true,
+			"speckit.tasks": true,
+			"speckit.implement": true
+		},
+		"chat.tools.terminal.autoApprove": {
+			".specify/scripts/bash/": true,
+			".specify/scripts/powershell/": true
+		}
+      }
+    }
+  }
+}
diff --git a/.devcontainer/post-create.sh b/.devcontainer/post-create.sh
new file mode 100755
index 0000000..9608a28
--- /dev/null
+++ b/.devcontainer/post-create.sh
@@ -0,0 +1,100 @@
+#!/bin/bash
+
+# Exit immediately on error, treat unset variables as an error, and fail if any command in a pipeline fails.
+set -euo pipefail
+
+# Function to run a command and show logs only on error
+run_command() {
+    local command_to_run="$*"
+    local output
+    local exit_code
+    
+    # Capture all output (stdout and stderr)
+    output=$(eval "$command_to_run" 2>&1) || exit_code=$?
+    exit_code=${exit_code:-0}
+    
+    if [ $exit_code -ne 0 ]; then
+        echo -e "\033[0;31m[ERROR] Command failed (Exit Code $exit_code): $command_to_run\033[0m" >&2
+        echo -e "\033[0;31m$output\033[0m" >&2
+        
+        exit $exit_code
+    fi
+}
+
+# Installing CLI-based AI Agents
+
+echo -e "\n🤖 Installing Copilot CLI..."
+run_command "npm install -g @github/copilot@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing Claude CLI..."
+run_command "npm install -g @anthropic-ai/claude-code@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing Codex CLI..."
+run_command "npm install -g @openai/codex@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing Gemini CLI..."
+run_command "npm install -g @google/gemini-cli@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing Augie CLI..."
+run_command "npm install -g @augmentcode/auggie@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing Qwen Code CLI..."
+run_command "npm install -g @qwen-code/qwen-code@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing OpenCode CLI..."
+run_command "npm install -g opencode-ai@latest"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing Amazon Q CLI..."
+# 👉🏾 https://docs.aws.amazon.com/amazonq/latest/qdeveloper-ug/command-line-verify-download.html
+
+run_command "curl --proto '=https' --tlsv1.2 -sSf 'https://desktop-release.q.us-east-1.amazonaws.com/latest/q-x86_64-linux.zip' -o 'q.zip'"
+run_command "curl --proto '=https' --tlsv1.2 -sSf 'https://desktop-release.q.us-east-1.amazonaws.com/latest/q-x86_64-linux.zip.sig' -o 'q.zip.sig'"
+cat > amazonq-public-key.asc << 'EOF'
+-----BEGIN PGP PUBLIC KEY BLOCK-----
+
+mDMEZig60RYJKwYBBAHaRw8BAQdAy/+G05U5/EOA72WlcD4WkYn5SInri8pc4Z6D
+BKNNGOm0JEFtYXpvbiBRIENMSSBUZWFtIDxxLWNsaUBhbWF6b24uY29tPoiZBBMW
+CgBBFiEEmvYEF+gnQskUPgPsUNx6jcJMVmcFAmYoOtECGwMFCQPCZwAFCwkIBwIC
+IgIGFQoJCAsCBBYCAwECHgcCF4AACgkQUNx6jcJMVmef5QD/QWWEGG/cOnbDnp68
+SJXuFkwiNwlH2rPw9ZRIQMnfAS0A/0V6ZsGB4kOylBfc7CNfzRFGtovdBBgHqA6P
+zQ/PNscGuDgEZig60RIKKwYBBAGXVQEFAQEHQC4qleONMBCq3+wJwbZSr0vbuRba
+D1xr4wUPn4Avn4AnAwEIB4h+BBgWCgAmFiEEmvYEF+gnQskUPgPsUNx6jcJMVmcF
+AmYoOtECGwwFCQPCZwAACgkQUNx6jcJMVmchMgEA6l3RveCM0YHAGQaSFMkguoAo
+vK6FgOkDawgP0NPIP2oA/jIAO4gsAntuQgMOsPunEdDeji2t+AhV02+DQIsXZpoB
+=f8yY
+-----END PGP PUBLIC KEY BLOCK-----
+EOF
+run_command "gpg --batch --import amazonq-public-key.asc"
+run_command "gpg --verify q.zip.sig q.zip"
+run_command "unzip -q q.zip"
+run_command "chmod +x ./q/install.sh"
+run_command "./q/install.sh --no-confirm"
+run_command "rm -rf ./q q.zip q.zip.sig amazonq-public-key.asc"
+echo "✅ Done"
+
+echo -e "\n🤖 Installing CodeBuddy CLI..."
+run_command "npm install -g @tencent-ai/codebuddy-code@latest"
+echo "✅ Done"
+
+# Installing UV (Python package manager)
+echo -e "\n🐍 Installing UV - Python Package Manager..."
+run_command "pipx install uv"
+echo "✅ Done"
+
+# Installing DocFx (for documentation site)
+echo -e "\n📚 Installing DocFx..."
+run_command "dotnet tool update -g docfx"
+echo "✅ Done"
+
+echo -e "\n🧹 Cleaning cache..."
+run_command "sudo apt-get autoclean"
+run_command "sudo apt-get clean"
+
+echo "✅ Setup completed. Happy coding! 🚀"
diff --git a/.gitattributes b/.gitattributes
new file mode 100644
index 0000000..6313b56
--- /dev/null
+++ b/.gitattributes
@@ -0,0 +1 @@
+* text=auto eol=lf
diff --git a/.github/CODEOWNERS b/.github/CODEOWNERS
index 27fe556..efb95fc 100644
--- a/.github/CODEOWNERS
+++ b/.github/CODEOWNERS
@@ -1,2 +1,3 @@
 # Global code owner
 * @localden
+
diff --git a/.github/workflows/docs.yml b/.github/workflows/docs.yml
index 92e81a5..b2811b4 100644
--- a/.github/workflows/docs.yml
+++ b/.github/workflows/docs.yml
@@ -65,3 +65,4 @@ jobs:
       - name: Deploy to GitHub Pages
         id: deployment
         uses: actions/deploy-pages@v4
+
diff --git a/.github/workflows/release.yml b/.github/workflows/release.yml
index 0bede83..9ad2087 100644
--- a/.github/workflows/release.yml
+++ b/.github/workflows/release.yml
@@ -57,3 +57,4 @@ jobs:
         run: |
           chmod +x .github/workflows/scripts/update-version.sh
           .github/workflows/scripts/update-version.sh ${{ steps.get_tag.outputs.new_version }}
+
diff --git a/.github/workflows/scripts/check-release-exists.sh b/.github/workflows/scripts/check-release-exists.sh
index 161bf20..88ef174 100644
--- a/.github/workflows/scripts/check-release-exists.sh
+++ b/.github/workflows/scripts/check-release-exists.sh
@@ -18,4 +18,4 @@ if gh release view "$VERSION" >/dev/null 2>&1; then
 else
   echo "exists=false" >> $GITHUB_OUTPUT
   echo "Release $VERSION does not exist, proceeding..."
-fi
\ No newline at end of file
+fi
diff --git a/.github/workflows/scripts/create-github-release.sh b/.github/workflows/scripts/create-github-release.sh
index 0257520..1125f51 100644
--- a/.github/workflows/scripts/create-github-release.sh
+++ b/.github/workflows/scripts/create-github-release.sh
@@ -22,8 +22,8 @@ gh release create "$VERSION" \
   .genreleases/spec-kit-template-claude-ps-"$VERSION".zip \
   .genreleases/spec-kit-template-gemini-sh-"$VERSION".zip \
   .genreleases/spec-kit-template-gemini-ps-"$VERSION".zip \
-  .genreleases/spec-kit-template-cursor-sh-"$VERSION".zip \
-  .genreleases/spec-kit-template-cursor-ps-"$VERSION".zip \
+  .genreleases/spec-kit-template-cursor-agent-sh-"$VERSION".zip \
+  .genreleases/spec-kit-template-cursor-agent-ps-"$VERSION".zip \
   .genreleases/spec-kit-template-opencode-sh-"$VERSION".zip \
   .genreleases/spec-kit-template-opencode-ps-"$VERSION".zip \
   .genreleases/spec-kit-template-qwen-sh-"$VERSION".zip \
@@ -38,5 +38,9 @@ gh release create "$VERSION" \
   .genreleases/spec-kit-template-auggie-ps-"$VERSION".zip \
   .genreleases/spec-kit-template-roo-sh-"$VERSION".zip \
   .genreleases/spec-kit-template-roo-ps-"$VERSION".zip \
+  .genreleases/spec-kit-template-codebuddy-sh-"$VERSION".zip \
+  .genreleases/spec-kit-template-codebuddy-ps-"$VERSION".zip \
+  .genreleases/spec-kit-template-q-sh-"$VERSION".zip \
+  .genreleases/spec-kit-template-q-ps-"$VERSION".zip \
   --title "Spec Kit Templates - $VERSION_NO_V" \
-  --notes-file release_notes.md
\ No newline at end of file
+  --notes-file release_notes.md
diff --git a/.github/workflows/scripts/create-release-packages.sh b/.github/workflows/scripts/create-release-packages.sh
index 1a12e55..5462a14 100644
--- a/.github/workflows/scripts/create-release-packages.sh
+++ b/.github/workflows/scripts/create-release-packages.sh
@@ -6,7 +6,7 @@ set -euo pipefail
 # Usage: .github/workflows/scripts/create-release-packages.sh <version>
 #   Version argument should include leading 'v'.
 #   Optionally set AGENTS and/or SCRIPTS env vars to limit what gets built.
-#     AGENTS  : space or comma separated subset of: claude gemini copilot cursor qwen opencode windsurf codex (default: all)
+#     AGENTS  : space or comma separated subset of: claude gemini copilot cursor-agent qwen opencode windsurf codex (default: all)
 #     SCRIPTS : space or comma separated subset of: sh ps (default: both)
 #   Examples:
 #     AGENTS=claude SCRIPTS=sh $0 v0.2.0
@@ -42,7 +42,7 @@ generate_commands() {
   mkdir -p "$output_dir"
   for template in templates/commands/*.md; do
     [[ -f "$template" ]] || continue
-    local name description script_command body
+    local name description script_command agent_script_command body
     name=$(basename "$template" .md)
     
     # Normalize line endings
@@ -57,13 +57,30 @@ generate_commands() {
       script_command="(Missing script command for $script_variant)"
     fi
     
+    # Extract agent_script command from YAML frontmatter if present
+    agent_script_command=$(printf '%s\n' "$file_content" | awk '
+      /^agent_scripts:$/ { in_agent_scripts=1; next }
+      in_agent_scripts && /^[[:space:]]*'"$script_variant"':[[:space:]]*/ {
+        sub(/^[[:space:]]*'"$script_variant"':[[:space:]]*/, "")
+        print
+        exit
+      }
+      in_agent_scripts && /^[a-zA-Z]/ { in_agent_scripts=0 }
+    ')
+    
     # Replace {SCRIPT} placeholder with the script command
     body=$(printf '%s\n' "$file_content" | sed "s|{SCRIPT}|${script_command}|g")
     
-    # Remove the scripts: section from frontmatter while preserving YAML structure
+    # Replace {AGENT_SCRIPT} placeholder with the agent script command if found
+    if [[ -n $agent_script_command ]]; then
+      body=$(printf '%s\n' "$body" | sed "s|{AGENT_SCRIPT}|${agent_script_command}|g")
+    fi
+    
+    # Remove the scripts: and agent_scripts: sections from frontmatter while preserving YAML structure
     body=$(printf '%s\n' "$body" | awk '
       /^---$/ { print; if (++dash_count == 1) in_frontmatter=1; else in_frontmatter=0; next }
       in_frontmatter && /^scripts:$/ { skip_scripts=1; next }
+      in_frontmatter && /^agent_scripts:$/ { skip_scripts=1; next }
       in_frontmatter && /^[a-zA-Z].*:/ && skip_scripts { skip_scripts=0 }
       in_frontmatter && skip_scripts && /^[[:space:]]/ { next }
       { print }
@@ -74,11 +91,12 @@ generate_commands() {
     
     case $ext in
       toml)
-        { echo "description = \"$description\""; echo; echo "prompt = \"\"\""; echo "$body"; echo "\"\"\""; } > "$output_dir/$name.$ext" ;;
+        body=$(printf '%s\n' "$body" | sed 's/\\/\\\\/g')
+        { echo "description = \"$description\""; echo; echo "prompt = \"\"\""; echo "$body"; echo "\"\"\""; } > "$output_dir/speckit.$name.$ext" ;;
       md)
-        echo "$body" > "$output_dir/$name.$ext" ;;
+        echo "$body" > "$output_dir/speckit.$name.$ext" ;;
       prompt.md)
-        echo "$body" > "$output_dir/$name.$ext" ;;
+        echo "$body" > "$output_dir/speckit.$name.$ext" ;;
     esac
   done
 }
@@ -112,27 +130,10 @@ build_variant() {
     esac
   fi
   
-  [[ -d templates ]] && { mkdir -p "$SPEC_DIR/templates"; find templates -type f -not -path "templates/commands/*" -exec cp --parents {} "$SPEC_DIR"/ \; ; echo "Copied templates -> .specify/templates"; }
-  # Inject variant into plan-template.md within .specify/templates if present
-  local plan_tpl="$base_dir/.specify/templates/plan-template.md"
-  if [[ -f "$plan_tpl" ]]; then
-    plan_norm=$(tr -d '\r' < "$plan_tpl")
-    # Extract script command from YAML frontmatter
-    script_command=$(printf '%s\n' "$plan_norm" | awk -v sv="$script" '/^[[:space:]]*'"$script"':[[:space:]]*/ {sub(/^[[:space:]]*'"$script"':[[:space:]]*/, ""); print; exit}')
-    if [[ -n $script_command ]]; then
-      # Always prefix with .specify/ for plan usage
-      script_command=".specify/$script_command"
-      # Replace {SCRIPT} placeholder with the script command and __AGENT__ with agent name
-      substituted=$(sed "s|{SCRIPT}|${script_command}|g" "$plan_tpl" | tr -d '\r' | sed "s|__AGENT__|${agent}|g")
-      # Strip YAML frontmatter from plan template output (keep body only)
-      stripped=$(printf '%s\n' "$substituted" | awk 'BEGIN{fm=0;dash=0} /^---$/ {dash++; if(dash==1){fm=1; next} else if(dash==2){fm=0; next}} {if(!fm) print}')
-      printf '%s\n' "$stripped" > "$plan_tpl"
-    else
-      echo "Warning: no plan-template script command found for $script in YAML frontmatter" >&2
-    fi
-  fi
+  [[ -d templates ]] && { mkdir -p "$SPEC_DIR/templates"; find templates -type f -not -path "templates/commands/*" -not -name "vscode-settings.json" -exec cp --parents {} "$SPEC_DIR"/ \; ; echo "Copied templates -> .specify/templates"; }
+  
   # NOTE: We substitute {ARGS} internally. Outward tokens differ intentionally:
-  #   * Markdown/prompt (claude, copilot, cursor, opencode): $ARGUMENTS
+  #   * Markdown/prompt (claude, copilot, cursor-agent, opencode): $ARGUMENTS
   #   * TOML (gemini, qwen): {{args}}
   # This keeps formats readable without extra abstraction.
 
@@ -146,10 +147,14 @@ build_variant() {
       [[ -f agent_templates/gemini/GEMINI.md ]] && cp agent_templates/gemini/GEMINI.md "$base_dir/GEMINI.md" ;;
     copilot)
       mkdir -p "$base_dir/.github/prompts"
-      generate_commands copilot prompt.md "\$ARGUMENTS" "$base_dir/.github/prompts" "$script" ;;
-    cursor)
+      generate_commands copilot prompt.md "\$ARGUMENTS" "$base_dir/.github/prompts" "$script"
+      # Create VS Code workspace settings
+      mkdir -p "$base_dir/.vscode"
+      [[ -f templates/vscode-settings.json ]] && cp templates/vscode-settings.json "$base_dir/.vscode/settings.json"
+      ;;
+    cursor-agent)
       mkdir -p "$base_dir/.cursor/commands"
-      generate_commands cursor md "\$ARGUMENTS" "$base_dir/.cursor/commands" "$script" ;;
+      generate_commands cursor-agent md "\$ARGUMENTS" "$base_dir/.cursor/commands" "$script" ;;
     qwen)
       mkdir -p "$base_dir/.qwen/commands"
       generate_commands qwen toml "{{args}}" "$base_dir/.qwen/commands" "$script"
@@ -172,16 +177,22 @@ build_variant() {
     roo)
       mkdir -p "$base_dir/.roo/commands"
       generate_commands roo md "\$ARGUMENTS" "$base_dir/.roo/commands" "$script" ;;
+    codebuddy)
+      mkdir -p "$base_dir/.codebuddy/commands"
+      generate_commands codebuddy md "\$ARGUMENTS" "$base_dir/.codebuddy/commands" "$script" ;;
+
+    q)
+      mkdir -p "$base_dir/.amazonq/prompts"
+      generate_commands q md "\$ARGUMENTS" "$base_dir/.amazonq/prompts" "$script" ;;
   esac
   ( cd "$base_dir" && zip -r "../spec-kit-template-${agent}-${script}-${NEW_VERSION}.zip" . )
   echo "Created $GENRELEASES_DIR/spec-kit-template-${agent}-${script}-${NEW_VERSION}.zip"
 }
 
 # Determine agent list
-ALL_AGENTS=(claude gemini copilot cursor qwen opencode windsurf codex kilocode auggie roo)
+ALL_AGENTS=(claude gemini copilot cursor-agent qwen opencode windsurf codex kilocode auggie roo codebuddy q)
 ALL_SCRIPTS=(sh ps)
 
-
 norm_list() {
   # convert comma+space separated -> space separated unique while preserving order of first occurrence
   tr ',\n' '  ' | awk '{for(i=1;i<=NF;i++){if(!seen[$i]++){printf((out?" ":"") $i)}}}END{printf("\n")}'
@@ -226,3 +237,4 @@ done
 
 echo "Archives in $GENRELEASES_DIR:"
 ls -1 "$GENRELEASES_DIR"/spec-kit-template-*-"${NEW_VERSION}".zip
+
diff --git a/.github/workflows/scripts/generate-release-notes.sh b/.github/workflows/scripts/generate-release-notes.sh
index a26d16b..eba2340 100644
--- a/.github/workflows/scripts/generate-release-notes.sh
+++ b/.github/workflows/scripts/generate-release-notes.sh
@@ -33,4 +33,4 @@ This is the latest set of releases that you can use with your agent of choice. W
 EOF
 
 echo "Generated release notes:"
-cat release_notes.md
\ No newline at end of file
+cat release_notes.md
diff --git a/.github/workflows/scripts/get-next-version.sh b/.github/workflows/scripts/get-next-version.sh
index 2be0b6c..9770b9f 100644
--- a/.github/workflows/scripts/get-next-version.sh
+++ b/.github/workflows/scripts/get-next-version.sh
@@ -21,4 +21,4 @@ PATCH=$((PATCH + 1))
 NEW_VERSION="v$MAJOR.$MINOR.$PATCH"
 
 echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT
-echo "New version will be: $NEW_VERSION"
\ No newline at end of file
+echo "New version will be: $NEW_VERSION"
diff --git a/.github/workflows/scripts/update-version.sh b/.github/workflows/scripts/update-version.sh
index b0dc0e6..12bd9cd 100644
--- a/.github/workflows/scripts/update-version.sh
+++ b/.github/workflows/scripts/update-version.sh
@@ -20,4 +20,4 @@ if [ -f "pyproject.toml" ]; then
   echo "Updated pyproject.toml version to $PYTHON_VERSION (for release artifacts only)"
 else
   echo "Warning: pyproject.toml not found, skipping version update"
-fi
\ No newline at end of file
+fi
diff --git a/.gitignore b/.gitignore
index 42a1fbb..94bed85 100644
--- a/.gitignore
+++ b/.gitignore
@@ -42,4 +42,4 @@ env/
 # Spec Kit-specific files
 .genreleases/
 *.zip
-sdd-*/
\ No newline at end of file
+sdd-*/
diff --git a/AGENTS.md b/AGENTS.md
index 59b9956..492603c 100644
--- a/AGENTS.md
+++ b/AGENTS.md
@@ -37,52 +37,57 @@ Specify supports multiple AI agents by generating agent-specific command files a
 | **Cursor** | `.cursor/commands/` | Markdown | `cursor-agent` | Cursor CLI |
 | **Qwen Code** | `.qwen/commands/` | TOML | `qwen` | Alibaba's Qwen Code CLI |
 | **opencode** | `.opencode/command/` | Markdown | `opencode` | opencode CLI |
+| **Codex CLI** | `.codex/commands/` | Markdown | `codex` | Codex CLI |
 | **Windsurf** | `.windsurf/workflows/` | Markdown | N/A (IDE-based) | Windsurf IDE workflows |
+| **Kilo Code** | `.kilocode/rules/` | Markdown | N/A (IDE-based) | Kilo Code IDE |
+| **Auggie CLI** | `.augment/rules/` | Markdown | `auggie` | Auggie CLI |
+| **Roo Code** | `.roo/rules/` | Markdown | N/A (IDE-based) | Roo Code IDE |
+| **CodeBuddy CLI** | `.codebuddy/commands/` | Markdown | `codebuddy` | CodeBuddy CLI |
+| **Amazon Q Developer CLI** | `.amazonq/prompts/` | Markdown | `q` | Amazon Q Developer CLI |
 
 ### Step-by-Step Integration Guide
 
-Follow these steps to add a new agent (using Windsurf as an example):
+Follow these steps to add a new agent (using a hypothetical new agent as an example):
 
-#### 1. Update AI_CHOICES Constant
+#### 1. Add to AGENT_CONFIG
 
-Add the new agent to the `AI_CHOICES` dictionary in `src/specify_cli/__init__.py`:
+**IMPORTANT**: Use the actual CLI tool name as the key, not a shortened version.
+
+Add the new agent to the `AGENT_CONFIG` dictionary in `src/specify_cli/__init__.py`. This is the **single source of truth** for all agent metadata:
 
 ```python
-AI_CHOICES = {
-    "copilot": "GitHub Copilot",
-    "claude": "Claude Code", 
-    "gemini": "Gemini CLI",
-    "cursor": "Cursor",
-    "qwen": "Qwen Code",
-    "opencode": "opencode",
-    "windsurf": "Windsurf"  # Add new agent here
+AGENT_CONFIG = {
+    # ... existing agents ...
+    "new-agent-cli": {  # Use the ACTUAL CLI tool name (what users type in terminal)
+        "name": "New Agent Display Name",
+        "folder": ".newagent/",  # Directory for agent files
+        "install_url": "https://example.com/install",  # URL for installation docs (or None if IDE-based)
+        "requires_cli": True,  # True if CLI tool required, False for IDE-based agents
+    },
 }
 ```
 
-Also update the `agent_folder_map` in the same file to include the new agent's folder for the security notice:
+**Key Design Principle**: The dictionary key should match the actual executable name that users install. For example:
+- ✅ Use `"cursor-agent"` because the CLI tool is literally called `cursor-agent`
+- ❌ Don't use `"cursor"` as a shortcut if the tool is `cursor-agent`
 
-```python
-agent_folder_map = {
-    "claude": ".claude/",
-    "gemini": ".gemini/",
-    "cursor": ".cursor/",
-    "qwen": ".qwen/",
-    "opencode": ".opencode/",
-    "codex": ".codex/",
-    "windsurf": ".windsurf/",  # Add new agent folder here
-    "kilocode": ".kilocode/",
-    "auggie": ".auggie/",
-    "copilot": ".github/"
-}
-```
+This eliminates the need for special-case mappings throughout the codebase.
+
+**Field Explanations**:
+- `name`: Human-readable display name shown to users
+- `folder`: Directory where agent-specific files are stored (relative to project root)
+- `install_url`: Installation documentation URL (set to `None` for IDE-based agents)
+- `requires_cli`: Whether the agent requires a CLI tool check during initialization
 
 #### 2. Update CLI Help Text
 
-Update all help text and examples to include the new agent:
+Update the `--ai` parameter help text in the `init()` command to include the new agent:
+
+```python
+ai_assistant: str = typer.Option(None, "--ai", help="AI assistant to use: claude, gemini, copilot, cursor-agent, qwen, opencode, codex, windsurf, kilocode, auggie, codebuddy, new-agent-cli, or q"),
+```
 
-- Command option help: `--ai` parameter description
-- Function docstrings and examples
-- Error messages with agent lists
+Also update any function docstrings, examples, and error messages that list available agents.
 
 #### 3. Update README Documentation
 
@@ -99,7 +104,7 @@ Modify `.github/workflows/scripts/create-release-packages.sh`:
 
 ##### Add to ALL_AGENTS array:
 ```bash
-ALL_AGENTS=(claude gemini copilot cursor qwen opencode windsurf)
+ALL_AGENTS=(claude gemini copilot cursor-agent qwen opencode windsurf q)
 ```
 
 ##### Add case statement for directory structure:
@@ -186,17 +191,111 @@ elif selected_ai == "windsurf":
         agent_tool_missing = True
 ```
 
-**Note**: Skip CLI checks for IDE-based agents (Copilot, Windsurf).
+**Note**: CLI tool checks are now handled automatically based on the `requires_cli` field in AGENT_CONFIG. No additional code changes needed in the `check()` or `init()` commands - they automatically loop through AGENT_CONFIG and check tools as needed.
+
+## Important Design Decisions
+
+### Using Actual CLI Tool Names as Keys
+
+**CRITICAL**: When adding a new agent to AGENT_CONFIG, always use the **actual executable name** as the dictionary key, not a shortened or convenient version.
+
+**Why this matters:**
+- The `check_tool()` function uses `shutil.which(tool)` to find executables in the system PATH
+- If the key doesn't match the actual CLI tool name, you'll need special-case mappings throughout the codebase
+- This creates unnecessary complexity and maintenance burden
+
+**Example - The Cursor Lesson:**
+
+❌ **Wrong approach** (requires special-case mapping):
+```python
+AGENT_CONFIG = {
+    "cursor": {  # Shorthand that doesn't match the actual tool
+        "name": "Cursor",
+        # ...
+    }
+}
+
+# Then you need special cases everywhere:
+cli_tool = agent_key
+if agent_key == "cursor":
+    cli_tool = "cursor-agent"  # Map to the real tool name
+```
+
+✅ **Correct approach** (no mapping needed):
+```python
+AGENT_CONFIG = {
+    "cursor-agent": {  # Matches the actual executable name
+        "name": "Cursor",
+        # ...
+    }
+}
+
+# No special cases needed - just use agent_key directly!
+```
+
+**Benefits of this approach:**
+- Eliminates special-case logic scattered throughout the codebase
+- Makes the code more maintainable and easier to understand
+- Reduces the chance of bugs when adding new agents
+- Tool checking "just works" without additional mappings
+
+#### 7. Update Devcontainer files (Optional)
+
+For agents that have VS Code extensions or require CLI installation, update the devcontainer configuration files:
+
+##### VS Code Extension-based Agents
+
+For agents available as VS Code extensions, add them to `.devcontainer/devcontainer.json`:
+
+```json
+{
+  "customizations": {
+    "vscode": {
+      "extensions": [
+        // ... existing extensions ...
+        // [New Agent Name]
+        "[New Agent Extension ID]"
+      ]
+    }
+  }
+}
+```
+
+##### CLI-based Agents
+
+For agents that require CLI tools, add installation commands to `.devcontainer/post-create.sh`:
+
+```bash
+#!/bin/bash
+
+# Existing installations...
+
+echo -e "\n🤖 Installing [New Agent Name] CLI..."
+# run_command "npm install -g [agent-cli-package]@latest" # Example for node-based CLI
+# or other installation instructions (must be non-interactive and compatible with Linux Debian "Trixie" or later)...
+echo "✅ Done"
+
+```
+
+**Quick Tips:**
+
+- **Extension-based agents**: Add to the `extensions` array in `devcontainer.json`
+- **CLI-based agents**: Add installation scripts to `post-create.sh`
+- **Hybrid agents**: May require both extension and CLI installation
+- **Test thoroughly**: Ensure installations work in the devcontainer environment
 
 ## Agent Categories
 
 ### CLI-Based Agents
+
 Require a command-line tool to be installed:
 - **Claude Code**: `claude` CLI
 - **Gemini CLI**: `gemini` CLI  
 - **Cursor**: `cursor-agent` CLI
 - **Qwen Code**: `qwen` CLI
 - **opencode**: `opencode` CLI
+- **Amazon Q Developer CLI**: `q` CLI
+- **CodeBuddy CLI**: `codebuddy` CLI
 
 ### IDE-Based Agents
 Work within integrated development environments:
@@ -206,7 +305,7 @@ Work within integrated development environments:
 ## Command File Formats
 
 ### Markdown Format
-Used by: Claude, Cursor, opencode, Windsurf
+Used by: Claude, Cursor, opencode, Windsurf, Amazon Q Developer
 
 ```markdown
 ---
@@ -253,20 +352,24 @@ Different agents use different argument placeholders:
 
 ## Common Pitfalls
 
-1. **Forgetting update scripts**: Both bash and PowerShell scripts must be updated
-2. **Missing CLI checks**: Only add for agents that actually have CLI tools
-3. **Wrong argument format**: Use correct placeholder format for each agent type
-4. **Directory naming**: Follow agent-specific conventions exactly
-5. **Help text inconsistency**: Update all user-facing text consistently
+1. **Using shorthand keys instead of actual CLI tool names**: Always use the actual executable name as the AGENT_CONFIG key (e.g., `"cursor-agent"` not `"cursor"`). This prevents the need for special-case mappings throughout the codebase.
+2. **Forgetting update scripts**: Both bash and PowerShell scripts must be updated when adding new agents.
+3. **Incorrect `requires_cli` value**: Set to `True` only for agents that actually have CLI tools to check; set to `False` for IDE-based agents.
+4. **Wrong argument format**: Use correct placeholder format for each agent type (`$ARGUMENTS` for Markdown, `{{args}}` for TOML).
+5. **Directory naming**: Follow agent-specific conventions exactly (check existing agents for patterns).
+6. **Help text inconsistency**: Update all user-facing text consistently (help strings, docstrings, README, error messages).
 
 ## Future Considerations
 
 When adding new agents:
+
 - Consider the agent's native command/workflow patterns
 - Ensure compatibility with the Spec-Driven Development process
 - Document any special requirements or limitations
 - Update this guide with lessons learned
+- Verify the actual CLI tool name before adding to AGENT_CONFIG
 
 ---
 
-*This documentation should be updated whenever new agents are added to maintain accuracy and completeness.*
\ No newline at end of file
+*This documentation should be updated whenever new agents are added to maintain accuracy and completeness.*
+
diff --git a/CHANGELOG.md b/CHANGELOG.md
index 92cb0b8..3ca2ee0 100644
--- a/CHANGELOG.md
+++ b/CHANGELOG.md
@@ -2,11 +2,61 @@
 
 <!-- markdownlint-disable MD024 -->
 
-All notable changes to the Specify CLI will be documented in this file.
+All notable changes to the Specify CLI and templates are documented here.
 
 The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
 and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
 
+## [0.0.20] - 2025-10-14
+
+### Added
+
+- **Intelligent Branch Naming**: `create-new-feature` scripts now support `--short-name` parameter for custom branch names
+  - When `--short-name` provided: Uses the custom name directly (cleaned and formatted)
+  - When omitted: Automatically generates meaningful names using stop word filtering and length-based filtering
+  - Filters out common stop words (I, want, to, the, for, etc.)
+  - Removes words shorter than 3 characters (unless they're uppercase acronyms)
+  - Takes 3-4 most meaningful words from the description
+  - **Enforces GitHub's 244-byte branch name limit** with automatic truncation and warnings
+  - Examples:
+    - "I want to create user authentication" → `001-create-user-authentication`
+    - "Implement OAuth2 integration for API" → `001-implement-oauth2-integration-api`
+    - "Fix payment processing bug" → `001-fix-payment-processing`
+    - Very long descriptions are automatically truncated at word boundaries to stay within limits
+  - Designed for AI agents to provide semantic short names while maintaining standalone usability
+
+### Changed
+
+- Enhanced help documentation for `create-new-feature.sh` and `create-new-feature.ps1` scripts with examples
+- Branch names now validated against GitHub's 244-byte limit with automatic truncation if needed
+
+## [0.0.19] - 2025-10-10
+
+### Added
+
+- Support for CodeBuddy (thank you to [@lispking](https://github.com/lispking) for the contribution).
+- You can now see Git-sourced errors in the Specify CLI.
+
+### Changed
+
+- Fixed the path to the constitution in `plan.md` (thank you to [@lyzno1](https://github.com/lyzno1) for spotting).
+- Fixed backslash escapes in generated TOML files for Gemini (thank you to [@hsin19](https://github.com/hsin19) for the contribution).
+- Implementation command now ensures that the correct ignore files are added (thank you to [@sigent-amazon](https://github.com/sigent-amazon) for the contribution).
+
+## [0.0.18] - 2025-10-06
+
+### Added
+
+- Support for using `.` as a shorthand for current directory in `specify init .` command, equivalent to `--here` flag but more intuitive for users.
+- Use the `/speckit.` command prefix to easily discover Spec Kit-related commands.
+- Refactor the prompts and templates to simplify their capabilities and how they are tracked. No more polluting things with tests when they are not needed.
+- Ensure that tasks are created per user story (simplifies testing and validation).
+- Add support for Visual Studio Code prompt shortcuts and automatic script execution.
+
+### Changed
+
+- All command files now prefixed with `speckit.` (e.g., `speckit.specify.md`, `speckit.plan.md`) for better discoverability and differentiation in IDE/CLI command palettes and file explorers
+
 ## [0.0.17] - 2025-09-22
 
 ### Added
@@ -116,3 +166,4 @@ N/A
 ### Changed
 
 N/A
+
diff --git a/CODE_OF_CONDUCT.md b/CODE_OF_CONDUCT.md
index a1f82f0..6dc4b12 100644
--- a/CODE_OF_CONDUCT.md
+++ b/CODE_OF_CONDUCT.md
@@ -71,4 +71,4 @@ This Code of Conduct is adapted from the [Contributor Covenant][homepage], versi
 available at [http://contributor-covenant.org/version/1/4][version]
 
 [homepage]: http://contributor-covenant.org
-[version]: http://contributor-covenant.org/version/1/4/
\ No newline at end of file
+[version]: http://contributor-covenant.org/version/1/4/
diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
index 17baec8..9289491 100644
--- a/CONTRIBUTING.md
+++ b/CONTRIBUTING.md
@@ -13,6 +13,23 @@ These are one time installations required to be able to test your changes locall
 1. Install [Git](https://git-scm.com/downloads)
 1. Have an [AI coding agent available](README.md#-supported-ai-agents)
 
+<details>
+<summary><b>💡 Hint if you are using <code>VSCode</code> or <code>GitHub Codespaces</code> as your IDE</b></summary>
+
+<br>
+
+Provided you have [Docker](https://docker.com) installed on your machine, you can leverage [Dev Containers](https://containers.dev) through this [VSCode extension](https://marketplace.visualstudio.com/items?itemName=ms-vscode-remote.remote-containers), to easily set up your development environment, with aforementioned tools already installed and configured, thanks to the `.devcontainer/devcontainer.json` file (located at the root of the project).
+
+To do so, simply:
+
+- Checkout the repo
+- Open it with VSCode
+- Open the [Command Palette](https://code.visualstudio.com/docs/getstarted/userinterface#_command-palette) and select "Dev Containers: Open Folder in Container..."
+
+On [GitHub Codespaces](https://github.com/features/codespaces) it's even simpler, as it leverages the `.devcontainer/devcontainer.json` automatically upon opening the codespace.
+
+</details>
+
 ## Submitting a pull request
 
 >[!NOTE]
@@ -40,19 +57,47 @@ Here are a few things you can do that will increase the likelihood of your pull
 
 When working on spec-kit:
 
-1. Test changes with the `specify` CLI commands (`/specify`, `/plan`, `/tasks`) in your coding agent of choice
+1. Test changes with the `specify` CLI commands (`/speckit.specify`, `/speckit.plan`, `/speckit.tasks`) in your coding agent of choice
 2. Verify templates are working correctly in `templates/` directory
 3. Test script functionality in the `scripts/` directory
 4. Ensure memory files (`memory/constitution.md`) are updated if major process changes are made
 
 ## AI contributions in Spec Kit
 
+> [!IMPORTANT]
+>
+> If you are using **any kind of AI assistance** to contribute to Spec Kit,
+> it must be disclosed in the pull request or issue.
+
 We welcome and encourage the use of AI tools to help improve Spec Kit! Many valuable contributions have been enhanced with AI assistance for code generation, issue detection, and feature definition.
 
+That being said, if you are using any kind of AI assistance (e.g., agents, ChatGPT) while contributing to Spec Kit,
+**this must be disclosed in the pull request or issue**, along with the extent to which AI assistance was used (e.g., documentation comments vs. code generation).
+
+If your PR responses or comments are being generated by an AI, disclose that as well.
+
+As an exception, trivial spacing or typo fixes don't need to be disclosed, so long as the changes are limited to small parts of the code or short phrases.
+
+An example disclosure:
+
+> This PR was written primarily by GitHub Copilot.
+
+Or a more detailed disclosure:
+
+> I consulted ChatGPT to understand the codebase but the solution
+> was fully authored manually by myself.
+
+Failure to disclose this is first and foremost rude to the human operators on the other end of the pull request, but it also makes it difficult to
+determine how much scrutiny to apply to the contribution.
+
+In a perfect world, AI assistance would produce equal or higher quality work than any human. That isn't the world we live in today, and in most cases
+where human supervision or expertise is not in the loop, it's generating code that cannot be reasonably maintained or evolved.
+
 ### What we're looking for
 
 When submitting AI-assisted contributions, please ensure they include:
 
+- **Clear disclosure of AI use** - You are transparent about AI use and degree to which you're using it for the contribution
 - **Human understanding and testing** - You've personally tested the changes and understand what they do
 - **Clear rationale** - You can explain why the change is needed and how it fits within Spec Kit's goals  
 - **Concrete evidence** - Include test cases, scenarios, or examples that demonstrate the improvement
@@ -72,9 +117,12 @@ The key is demonstrating that you understand and have validated your proposed ch
 
 Contributors who consistently submit low-effort AI-generated changes may be restricted from further contributions at the maintainers' discretion.
 
+Please be respectful to maintainers and disclose AI assistance.
+
 ## Resources
 
 - [Spec-Driven Development Methodology](./spec-driven.md)
 - [How to Contribute to Open Source](https://opensource.guide/how-to-contribute/)
 - [Using Pull Requests](https://help.github.com/articles/about-pull-requests/)
 - [GitHub Help](https://help.github.com)
+
diff --git a/LICENSE b/LICENSE
index 28a50fa..a0eb787 100644
--- a/LICENSE
+++ b/LICENSE
@@ -19,3 +19,4 @@ AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
 LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
 OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 SOFTWARE.
+
diff --git a/README.md b/README.md
index 226da68..cb20ad6 100644
--- a/README.md
+++ b/README.md
@@ -5,26 +5,31 @@
 </div>
 
 <p align="center">
-    <strong>An effort to allow organizations to focus on product scenarios rather than writing undifferentiated code with the help of Spec-Driven Development.</strong>
+    <strong>An open source toolkit that allows you to focus on product scenarios and predictable outcomes instead of vibe coding every piece from scratch.</strong>
 </p>
 
-[![Release](https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg)](https://github.com/github/spec-kit/actions/workflows/release.yml)
+<p align="center">
+    <a href="https://github.com/github/spec-kit/actions/workflows/release.yml"><img src="https://github.com/github/spec-kit/actions/workflows/release.yml/badge.svg" alt="Release"/></a>
+    <a href="https://github.com/github/spec-kit/stargazers"><img src="https://img.shields.io/github/stars/github/spec-kit?style=social" alt="GitHub stars"/></a>
+    <a href="https://github.com/github/spec-kit/blob/main/LICENSE"><img src="https://img.shields.io/github/license/github/spec-kit" alt="License"/></a>
+    <a href="https://github.github.io/spec-kit/"><img src="https://img.shields.io/badge/docs-GitHub_Pages-blue" alt="Documentation"/></a>
+</p>
 
 ---
 
 ## Table of Contents
 
 - [🤔 What is Spec-Driven Development?](#-what-is-spec-driven-development)
-- [⚡ Get started](#-get-started)
+- [⚡ Get Started](#-get-started)
 - [📽️ Video Overview](#️-video-overview)
 - [🤖 Supported AI Agents](#-supported-ai-agents)
 - [🔧 Specify CLI Reference](#-specify-cli-reference)
-- [📚 Core philosophy](#-core-philosophy)
-- [🌟 Development phases](#-development-phases)
-- [🎯 Experimental goals](#-experimental-goals)
+- [📚 Core Philosophy](#-core-philosophy)
+- [🌟 Development Phases](#-development-phases)
+- [🎯 Experimental Goals](#-experimental-goals)
 - [🔧 Prerequisites](#-prerequisites)
-- [📖 Learn more](#-learn-more)
-- [📋 Detailed process](#-detailed-process)
+- [📖 Learn More](#-learn-more)
+- [📋 Detailed Process](#-detailed-process)
 - [🔍 Troubleshooting](#-troubleshooting)
 - [👥 Maintainers](#-maintainers)
 - [💬 Support](#-support)
@@ -35,9 +40,9 @@
 
 Spec-Driven Development **flips the script** on traditional software development. For decades, code has been king — specifications were just scaffolding we built and discarded once the "real work" of coding began. Spec-Driven Development changes this: **specifications become executable**, directly generating working implementations rather than just guiding them.
 
-## ⚡ Get started
+## ⚡ Get Started
 
-### 1. Install Specify
+### 1. Install Specify CLI
 
 Choose your preferred installation method:
 
@@ -56,6 +61,12 @@ specify init <PROJECT_NAME>
 specify check
 ```
 
+To upgrade specify run:
+
+```bash
+uv tool install specify-cli --force --from git+https://github.com/github/spec-kit.git
+```
+
 #### Option 2: One-time Usage
 
 Run directly without installing:
@@ -73,42 +84,44 @@ uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME
 
 ### 2. Establish project principles
 
-Use the **`/constitution`** command to create your project's governing principles and development guidelines that will guide all subsequent development.
+Launch your AI assistant in the project directory. The `/speckit.*` commands are available in the assistant.
+
+Use the **`/speckit.constitution`** command to create your project's governing principles and development guidelines that will guide all subsequent development.
 
 ```bash
-/constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements
+/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements
 ```
 
 ### 3. Create the spec
 
-Use the **`/specify`** command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.
+Use the **`/speckit.specify`** command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.
 
 ```bash
-/specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
+/speckit.specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
 ```
 
 ### 4. Create a technical implementation plan
 
-Use the **`/plan`** command to provide your tech stack and architecture choices.
+Use the **`/speckit.plan`** command to provide your tech stack and architecture choices.
 
 ```bash
-/plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
+/speckit.plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
 ```
 
 ### 5. Break down into tasks
 
-Use **`/tasks`** to create an actionable task list from your implementation plan.
+Use **`/speckit.tasks`** to create an actionable task list from your implementation plan.
 
 ```bash
-/tasks
+/speckit.tasks
 ```
 
 ### 6. Execute implementation
 
-Use **`/implement`** to execute all tasks and build your feature according to the plan.
+Use **`/speckit.implement`** to execute all tasks and build your feature according to the plan.
 
 ```bash
-/implement
+/speckit.implement
 ```
 
 For detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).
@@ -132,8 +145,10 @@ Want to see Spec Kit in action? Watch our [video overview](https://www.youtube.c
 | [Windsurf](https://windsurf.com/)                         | ✅ |                                                   |
 | [Kilo Code](https://github.com/Kilo-Org/kilocode)         | ✅ |                                                   |
 | [Auggie CLI](https://docs.augmentcode.com/cli/overview)   | ✅ |                                                   |
+| [CodeBuddy CLI](https://www.codebuddy.ai/cli)             | ✅ |                                                   |
 | [Roo Code](https://roocode.com/)                          | ✅ |                                                   |
-| [Codex CLI](https://github.com/openai/codex)              | ⚠️ | Codex [does not support](https://github.com/openai/codex/issues/2890) custom arguments for slash commands.  |
+| [Codex CLI](https://github.com/openai/codex)              | ✅ |                                                   |
+| [Amazon Q Developer CLI](https://aws.amazon.com/developer/learning/q-developer-cli/) | ⚠️ | Amazon Q Developer CLI [does not support](https://github.com/aws/amazon-q-developer-cli/issues/3064) custom arguments for slash commands. |
 
 ## 🔧 Specify CLI Reference
 
@@ -150,13 +165,13 @@ The `specify` command supports the following options:
 
 | Argument/Option        | Type     | Description                                                                  |
 |------------------------|----------|------------------------------------------------------------------------------|
-| `<project-name>`       | Argument | Name for your new project directory (optional if using `--here`)            |
-| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, `cursor`, `qwen`, `opencode`, `codex`, `windsurf`, `kilocode`, `auggie`, or `roo` |
+| `<project-name>`       | Argument | Name for your new project directory (optional if using `--here`, or use `.` for current directory) |
+| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, `cursor-agent`, `qwen`, `opencode`, `codex`, `windsurf`, `kilocode`, `auggie`, `roo`, `codebuddy`, or `q` |
 | `--script`             | Option   | Script variant to use: `sh` (bash/zsh) or `ps` (PowerShell)                 |
 | `--ignore-agent-tools` | Flag     | Skip checks for AI agent tools like Claude Code                             |
 | `--no-git`             | Flag     | Skip git repository initialization                                          |
 | `--here`               | Flag     | Initialize project in the current directory instead of creating a new one   |
-| `--force`              | Flag     | Force merge/overwrite when using `--here` in a non-empty directory (skip confirmation) |
+| `--force`              | Flag     | Force merge/overwrite when initializing in current directory (skip confirmation) |
 | `--skip-tls`           | Flag     | Skip SSL/TLS verification (not recommended)                                 |
 | `--debug`              | Flag     | Enable detailed debug output for troubleshooting                            |
 | `--github-token`       | Option   | GitHub token for API requests (or set GH_TOKEN/GITHUB_TOKEN env variable)  |
@@ -171,7 +186,7 @@ specify init my-project
 specify init my-project --ai claude
 
 # Initialize with Cursor support
-specify init my-project --ai cursor
+specify init my-project --ai cursor-agent
 
 # Initialize with Windsurf support
 specify init my-project --ai windsurf
@@ -180,9 +195,13 @@ specify init my-project --ai windsurf
 specify init my-project --ai copilot --script ps
 
 # Initialize in current directory
+specify init . --ai copilot
+# or use the --here flag
 specify init --here --ai copilot
 
 # Force merge into current (non-empty) directory without confirmation
+specify init . --force --ai copilot
+# or 
 specify init --here --force --ai copilot
 
 # Skip git initialization
@@ -202,23 +221,35 @@ specify check
 
 After running `specify init`, your AI coding agent will have access to these slash commands for structured development:
 
-| Command         | Description                                                           |
-|-----------------|-----------------------------------------------------------------------|
-| `/constitution` | Create or update project governing principles and development guidelines |
-| `/specify`      | Define what you want to build (requirements and user stories)        |
-| `/clarify`      | Clarify underspecified areas (must be run before `/plan` unless explicitly skipped; formerly `/quizme`) |
-| `/plan`         | Create technical implementation plans with your chosen tech stack     |
-| `/tasks`        | Generate actionable task lists for implementation                     |
-| `/analyze`      | Cross-artifact consistency & coverage analysis (run after /tasks, before /implement) |
-| `/implement`    | Execute all tasks to build the feature according to the plan         |
+#### Core Commands
+
+Essential commands for the Spec-Driven Development workflow:
+
+| Command                  | Description                                                           |
+|--------------------------|-----------------------------------------------------------------------|
+| `/speckit.constitution`  | Create or update project governing principles and development guidelines |
+| `/speckit.specify`       | Define what you want to build (requirements and user stories)        |
+| `/speckit.plan`          | Create technical implementation plans with your chosen tech stack     |
+| `/speckit.tasks`         | Generate actionable task lists for implementation                     |
+| `/speckit.implement`     | Execute all tasks to build the feature according to the plan         |
+
+#### Optional Commands
+
+Additional commands for enhanced quality and validation:
+
+| Command              | Description                                                           |
+|----------------------|-----------------------------------------------------------------------|
+| `/speckit.clarify`   | Clarify underspecified areas (recommended before `/speckit.plan`; formerly `/quizme`) |
+| `/speckit.analyze`   | Cross-artifact consistency & coverage analysis (run after `/speckit.tasks`, before `/speckit.implement`) |
+| `/speckit.checklist` | Generate custom quality checklists that validate requirements completeness, clarity, and consistency (like "unit tests for English") |
 
 ### Environment Variables
 
 | Variable         | Description                                                                                    |
 |------------------|------------------------------------------------------------------------------------------------|
-| `SPECIFY_FEATURE` | Override feature detection for non-Git repositories. Set to the feature directory name (e.g., `001-photo-albums`) to work on a specific feature when not using Git branches.<br/>**Must be set in the context of the agent you're working with prior to using `/plan` or follow-up commands. |
+| `SPECIFY_FEATURE` | Override feature detection for non-Git repositories. Set to the feature directory name (e.g., `001-photo-albums`) to work on a specific feature when not using Git branches.<br/>**Must be set in the context of the agent you're working with prior to using `/speckit.plan` or follow-up commands. |
 
-## 📚 Core philosophy
+## 📚 Core Philosophy
 
 Spec-Driven Development is a structured process that emphasizes:
 
@@ -227,7 +258,7 @@ Spec-Driven Development is a structured process that emphasizes:
 - **Multi-step refinement** rather than one-shot code generation from prompts
 - **Heavy reliance** on advanced AI model capabilities for specification interpretation
 
-## 🌟 Development phases
+## 🌟 Development Phases
 
 | Phase | Focus | Key Activities |
 |-------|-------|----------------|
@@ -235,7 +266,7 @@ Spec-Driven Development is a structured process that emphasizes:
 | **Creative Exploration** | Parallel implementations | <ul><li>Explore diverse solutions</li><li>Support multiple technology stacks & architectures</li><li>Experiment with UX patterns</li></ul> |
 | **Iterative Enhancement** ("Brownfield") | Brownfield modernization | <ul><li>Add features iteratively</li><li>Modernize legacy systems</li><li>Adapt processes</li></ul> |
 
-## 🎯 Experimental goals
+## 🎯 Experimental Goals
 
 Our research and experimentation focus on:
 
@@ -263,22 +294,22 @@ Our research and experimentation focus on:
 
 ## 🔧 Prerequisites
 
-- **Linux/macOS** (or WSL2 on Windows)
-- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), [Gemini CLI](https://github.com/google-gemini/gemini-cli), [Cursor](https://cursor.sh/), [Qwen CLI](https://github.com/QwenLM/qwen-code), [opencode](https://opencode.ai/), [Codex CLI](https://github.com/openai/codex), or [Windsurf](https://windsurf.com/)
+- **Linux/macOS/Windows**
+- [Supported](#-supported-ai-agents) AI coding agent.
 - [uv](https://docs.astral.sh/uv/) for package management
 - [Python 3.11+](https://www.python.org/downloads/)
 - [Git](https://git-scm.com/downloads)
 
 If you encounter issues with an agent, please open an issue so we can refine the integration.
 
-## 📖 Learn more
+## 📖 Learn More
 
 - **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process
 - **[Detailed Walkthrough](#-detailed-process)** - Step-by-step implementation guide
 
 ---
 
-## 📋 Detailed process
+## 📋 Detailed Process
 
 <details>
 <summary>Click to expand the detailed step-by-step walkthrough</summary>
@@ -292,8 +323,12 @@ specify init <project_name>
 Or initialize in the current directory:
 
 ```bash
+specify init .
+# or use the --here flag
 specify init --here
 # Skip confirmation when the directory already has files
+specify init . --force
+# or
 specify init --here --force
 ```
 
@@ -305,19 +340,23 @@ You will be prompted to select the AI agent you are using. You can also proactiv
 specify init <project_name> --ai claude
 specify init <project_name> --ai gemini
 specify init <project_name> --ai copilot
-specify init <project_name> --ai cursor
-specify init <project_name> --ai qwen
-specify init <project_name> --ai opencode
-specify init <project_name> --ai codex
-specify init <project_name> --ai windsurf
+
 # Or in current directory:
+specify init . --ai claude
+specify init . --ai codex
+
+# or use --here flag
 specify init --here --ai claude
 specify init --here --ai codex
+
 # Force merge into a non-empty current directory
+specify init . --force --ai claude
+
+# or
 specify init --here --force --ai claude
 ```
 
-The CLI will check if you have Claude Code, Gemini CLI, Cursor CLI, Qwen CLI, opencode, or Codex CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:
+The CLI will check if you have Claude Code, Gemini CLI, Cursor CLI, Qwen CLI, opencode, Codex CLI, or Amazon Q Developer CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:
 
 ```bash
 specify init <project_name> --ai claude --ignore-agent-tools
@@ -329,19 +368,19 @@ Go to the project folder and run your AI agent. In our example, we're using `cla
 
 ![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)
 
-You will know that things are configured correctly if you see the `/constitution`, `/specify`, `/plan`, `/tasks`, and `/implement` commands available.
+You will know that things are configured correctly if you see the `/speckit.constitution`, `/speckit.specify`, `/speckit.plan`, `/speckit.tasks`, and `/speckit.implement` commands available.
 
-The first step should be establishing your project's governing principles using the `/constitution` command. This helps ensure consistent decision-making throughout all subsequent development phases:
+The first step should be establishing your project's governing principles using the `/speckit.constitution` command. This helps ensure consistent decision-making throughout all subsequent development phases:
 
 ```text
-/constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements. Include governance for how these principles should guide technical decisions and implementation choices.
+/speckit.constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements. Include governance for how these principles should guide technical decisions and implementation choices.
 ```
 
-This step creates or updates the `/memory/constitution.md` file with your project's foundational guidelines that the AI agent will reference during specification, planning, and implementation phases.
+This step creates or updates the `.specify/memory/constitution.md` file with your project's foundational guidelines that the AI agent will reference during specification, planning, and implementation phases.
 
 ### **STEP 2:** Create project specifications
 
-With your project principles established, you can now create the functional specifications. Use the `/specify` command and then provide the concrete requirements for the project you want to develop.
+With your project principles established, you can now create the functional specifications. Use the `/speckit.specify` command and then provide the concrete requirements for the project you want to develop.
 
 >[!IMPORTANT]
 >Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.
@@ -376,21 +415,22 @@ The produced specification should contain a set of user stories and functional r
 At this stage, your project folder contents should resemble the following:
 
 ```text
-├── memory
-│	 └── constitution.md
-├── scripts
-│	 ├── check-prerequisites.sh
-│	 ├── common.sh
-│	 ├── create-new-feature.sh
-│	 ├── setup-plan.sh
-│	 └── update-claude-md.sh
-├── specs
-│	 └── 001-create-taskify
-│	     └── spec.md
-└── templates
-    ├── plan-template.md
-    ├── spec-template.md
-    └── tasks-template.md
+└── .specify
+    ├── memory
+    │	 └── constitution.md
+    ├── scripts
+    │	 ├── check-prerequisites.sh
+    │	 ├── common.sh
+    │	 ├── create-new-feature.sh
+    │	 ├── setup-plan.sh
+    │	 └── update-claude-md.sh
+    ├── specs
+    │	 └── 001-create-taskify
+    │	     └── spec.md
+    └── templates
+        ├── plan-template.md
+        ├── spec-template.md
+        └── tasks-template.md
 ```
 
 ### **STEP 3:** Functional specification clarification (required before planning)
@@ -400,12 +440,12 @@ With the baseline specification created, you can go ahead and clarify any of the
 You should run the structured clarification workflow **before** creating a technical plan to reduce rework downstream.
 
 Preferred order:
-1. Use `/clarify` (structured) – sequential, coverage-based questioning that records answers in a Clarifications section.
+1. Use `/speckit.clarify` (structured) – sequential, coverage-based questioning that records answers in a Clarifications section.
 2. Optionally follow up with ad-hoc free-form refinement if something still feels vague.
 
 If you intentionally want to skip clarification (e.g., spike or exploratory prototype), explicitly state that so the agent doesn't block on missing clarifications.
 
-Example free-form refinement prompt (after `/clarify` if still needed):
+Example free-form refinement prompt (after `/speckit.clarify` if still needed):
 
 ```text
 For each sample project or project that you create there should be a variable number of tasks between 5 and 15
@@ -423,7 +463,7 @@ It's important to use the interaction with Claude Code as an opportunity to clar
 
 ### **STEP 4:** Generate a plan
 
-You can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:
+You can now be specific about the tech stack and other technical requirements. You can use the `/speckit.plan` command that is built into the project template with a prompt like this:
 
 ```text
 We are going to generate this using .NET Aspire, using Postgres as the database. The frontend should use
@@ -507,15 +547,34 @@ You can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.c
 >[!NOTE]
 >Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.
 
-### STEP 6: Implementation
+### **STEP 6:** Generate task breakdown with /speckit.tasks
+
+With the implementation plan validated, you can now break down the plan into specific, actionable tasks that can be executed in the correct order. Use the `/speckit.tasks` command to automatically generate a detailed task breakdown from your implementation plan:
+
+```text
+/speckit.tasks
+```
+
+This step creates a `tasks.md` file in your feature specification directory that contains:
+
+- **Task breakdown organized by user story** - Each user story becomes a separate implementation phase with its own set of tasks
+- **Dependency management** - Tasks are ordered to respect dependencies between components (e.g., models before services, services before endpoints)
+- **Parallel execution markers** - Tasks that can run in parallel are marked with `[P]` to optimize development workflow
+- **File path specifications** - Each task includes the exact file paths where implementation should occur
+- **Test-driven development structure** - If tests are requested, test tasks are included and ordered to be written before implementation
+- **Checkpoint validation** - Each user story phase includes checkpoints to validate independent functionality
+
+The generated tasks.md provides a clear roadmap for the `/speckit.implement` command, ensuring systematic implementation that maintains code quality and allows for incremental delivery of user stories.
 
-Once ready, use the `/implement` command to execute your implementation plan:
+### **STEP 7:** Implementation
+
+Once ready, use the `/speckit.implement` command to execute your implementation plan:
 
 ```text
-/implement
+/speckit.implement
 ```
 
-The `/implement` command will:
+The `/speckit.implement` command will:
 - Validate that all prerequisites are in place (constitution, spec, plan, and tasks)
 - Parse the task breakdown from `tasks.md`
 - Execute tasks in the correct order, respecting dependencies and parallel execution markers
@@ -566,3 +625,4 @@ This project is heavily influenced by and based on the work and research of [Joh
 ## 📄 License
 
 This project is licensed under the terms of the MIT open source license. Please refer to the [LICENSE](./LICENSE) file for the full terms.
+
diff --git a/SECURITY.md b/SECURITY.md
index 4279c87..67a9cbf 100644
--- a/SECURITY.md
+++ b/SECURITY.md
@@ -28,4 +28,4 @@ This information will help us triage your report more quickly.
 
 ## Policy
 
-See [GitHub's Safe Harbor Policy](https://docs.github.com/en/site-policy/security-policies/github-bug-bounty-program-legal-safe-harbor#1-safe-harbor-terms)
\ No newline at end of file
+See [GitHub's Safe Harbor Policy](https://docs.github.com/en/site-policy/security-policies/github-bug-bounty-program-legal-safe-harbor#1-safe-harbor-terms)
diff --git a/SUPPORT.md b/SUPPORT.md
index 791d010..c75ce9b 100644
--- a/SUPPORT.md
+++ b/SUPPORT.md
@@ -17,3 +17,4 @@ For help or questions about using this project, please:
 ## GitHub Support Policy
 
 Support for this project is limited to the resources listed above.
+
diff --git a/docs/.gitignore b/docs/.gitignore
index 614670d..68fec76 100644
--- a/docs/.gitignore
+++ b/docs/.gitignore
@@ -6,3 +6,4 @@ obj/
 # Temporary files
 *.tmp
 *.log
+
diff --git a/docs/README.md b/docs/README.md
index 5501adf..7a155cf 100644
--- a/docs/README.md
+++ b/docs/README.md
@@ -31,3 +31,4 @@ To build the documentation locally:
 ## Deployment
 
 Documentation is automatically built and deployed to GitHub Pages when changes are pushed to the `main` branch. The workflow is defined in `.github/workflows/docs.yml`.
+
diff --git a/docs/docfx.json b/docs/docfx.json
index c59dedb..dca3f0f 100644
--- a/docs/docfx.json
+++ b/docs/docfx.json
@@ -68,3 +68,4 @@
     }
   }
 }
+
diff --git a/docs/index.md b/docs/index.md
index 34da702..e134404 100644
--- a/docs/index.md
+++ b/docs/index.md
@@ -55,8 +55,9 @@ Our research and experimentation focus on:
 
 ## Contributing
 
-Please see our [Contributing Guide](CONTRIBUTING.md) for information on how to contribute to this project.
+Please see our [Contributing Guide](https://github.com/github/spec-kit/blob/main/CONTRIBUTING.md) for information on how to contribute to this project.
 
 ## Support
 
-For support, please check our [Support Guide](SUPPORT.md) or open an issue on GitHub.
+For support, please check our [Support Guide](https://github.com/github/spec-kit/blob/main/SUPPORT.md) or open an issue on GitHub.
+
diff --git a/docs/installation.md b/docs/installation.md
index 7cf9a6a..d4dfaa3 100644
--- a/docs/installation.md
+++ b/docs/installation.md
@@ -3,7 +3,7 @@
 ## Prerequisites
 
 - **Linux/macOS** (or Windows; PowerShell scripts now supported without WSL)
-- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli)
+- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), [Codebuddy CLI](https://www.codebuddy.ai/cli) or [Gemini CLI](https://github.com/google-gemini/gemini-cli)
 - [uv](https://docs.astral.sh/uv/) for package management
 - [Python 3.11+](https://www.python.org/downloads/)
 - [Git](https://git-scm.com/downloads)
@@ -21,6 +21,8 @@ uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME
 Or initialize in the current directory:
 
 ```bash
+uvx --from git+https://github.com/github/spec-kit.git specify init .
+# or use the --here flag
 uvx --from git+https://github.com/github/spec-kit.git specify init --here
 ```
 
@@ -32,6 +34,7 @@ You can proactively specify your AI agent during initialization:
 uvx --from git+https://github.com/github/spec-kit.git specify init <project_name> --ai claude
 uvx --from git+https://github.com/github/spec-kit.git specify init <project_name> --ai gemini
 uvx --from git+https://github.com/github/spec-kit.git specify init <project_name> --ai copilot
+uvx --from git+https://github.com/github/spec-kit.git specify init <project_name> --ai codebuddy
 ```
 
 ### Specify Script Type (Shell vs PowerShell)
@@ -60,9 +63,9 @@ uvx --from git+https://github.com/github/spec-kit.git specify init <project_name
 ## Verification
 
 After initialization, you should see the following commands available in your AI agent:
-- `/specify` - Create specifications
-- `/plan` - Generate implementation plans  
-- `/tasks` - Break down into actionable tasks
+- `/speckit.specify` - Create specifications
+- `/speckit.plan` - Generate implementation plans  
+- `/speckit.tasks` - Break down into actionable tasks
 
 The `.specify/scripts` directory will contain both `.sh` and `.ps1` scripts.
 
@@ -84,3 +87,4 @@ git config --global credential.helper manager
 echo "Cleaning up..."
 rm gcm-linux_amd64.2.6.1.deb
 ```
+
diff --git a/docs/local-development.md b/docs/local-development.md
index 58f174b..bed67b3 100644
--- a/docs/local-development.md
+++ b/docs/local-development.md
@@ -166,3 +166,4 @@ rm -rf .venv dist build *.egg-info
 - Open a PR when satisfied
 - (Optional) Tag a release once changes land in `main`
 
+
diff --git a/docs/quickstart.md b/docs/quickstart.md
index 11d5c1e..0ad5f6e 100644
--- a/docs/quickstart.md
+++ b/docs/quickstart.md
@@ -22,29 +22,29 @@ uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME
 
 ### 2. Create the Spec
 
-Use the `/specify` command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.
+Use the `/speckit.specify` command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.
 
 ```bash
-/specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
+/speckit.specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
 ```
 
 ### 3. Create a Technical Implementation Plan
 
-Use the `/plan` command to provide your tech stack and architecture choices.
+Use the `/speckit.plan` command to provide your tech stack and architecture choices.
 
 ```bash
-/plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
+/speckit.plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
 ```
 
 ### 4. Break Down and Implement
 
-Use `/tasks` to create an actionable task list, then ask your agent to implement the feature.
+Use `/speckit.tasks` to create an actionable task list, then ask your agent to implement the feature.
 
 ## Detailed Example: Building Taskify
 
 Here's a complete example of building a team productivity platform:
 
-### Step 1: Define Requirements with `/specify`
+### Step 1: Define Requirements with `/speckit.specify`
 
 ```text
 Develop Taskify, a team productivity platform. It should allow users to create projects, add team members,
@@ -81,7 +81,7 @@ Also validate the specification checklist:
 Read the review and acceptance checklist, and check off each item in the checklist if the feature spec meets the criteria. Leave it empty if it does not.
 ```
 
-### Step 3: Generate Technical Plan with `/plan`
+### Step 3: Generate Technical Plan with `/speckit.plan`
 
 Be specific about your tech stack and technical requirements:
 
@@ -120,3 +120,4 @@ implement specs/002-create-taskify/plan.md
 - Read the complete methodology for in-depth guidance
 - Check out more examples in the repository
 - Explore the source code on GitHub
+
diff --git a/docs/toc.yml b/docs/toc.yml
index ecabd18..082bb8c 100644
--- a/docs/toc.yml
+++ b/docs/toc.yml
@@ -15,3 +15,4 @@
   items:
     - name: Local Development
       href: local-development.md
+
diff --git a/learn-spec-kit/README.md b/learn-spec-kit/README.md
deleted file mode 100644
index 5e807fa..0000000
--- a/learn-spec-kit/README.md
+++ /dev/null
@@ -1,159 +0,0 @@
-# Spec-Kit 学习中心
-
-欢迎来到 Spec-Kit 学习中心！这里提供了从理论到实践的完整学习路径，帮助您深入理解 Spec-Driven Development (SDD) 和 SpecKit 工具。
-
-## 🌟 为什么值得深入学习 SpecKit？
-
-SpecKit 不仅仅是一个简单的命令工具，它代表了软件开发范式的重大转变。深入学习 SpecKit 将为您带来：
-
-### 🎯 **规范驱动开发 (SDD) 的完整实践**
-- 从"代码为王"到"规范为王"的思维转变
-- 如何让规范成为可执行的开发指导
-- 多阶段文档驱动的开发流程设计
-
-### 🤖 **AI Agent 协作的工程化实践**
-- 如何设计 AI Agent 友好的项目结构
-- 多 AI 代理的集成机制和最佳实践
-- 从 AGENTS.md 标准到实际工程应用的完整链路
-
-### 🛠️ **精巧的模板和脚本系统**
-- 模板驱动的文档生成机制
-- 跨平台脚本的自动化工作流
-- 命令背后的完整技术实现原理
-
-### 🏗️ **现代软件工程的最佳实践**
-- 项目治理和宪法驱动的开发
-- 测试驱动开发 (TDD) 的自动化实现
-- 从需求到代码的完整可追溯性
-
-### 🚀 **AI 时代的开发范式**
-- 如何与 AI 助手高效协作
-- 多 AI 代理的协调和管理
-- 人机协作的最佳实践模式
-
-**无论您是初学者还是资深开发者，SpecKit 都能为您提供从基础使用到深度定制的全方位学习体验。**
-
-## 🎯 学习路径
-
-### 第一阶段：理论基础
-
-#### 1.1 **[SDD 理论介绍](./sdd-theory-guide.md)**
-   - 规范驱动开发的核心思想
-   - 从代码为王到规范为王的转变
-   - SDD 工作流程和实践原则
-   - 为什么现在需要 SDD
-   - **扩展阅读**: [spec-driven.md](../spec-driven.md) - 官方 SDD 理论文档
-
-#### 1.2. **[SpecKit 理论介绍](./speckit-theory-guide.md)**
-   - SpecKit 的设计理念和定位
-   - 如何实现 SDD 的工具化
-   - 与 AI 助手的集成机制
-   - 项目结构和文档组织原理
-
-### 第二阶段：快速上手
-
-#### 2.1. **[安装和简单使用](./installation-and-quickstart.md)**
-   - 环境准备和工具安装
-   - 创建第一个 SpecKit 项目
-   - 基本命令使用
-   - 快速了解 SpecKit 开发流程
-
-#### 2.2. **[实际项目开发流程指南](./practical-workflow-guide.md)**
-   - Cursor 环境下的核心开发流程
-   - /constitution /specify /clarify /plan /tasks /analyze /implement 7个核心命令
-   - 脚本和文档的协同工作机制
-   - 实战案例：用户认证系统开发
-
-### 第三阶段：命令详解(速查手册)
-
-#### 3.1. **[SpecKit CLI 项目管理命令参考](./cli-commands-reference.md)**
-   - **项目管理命令**: `specify init`, `specify check` 等
-   - 所有可用命令的详细说明
-   - 参数和选项参考
-   - 使用示例和最佳实践
-   - 故障排除指南
-
-#### 3.2. **[AI Agent 开发命令详解](./agent-commands-guide.md)**
-   - **开发流程命令**: `/constitution`, `/specify`, `/clarify`, `/plan`, `/tasks`, `/analyze`, `/implement` 等
-   - **使用角度**: 每个命令的设计目的和使用场景
-   - **具体作用**: 命令能解决什么问题
-   - **最佳实践**: 如何高效使用各个命令
-   - **常见问题**: 使用中的注意事项和解决方案
-
-### 第四阶段：深入理解Agent命令工作机制
-
-#### 4.1. **[AI Agent 命令原理](./agent-commands-principles.md)**
-   - **背后流程**: 用户触发命令后发生了什么
-   - **文档组织**: 业务文档如何自动生成和更新
-   - **完整流程图**: 从用户命令到文档生成的完整流程
-   - **技术实现**: 命令背后的SpecKit原理
-
-#### 4.2. **[Memory 文档系统指南](./memory-documents-guide.md)**
-   - 项目宪法和治理文档说明
-   - 核心原则和开发规范
-   - 宪法更新和维护流程
-   - 与其他系统的集成
-
-#### 4.3. **[Templates 模板系统指南](./templates-system-guide.md)**
-   - 所有模板文档的详细说明
-   - 模板结构和占位符系统
-   - 命令模板和自动化集成
-   - 模板使用和自定义方法
-
-#### 4.4. **[Scripts 脚本参考指南](./scripts-reference-guide.md)**
-   - 所有脚本工具的详细说明
-   - Bash 和 PowerShell 版本对比
-   - 功能开发工作流程
-   - 跨平台兼容性说明
-
-#### 4.5. **[Quickstart 学习指南](./quickstart-learning-guide.md)**
-   - Quickstart 的作用与定位详解
-   - 与用户交互流程、页面设计的关系
-   - 页面拆解的正确理解
-   - 实际应用示例和最佳实践
-   - 常见误区与避免方法
-
-#### 4.6. **[Tasks 隐式页面设计指南](./tasks-implicit-page-design-guide.md)**
-   - Tasks 命令的隐式页面设计机制
-   - 基于用户故事的自动页面拆解
-   - 与显式页面设计的关系和协作
-   - 实际应用示例和最佳实践
-   - 优势局限性和常见问题解答
-
-### 第五阶段：深入理解CLI工程化技术
-
-#### 5.1. **[项目结构概览](./project-structure-overview.md)**
-   - 完整的项目目录结构说明
-   - 核心组件介绍
-   - 项目特点和开发工作流
-   - 扩展性说明
-
-#### 5.2. **[uvx 命令实现原理详解](./uvx-implementation-guide.md)**
-   - 详细说明 `uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>` 命令的工作原理
-   - 项目配置分析
-   - 执行流程详解
-   - 技术特点和模板系统
-
-#### 5.3. **[SpecKit 工程化原理](./speckit-engineering-principles.md)**
-   - **SpecKit CLI 实现原理**: 如何支持11个AI Agent（Claude、Gemini、Copilot、Cursor、Qwen、opencode、Windsurf、Codex、Kilo Code、Auggie、Roo Code）
-   - **发布机制**: 如何实现跨平台发布
-   - **安装机制**: uvx 命令的工作原理
-   - **扩展性设计**: 如何添加新的 AI Agent 支持
-
-#### 5.4. **[AGENTS.md 机制详解指南](./agents-md-mechanism-guide.md)**
-   - AGENTS.md 标准机制的历史背景和设计理念
-   - AI 代理的读取流程和交互模式
-   - 与 README.md 的区别和互补关系
-   - 核心价值和项目治理优势
-   - 与 SpecKit 多 AI 代理的集成机制
-
-
-## 📄 许可证
-
-本项目采用 [LICENSE](../LICENSE) 中指定的许可证。
-
----
-
-**注意**: 这些学习文档会随着项目的发展持续更新。如果您发现任何过时或不准确的信息，请及时反馈。
-
-**最后更新**: 2025年9月
diff --git a/learn-spec-kit/agent-commands-guide.md b/learn-spec-kit/agent-commands-guide.md
deleted file mode 100644
index ba6503c..0000000
--- a/learn-spec-kit/agent-commands-guide.md
+++ /dev/null
@@ -1,265 +0,0 @@
-# AI Agent 开发命令详解
-
-## 概述
-
-本文档从使用角度详细介绍 SpecKit 的 AI Agent 开发命令，包括设计目的、使用场景、具体作用和最佳实践。这些命令是规范驱动开发流程的核心工具。
-
-## AI Agent 命令概览
-
-SpecKit 提供了一套完整的 AI Agent 命令体系，支持从规范创建到代码实现的完整开发流程：
-
-| 命令 | 设计目的 | 使用场景 | 核心作用 |
-|------|----------|----------|----------|
-| `/constitution` | 项目宪法 | 项目治理 | 建立项目开发规范和原则 |
-| `/specify` | 详细规范制定 | 需求分析阶段 | 生成完整的产品需求文档 |
-| `/clarify` | 需求澄清 | 需求不明确时 | 澄清模糊需求和技术细节 |
-| `/plan` | 制定开发计划 | 项目规划阶段 | 结构化项目目标和里程碑 |
-| `/tasks` | 任务分解 | 开发准备阶段 | 将规范分解为具体任务 |
-| `/analyze` | 代码分析 | 代码审查阶段 | 分析代码质量和规范符合性 |
-| `/implement` | 代码实现 | 开发实施阶段 | 基于规范生成代码 |
-
-## 详细命令说明
-
-### 1. `/constitution` - 项目宪法
-
-#### 设计目的
-建立项目开发的核心原则和治理规范，为所有后续开发提供指导框架。
-
-#### 使用场景
-- 项目启动时建立开发规范
-- 团队协作时统一开发标准
-- 项目治理和质量控制
-
-#### 具体作用
-- 定义项目开发原则和价值观
-- 建立代码质量和架构标准
-- 设置团队协作规范
-- 创建项目治理框架
-
-#### 使用示例
-
-```
-/constitution 创建专注于代码质量、测试标准、用户体验一致性和性能要求的原则
-```
-
-#### 最佳实践
-- 在项目开始前就使用 `/constitution` 建立开发规范
-- 根据项目特点制定合适的开发原则
-- 定期回顾和更新宪法内容
-
-### 2. `/specify` - 功能规范制定
-
-#### 设计目的
-将模糊的项目想法转化为结构化的功能规范，明确功能需求、用户场景和验收标准。
-
-#### 使用场景
-- 项目启动时的需求分析
-- 功能需求的详细定义
-- 用户故事的编写
-- 验收标准的制定
-
-#### 具体作用
-- 定义功能需求和用户场景
-- 编写用户故事和验收标准
-- 识别功能边界和约束
-- 建立功能规范文档
-
-#### 使用示例
-
-```
-/specify 构建一个用户认证系统，包含用户注册、登录、密码重置功能，支持邮箱验证和 JWT 令牌
-```
-
-#### 最佳实践
-- 详细描述功能需求，避免模糊表述
-- 包含具体的用户场景和验收标准
-- 考虑边界条件和异常情况
-
-### 3. `/clarify` - 需求澄清
-
-#### 设计目的
-澄清功能规范中的模糊或不明确的部分，确保开发团队对需求有统一的理解。
-
-#### 使用场景
-- 需求描述不够清晰时
-- 技术实现方案不明确时
-- 团队对需求理解有分歧时
-- 复杂功能需要进一步细化时
-
-#### 具体作用
-- 识别需求中的模糊点
-- 提出澄清问题
-- 记录澄清结果
-- 更新功能规范
-
-#### 使用示例
-
-```
-/clarify 用户认证系统的密码复杂度要求是什么？是否需要支持第三方登录？
-```
-
-#### 最佳实践
-- 在制定计划前先进行需求澄清
-- 针对关键功能点进行深入澄清
-- 记录所有澄清结果
-
-### 4. `/plan` - 技术实现计划
-
-#### 设计目的
-基于功能规范制定详细的技术实现计划，包括技术选型、架构设计和开发步骤。
-
-#### 使用场景
-- 功能规范确定后的技术规划
-- 技术选型和架构设计
-- 开发任务的分解和排序
-- 技术风险评估和应对
-
-#### 具体作用
-- 制定技术实现方案
-- 选择合适的技术栈
-- 设计系统架构
-- 制定开发计划
-
-#### 使用示例
-
-```
-/plan 使用 Python 3.11, FastAPI, PostgreSQL, JWT, 邮箱服务集成
-```
-
-#### 最佳实践
-- 基于功能需求选择合适的技术栈
-- 考虑系统的可扩展性和维护性
-- 制定详细的开发步骤
-
-### 5. `/tasks` - 任务分解
-
-#### 设计目的
-将技术实现计划分解为具体的、可执行的任务，为开发实施提供详细的指导。
-
-#### 使用场景
-- 开发实施前的任务规划
-- 团队协作的任务分配
-- 开发进度的跟踪和管理
-- 任务依赖关系的梳理
-
-#### 具体作用
-- 将计划分解为具体任务
-- 确定任务优先级和依赖关系
-- 分配任务给团队成员
-- 跟踪任务执行进度
-
-#### 使用示例
-
-```
-/tasks
-```
-
-#### 最佳实践
-- 按照 TDD 原则安排任务顺序
-- 标记可以并行执行的任务
-- 明确任务之间的依赖关系
-
-### 6. `/analyze` - 代码分析
-
-#### 设计目的
-分析代码质量、规范符合性和一致性，确保代码符合项目标准。
-
-#### 使用场景
-- 代码审查和质量检查
-- 规范符合性验证
-- 代码一致性分析
-- 潜在问题的识别
-
-#### 具体作用
-- 检查代码质量
-- 验证规范符合性
-- 分析代码一致性
-- 识别潜在问题
-
-#### 使用示例
-
-```
-/analyze
-```
-
-#### 最佳实践
-- 在代码实现后及时进行分析
-- 关注代码质量和规范符合性
-- 及时修复发现的问题
-
-### 7. `/implement` - 代码实现
-
-#### 设计目的
-基于功能规范和技术计划，生成高质量的代码实现。
-
-#### 使用场景
-- 功能代码的实现
-- 测试代码的编写
-- 配置文件的生成
-- 文档的自动生成
-
-#### 具体作用
-- 生成功能代码
-- 编写测试用例
-- 创建配置文件
-- 生成技术文档
-
-#### 使用示例
-
-```
-/implement
-```
-
-#### 最佳实践
-- 按照任务列表顺序执行
-- 确保代码质量和测试覆盖
-- 遵循项目开发规范
-
-## 命令使用流程
-
-### 标准开发流程
-
-1. **项目启动**: `/constitution` → 建立开发规范
-2. **需求分析**: `/specify` → 定义功能需求
-3. **需求澄清**: `/clarify` → 澄清模糊需求
-4. **技术规划**: `/plan` → 制定技术方案
-5. **任务分解**: `/tasks` → 分解开发任务
-6. **代码实现**: `/implement` → 实现功能代码
-7. **代码分析**: `/analyze` → 分析代码质量
-
-### 快速开发流程
-
-1. **需求定义**: `/specify` → 定义功能需求
-2. **技术规划**: `/plan` → 制定技术方案
-3. **任务执行**: `/tasks` → 分解任务
-4. **代码实现**: `/implement` → 实现功能
-
-## 常见问题
-
-### Q: 什么时候使用 `/clarify` 命令？
-A: 当功能需求描述不够清晰，或者对技术实现方案有疑问时使用。
-
-### Q: `/plan` 和 `/tasks` 有什么区别？
-A: `/plan` 制定技术实现方案，`/tasks` 将方案分解为具体任务。
-
-### Q: 可以跳过某些命令吗？
-A: 可以，但建议按照标准流程使用，以确保开发质量。
-
-### Q: 如何确保代码质量？
-A: 使用 `/analyze` 命令定期分析代码质量，及时修复问题。
-
-## 最佳实践总结
-
-1. **按顺序使用命令**: 遵循标准开发流程，确保每个阶段都得到充分处理
-2. **详细描述需求**: 在 `/specify` 中提供详细的功能描述
-3. **及时澄清**: 遇到模糊需求时及时使用 `/clarify`
-4. **合理规划**: 在 `/plan` 中选择合适的技术栈和架构
-5. **任务分解**: 在 `/tasks` 中合理分解任务，明确依赖关系
-6. **质量检查**: 使用 `/analyze` 确保代码质量
-7. **持续改进**: 根据项目经验不断优化开发流程
-
----
-
-**下一步学习**: 
-- [AI Agent 命令原理](./speckit-commands-principles.md) - 了解命令背后的工作机制
-- [实际项目开发流程指南](./practical-workflow-guide.md) - 实战应用示例
\ No newline at end of file
diff --git a/learn-spec-kit/agent-commands-principles.md b/learn-spec-kit/agent-commands-principles.md
deleted file mode 100644
index d43b6a1..0000000
--- a/learn-spec-kit/agent-commands-principles.md
+++ /dev/null
@@ -1,448 +0,0 @@
-# SpecKit 命令原理
-
-## 概述
-
-本文档深入解析当用户在 AI Agent 中触发命令（如 `/specify`, `/plan`, `/tasks` 等）后，SpecKit 系统内部的完整业务流程，包括脚本如何执行、模板如何使用、文档如何生成和更新，以及从用户命令到文档生成的完整技术实现。
-
-## SpecKit 命令总流程图
-
-> **📖 如何使用这个流程图**：
-> - **颜色编码**：每个命令用不同颜色线条连接，便于追踪完整流程
-> - **层次结构**：从上到下展示从用户输入到文件生成的完整过程
-> - **快速导航**：点击下方命令名称可跳转到详细说明
-> - **使用顺序**：按照 constitution → specify → clarify → plan → tasks → analyze → implement 的顺序执行  
-
-```mermaid
-graph TB
-    subgraph "第一层：用户输入命令"
-        A1["/constitution"]
-        A2["/specify"]
-        A3["/clarify"]
-        A4["/plan"]
-        A5["/tasks"]
-        A6["/analyze"]
-        A7["/implement"]
-    end
-    
-    subgraph "第二层：脚本执行"
-        B1["无脚本调用"]
-        B2["create-new-feature.sh"]
-        B3["check-prerequisites.sh<br/>--paths-only"]
-        B4["setup-plan.sh<br/>+ update-agent-context.sh"]
-        B5["check-prerequisites.sh"]
-        B6["check-prerequisites.sh<br/>--require-tasks"]
-        B7["check-prerequisites.sh<br/>--require-tasks"]
-    end
-    
-    subgraph "第三层：模板文件"
-        C1["constitution.md"]
-        C2["spec-template.md"]
-        C3["无模板"]
-        C4["plan-template.md"]
-        C5["tasks-**template**.md"]
-        C6["无模板"]
-        C7["无模板"]
-    end
-    
-    subgraph "第四层：参考产物"
-        D1["无参考"]
-        D2["无参考"]
-        D3["spec.md"]
-        D4["spec.md + constitution.md"]
-        D5["spec.md<br/>+ plan.md<br/>+ research.md<br/>+ data-model.md<br/>+ quickstart.md<br/>+ contracts/"]
-        D6["spec.md + plan.md<br/>+ tasks.md + constitution.md"]
-        D7["tasks.md + plan.md<br/>+ research.md<br/>+ data-model.md<br/>+ quickstart.md<br/>+ contracts/"]
-    end
-    
-    subgraph "第五层：生成的文件"
-        E1["constitution.md"]
-        E2["spec.md"]
-        E3["spec.md (更新)"]
-        E4["plan.md<br/>+ research.md<br/>+ data-model.md<br/>+ quickstart.md<br/>+ contracts/<br/>+ agent规则文件"]
-        E5["tasks.md"]
-        E6["分析报告"]
-        E7["源代码文件 + 测试文件"]
-    end
-    
-    %% 连接线 - 使用不同颜色表示不同命令
-    A1 -->|红色| B1
-    A2 -->|橙色| B2
-    A3 -->|黄色| B3
-    A4 -->|绿色| B4
-    A5 -->|蓝色| B5
-    A6 -->|紫色| B6
-    A7 -->|灰色| B7
-    
-    B1 -->|红色| C1
-    B2 -->|橙色| C2
-    B3 -->|黄色| C3
-    B4 -->|绿色| C4
-    B5 -->|蓝色| C5
-    B6 -->|紫色| C6
-    B7 -->|灰色| C7
-    
-    C1 -->|红色| D1
-    C2 -->|橙色| D2
-    C3 -->|黄色| D3
-    C4 -->|绿色| D4
-    C5 -->|蓝色| D5
-    C6 -->|紫色| D6
-    C7 -->|灰色| D7
-    
-    D1 -->|红色| E1
-    D2 -->|橙色| E2
-    D3 -->|黄色| E3
-    D4 -->|绿色| E4
-    D5 -->|蓝色| E5
-    D6 -->|紫色| E6
-    D7 -->|灰色| E7
-    
-    %% 样式定义
-    classDef userInput fill:#e1f5fe,stroke:#01579b,stroke-width:2px
-    classDef script fill:#f3e5f5,stroke:#4a148c,stroke-width:2px
-    classDef template fill:#e8f5e8,stroke:#1b5e20,stroke-width:2px
-    classDef reference fill:#fff8e1,stroke:#f57c00,stroke-width:2px
-    classDef output fill:#fff3e0,stroke:#e65100,stroke-width:2px
-    
-    class A1,A2,A3,A4,A5,A6,A7 userInput
-    class B1,B2,B3,B4,B5,B6,B7 script
-    class C1,C2,C3,C4,C5,C6,C7 template
-    class D1,D2,D3,D4,D5,D6,D7 reference
-    class E1,E2,E3,E4,E5,E6,E7 output
-```
-
-## 命令详细原理分析
-
-### 1. `/constitution` 命令原理
-
-#### 背后流程
-当用户在 AI Agent 中触发 `/constitution` 命令时：
-
-1. **无脚本调用**：该命令不调用任何外部脚本，完全由 AI Agent 内部处理
-2. **模板加载**：AI Agent 从 `memory/constitution.md` 模板文件加载内容
-3. **内容生成**：AI Agent 根据用户输入生成项目治理原则和开发指导方针
-4. **文件创建**：直接在 `memory/constitution.md` 创建或更新文件
-
-#### 文档组织
-- **输入**：用户描述的项目原则和治理要求
-- **模板**：`memory/constitution.md` 模板文件
-- **输出**：`memory/constitution.md` 项目宪法文件
-- **参考**：无其他文档依赖
-
-#### 技术实现
-- **无脚本执行**：完全依赖 AI Agent 的模板处理能力
-- **模板系统**：使用预定义的宪法模板结构
-- **内容填充**：AI Agent 根据用户输入填充模板占位符
-- **版本控制**：自动生成版本号、批准日期等元数据
-
-#### 模板执行流程
-根据 `memory/constitution.md` 模板，AI Agent 执行以下流程：
-
-1. **解析用户输入**：分析用户描述的项目原则和治理要求
-2. **填充核心原则**：根据输入生成 5 个核心原则（Library-First、CLI Interface、Test-First 等）
-3. **添加约束条件**：生成技术栈要求、合规标准、部署策略等
-4. **设置工作流程**：定义代码审查要求、测试门禁、部署审批流程
-5. **生成治理规则**：创建宪法优先规则、修订流程、合规检查机制
-6. **元数据生成**：自动设置版本号、批准日期、最后修订日期
-
-### 2. `/specify` 命令原理
-
-#### 背后流程
-当用户触发 `/specify` 命令时：
-
-1. **脚本调用**：执行 `create-new-feature.sh` 脚本
-2. **分支创建**：自动创建新的功能分支（如 `001-feature-name`）
-3. **目录结构**：在 `specs/001-feature-name/` 创建功能目录
-4. **模板复制**：将 `spec-template.md` 复制到 `spec.md`
-5. **环境变量**：设置 `SPECIFY_FEATURE` 环境变量
-
-#### 文档组织
-- **输入**：用户的功能描述和需求
-- **模板**：`templates/spec-template.md` 规格模板
-- **输出**：`specs/[feature-name]/spec.md` 功能规格文档
-- **参考**：无其他文档依赖
-
-#### 技术实现
-```bash
-# create-new-feature.sh 核心逻辑
-1. 解析功能描述
-2. 生成下一个功能编号（001, 002, 003...）
-3. 创建功能分支（如果使用 Git）
-4. 创建功能目录结构
-5. 复制规格模板
-6. 设置环境变量
-```
-
-#### 模板执行流程
-根据 `templates/spec-template.md` 模板，AI Agent 执行以下流程：
-
-1. **解析用户描述**：从用户输入中提取功能描述
-2. **提取关键概念**：识别参与者、动作、数据、约束条件
-3. **标记模糊需求**：对不清楚的方面使用 `[NEEDS CLARIFICATION: 具体问题]`
-4. **填充用户场景**：生成主要用户故事和验收场景
-5. **生成功能需求**：创建可测试的功能需求列表
-6. **识别关键实体**：如果涉及数据，识别主要实体
-7. **运行审查清单**：检查规格完整性和质量
-8. **更新执行状态**：标记各个处理步骤的完成状态
-
-### 3. `/clarify` 命令原理
-
-#### 背后流程
-当用户触发 `/clarify` 命令时：
-
-1. **脚本调用**：执行 `check-prerequisites.sh --paths-only`
-2. **路径验证**：检查当前功能目录和文件路径
-3. **规格分析**：AI Agent 分析 `spec.md` 中的模糊需求
-4. **问题生成**：生成结构化的澄清问题
-5. **规格更新**：将澄清结果更新到 `spec.md`
-
-#### 文档组织
-- **输入**：现有的 `spec.md` 文件
-- **模板**：无特定模板，使用 AI Agent 的澄清逻辑
-- **输出**：更新后的 `spec.md` 文件
-- **参考**：`spec.md` 文件内容
-
-#### 技术实现
-```bash
-# check-prerequisites.sh --paths-only 输出
-{
-  "REPO_ROOT": "/path/to/repo",
-  "BRANCH": "001-feature-name", 
-  "FEATURE_DIR": "/path/to/specs/001-feature-name",
-  "FEATURE_SPEC": "/path/to/spec.md",
-  "IMPL_PLAN": "/path/to/plan.md",
-  "TASKS": "/path/to/tasks.md"
-}
-```
-
-#### 模板执行流程
-`/clarify` 命令没有特定模板，AI Agent 执行以下澄清流程：
-
-1. **分析现有规格**：读取 `spec.md` 文件内容
-2. **识别模糊点**：查找 `[NEEDS CLARIFICATION]` 标记
-3. **生成澄清问题**：为每个模糊点生成具体的澄清问题
-4. **结构化提问**：按优先级和逻辑顺序组织问题
-5. **记录澄清结果**：将用户回答整合到规格中
-6. **更新规格文档**：移除 `[NEEDS CLARIFICATION]` 标记，添加澄清内容
-7. **验证完整性**：确保所有模糊点都已澄清
-
-### 4. `/plan` 命令原理
-
-#### 背后流程
-当用户触发 `/plan` 命令时：
-
-1. **脚本调用**：执行 `setup-plan.sh` 脚本
-2. **模板复制**：将 `plan-template.md` 复制到 `plan.md`
-3. **上下文更新**：执行 `update-agent-context.sh` 更新 AI Agent 上下文
-4. **规格分析**：AI Agent 分析 `spec.md` 和 `constitution.md`
-5. **技术规划**：生成技术栈选择和架构设计
-6. **文档生成**：创建 `research.md`、`data-model.md`、`quickstart.md`、`contracts/` 等
-
-#### 文档组织
-- **输入**：`spec.md` + `constitution.md`
-- **模板**：`templates/plan-template.md` 计划模板
-- **输出**：`plan.md` + `research.md` + `data-model.md` + `quickstart.md` + `contracts/`
-- **参考**：规格文档和宪法文档
-
-#### 技术实现
-```bash
-# setup-plan.sh 核心逻辑
-1. 验证功能分支
-2. 复制计划模板到 plan.md
-3. 输出路径信息给 AI Agent
-
-# update-agent-context.sh 核心逻辑  
-1. 解析 plan.md 中的技术信息
-2. 更新 AI Agent 上下文文件（如 CLAUDE.md）
-3. 添加新技术栈和最近变更
-```
-
-#### 模板执行流程
-根据 `templates/plan-template.md` 模板，AI Agent 执行以下流程：
-
-1. **加载功能规格**：从 `spec.md` 读取功能需求
-2. **填充技术上下文**：扫描并解决 `NEEDS CLARIFICATION` 标记
-3. **检测项目类型**：根据上下文确定项目类型（web/mobile/single）
-4. **宪法检查**：基于宪法文档内容填充宪法检查部分
-5. **评估宪法合规**：检查是否存在违反宪法的设计，记录复杂性跟踪
-6. **执行阶段 0**：生成 `research.md` 研究文档
-7. **执行阶段 1**：创建 `contracts/`、`data-model.md`、`quickstart.md`、Agent 上下文文件
-8. **重新评估宪法**：检查设计后是否产生新的宪法违规
-9. **规划阶段 2**：描述任务生成方法（不实际创建 tasks.md）
-10. **停止准备**：为 `/tasks` 命令做好准备
-
-### 5. `/tasks` 命令原理
-
-#### 背后流程
-当用户触发 `/tasks` 命令时：
-
-1. **脚本调用**：执行 `check-prerequisites.sh` 验证前置条件
-2. **计划分析**：AI Agent 分析 `plan.md` 和相关设计文档
-3. **任务生成**：根据设计文档生成具体的实现任务
-4. **依赖分析**：确定任务之间的依赖关系和并行执行标记
-5. **模板填充**：使用 `tasks-template.md` 生成 `tasks.md`
-
-#### 文档组织
-- **输入**：`plan.md` + `research.md` + `data-model.md` + `contracts/`
-- **模板**：`templates/tasks-template.md` 任务模板
-- **输出**：`tasks.md` 任务列表文档
-- **参考**：所有设计阶段的文档
-
-#### 技术实现
-```bash
-# check-prerequisites.sh 验证逻辑
-1. 检查 plan.md 是否存在
-2. 验证功能目录结构
-3. 输出可用文档列表
-4. 确保所有前置条件满足
-```
-
-#### 模板执行流程
-根据 `templates/tasks-template.md` 模板，AI Agent 执行以下流程：
-
-1. **加载计划文档**：从 `plan.md` 读取技术栈和架构信息
-2. **加载设计文档**：读取 `data-model.md`、`contracts/`、`research.md`
-3. **按类别生成任务**：
-   - 设置：项目初始化、依赖管理、代码规范
-   - 测试：契约测试、集成测试
-   - 核心：模型、服务、CLI 命令
-   - 集成：数据库、中间件、日志
-   - 完善：单元测试、性能、文档
-4. **应用任务规则**：
-   - 不同文件标记 `[P]` 并行执行
-   - 相同文件顺序执行
-   - 测试优先于实现（TDD）
-5. **任务编号**：按顺序编号（T001, T002...）
-6. **生成依赖图**：确定任务间依赖关系
-7. **创建并行示例**：展示可并行执行的任务组合
-8. **验证任务完整性**：确保所有契约、实体、端点都有对应任务
-
-### 6. `/analyze` 命令原理
-
-#### 背后流程
-当用户触发 `/analyze` 命令时：
-
-1. **脚本调用**：执行 `check-prerequisites.sh --require-tasks`
-2. **文档验证**：确保 `tasks.md` 和所有设计文档存在
-3. **一致性分析**：AI Agent 分析各文档间的一致性
-4. **覆盖度检查**：验证需求覆盖度和实现完整性
-5. **分析报告**：生成详细的分析报告
-
-#### 文档组织
-- **输入**：`spec.md` + `plan.md` + `tasks.md` + `constitution.md`
-- **模板**：无特定模板，使用 AI Agent 分析逻辑
-- **输出**：分析报告（文本形式）
-- **参考**：所有已生成的文档
-
-#### 技术实现
-```bash
-# check-prerequisites.sh --require-tasks 验证逻辑
-1. 检查 plan.md 存在
-2. 检查 tasks.md 存在（必需）
-3. 验证所有设计文档完整性
-4. 输出可用文档列表
-```
-
-#### 模板执行流程
-`/analyze` 命令没有特定模板，AI Agent 执行以下分析流程：
-
-1. **文档完整性检查**：验证所有必需文档存在且完整
-2. **一致性分析**：
-   - 规格与计划的一致性
-   - 计划与任务的一致性
-   - 任务与实现的一致性
-3. **覆盖度检查**：
-   - 功能需求覆盖度
-   - 测试覆盖度
-   - 实现覆盖度
-4. **质量评估**：
-   - 文档质量评估
-   - 架构合理性评估
-   - 可维护性评估
-5. **风险识别**：
-   - 技术风险识别
-   - 依赖风险识别
-   - 性能风险识别
-6. **建议生成**：基于分析结果生成改进建议
-7. **报告输出**：生成详细的分析报告
-
-### 7. `/implement` 命令原理
-
-#### 背后流程
-当用户触发 `/implement` 命令时：
-
-1. **脚本调用**：执行 `check-prerequisites.sh --require-tasks`
-2. **任务验证**：确保所有前置条件满足
-3. **任务执行**：AI Agent 按照 `tasks.md` 执行实现任务
-4. **代码生成**：生成源代码文件和测试文件
-5. **测试执行**：运行测试验证实现正确性
-
-#### 文档组织
-- **输入**：`tasks.md` + `plan.md` + `research.md` + `data-model.md` + `contracts/`
-- **模板**：无特定模板，基于任务列表执行
-- **输出**：源代码文件 + 测试文件
-- **参考**：所有设计文档和任务列表
-
-#### 技术实现
-```bash
-# check-prerequisites.sh --require-tasks 最终验证
-1. 验证所有前置条件
-2. 确保 tasks.md 存在且完整
-3. 验证所有设计文档可用
-4. 准备执行环境
-```
-
-#### 模板执行流程
-`/implement` 命令没有特定模板，AI Agent 执行以下实现流程：
-
-1. **任务解析**：读取 `tasks.md` 文件，解析所有任务
-2. **依赖分析**：分析任务间依赖关系，确定执行顺序
-3. **并行规划**：识别可并行执行的任务（标记 `[P]`）
-4. **顺序执行**：
-   - 按依赖顺序执行任务
-   - 优先执行测试任务（TDD）
-   - 然后执行实现任务
-5. **代码生成**：
-   - 根据任务描述生成源代码
-   - 创建测试文件
-   - 生成配置文件
-6. **测试执行**：
-   - 运行单元测试
-   - 运行集成测试
-   - 验证功能正确性
-7. **质量检查**：
-   - 代码规范检查
-   - 性能测试
-   - 安全检查
-8. **文档更新**：更新相关文档和注释
-
-## 核心设计原则
-
-### 1. 模板驱动
-- 每个命令都有对应的模板文件
-- 模板定义了文档结构和内容要求
-- AI Agent 根据模板生成标准化文档
-
-### 2. 脚本自动化
-- 每个命令都调用相应的脚本处理文件操作
-- 脚本负责目录创建、文件复制、路径验证等
-- 确保文件系统操作的一致性和可靠性
-
-### 3. 依赖管理
-- 命令之间有明确的依赖关系
-- 前置条件检查确保命令执行的正确顺序
-- 错误处理机制防止不完整的状态
-
-### 4. 上下文维护
-- AI Agent 上下文文件自动更新
-- 技术栈信息持续累积
-- 项目历史记录完整保存
-
-### 5. 并行优化
-- 任务标记 `[P]` 支持并行执行
-- 依赖分析确保执行顺序正确
-- 提高开发效率
-
-## 总结
-
-SpecKit 的命令系统通过精心设计的模板、脚本和文档组织，实现了从用户需求到代码实现的完整自动化流程。每个命令都有明确的职责和输出，通过依赖关系串联成完整的开发工作流。这种设计既保证了开发过程的结构化，又提供了足够的灵活性来适应不同的项目需求。
\ No newline at end of file
diff --git a/learn-spec-kit/agents-md-mechanism-guide.md b/learn-spec-kit/agents-md-mechanism-guide.md
deleted file mode 100644
index 6d4993b..0000000
--- a/learn-spec-kit/agents-md-mechanism-guide.md
+++ /dev/null
@@ -1,119 +0,0 @@
-# AGENTS.md 机制详解指南
-
-## 📖 背景与起源
-
-**AGENTS.md** 是专为 AI 编码代理（AI coding agents）设计的开放标准文件格式。随着 AI 编程助手的普及，开发者发现传统的 README.md 文件无法满足 AI 代理的特殊需求，因此需要一个专门的文件来为 AI 代理提供项目的详细上下文和具体指令。
-
-### 历史背景
-- **2023年兴起**：随着 ChatGPT、Claude、Copilot 等 AI 编程助手的广泛应用
-- **标准化需求**：不同 AI 代理需要统一的项目指导格式
-- **行业共识**：多家科技公司共同推动 AGENTS.md 成为行业标准
-- **开源社区支持**：得到 OpenAI、Google、Cursor 等公司的官方支持
-
-## 🎯 核心机制
-
-### 1. 设计理念
-- **专门化**：专门为 AI 代理设计，而非人类开发者
-- **标准化**：提供统一的文件格式和内容结构
-- **可预测性**：固定位置（项目根目录），AI 代理可快速定位
-- **结构化**：包含项目概述、构建指令、代码规范等关键信息
-
-### 2. 工作机制
-- **上下文提供**：为 AI 代理提供项目的完整技术上下文
-- **指令传递**：明确告知 AI 代理如何构建、测试、部署项目
-- **规范约束**：通过代码风格指南确保 AI 生成的代码符合项目标准
-- **安全指导**：通过安全注意事项防止 AI 代理执行危险操作
-
-## 🏗️ 标准结构
-
-### 基本格式
-AGENTS.md 文件通常包含以下核心部分：
-
-1. **项目概述**：项目的基本信息和目标
-2. **开发环境设置**：安装依赖、启动服务等命令
-3. **代码风格指南**：代码规范和要求
-4. **安全注意事项**：安全相关的注意事项
-5. **构建和部署**：构建、测试、部署相关指令
-
-### 与 README.md 的区别
-
-| 方面 | README.md | AGENTS.md |
-|------|-----------|-----------|
-| **目标受众** | 人类开发者 | AI 编码代理 |
-| **内容重点** | 项目介绍、使用说明 | 技术细节、操作指令 |
-| **详细程度** | 简洁明了 | 详细具体 |
-| **更新频率** | 相对稳定 | 随技术变化更新 |
-| **使用场景** | 项目展示、入门指导 | AI 代理协作、代码生成 |
-
-## 🔧 工作机制
-
-### 1. AI 代理的读取流程
-1. **文件定位**：AI 代理首先在项目根目录查找 AGENTS.md 文件
-2. **内容解析**：解析文件中的结构化信息，理解项目上下文
-3. **指令提取**：提取构建、测试、部署等具体操作指令
-4. **规范应用**：根据代码风格指南生成符合项目标准的代码
-5. **安全检查**：遵循安全注意事项，避免执行危险操作
-
-### 2. 与 AI 代理的交互模式
-- **上下文感知**：AI 代理基于 AGENTS.md 中的信息理解项目结构
-- **指令执行**：按照文件中的命令和流程执行开发任务
-- **规范遵循**：生成的代码符合项目定义的风格和标准
-- **安全约束**：避免执行可能危害项目安全的操作
-
-## 🚀 核心价值
-
-### 1. 提升 AI 代理效率
-- **减少理解时间**：AI 代理无需花费大量时间理解项目结构
-- **提高代码质量**：通过明确的代码风格指南确保一致性
-- **降低沟通成本**：减少人类开发者与 AI 代理的沟通成本
-- **标准化协作**：为 AI 代理提供统一的项目指导格式
-
-### 2. 项目治理优势
-- **职责分离**：README.md 面向人类开发者，AGENTS.md 面向 AI 代理
-- **保持简洁**：避免 README.md 变得冗长和复杂
-- **专业指导**：为 AI 代理提供专门的技术指导
-- **可预测性**：固定位置（项目根目录），AI 代理可快速定位
-
-## 🔍 与 SpecKit 的集成
-
-### SpecKit 中的 AGENTS.md 应用
-
-在 SpecKit 项目中，AGENTS.md 文件发挥了重要作用：
-
-#### 1. 多 AI 代理支持机制
-- **统一标准**：为不同 AI 代理提供统一的项目指导
-- **格式适配**：支持 Markdown、TOML 等不同格式
-- **目录结构**：为每个 AI 代理创建专门的目录结构
-- **命令生成**：自动生成符合各 AI 代理要求的命令文件
-
-#### 2. Spec-Driven Development 流程指导
-- **宪法建立**：指导 AI 代理创建项目宪法和治理文档
-- **规范制定**：帮助 AI 代理理解 SDD 工作流程
-- **任务分解**：指导 AI 代理进行任务分解和计划制定
-- **实施执行**：确保 AI 代理按照规范执行开发任务
-
-#### 3. 技术实现约束
-- **代码质量**：通过代码风格指南确保 AI 生成代码的质量
-- **安全约束**：通过安全注意事项防止 AI 代理执行危险操作
-- **测试要求**：指导 AI 代理编写和运行测试
-- **文档维护**：确保 AI 代理更新相关技术文档
-
-## 📚 进一步了解
-
-- **[AGENTS.md 官方标准](https://docs.factory.ai/factory-cli/configuration/agents-md)** - Factory AI 官方文档，了解 AGENTS.md 的完整规范
-
-## 🎯 总结
-
-AGENTS.md 机制代表了 AI 编程时代的重要创新，通过专门为 AI 编码代理设计的文件格式，实现了人类开发者与 AI 代理之间的高效协作。这一机制的核心价值在于：
-
-### 核心贡献
-1. **标准化协作**：为 AI 代理提供了统一的项目指导格式
-2. **效率提升**：显著减少了 AI 代理理解项目结构的时间
-3. **质量保证**：通过明确的规范约束确保代码质量
-4. **安全防护**：通过安全指导防止 AI 代理执行危险操作
-
-### 在 SpecKit 中的意义
-在 SpecKit 项目中，AGENTS.md 不仅支持了多 AI 代理的集成，还成为了 Spec-Driven Development 工作流程的重要组成部分，为 AI 代理提供了完整的项目上下文和操作指导。
-
-### 未来展望
-随着 AI 编程助手的不断发展，AGENTS.md 机制将继续演进，为开发者提供更加智能、高效的协作体验。
\ No newline at end of file
diff --git a/learn-spec-kit/cli-commands-reference.md b/learn-spec-kit/cli-commands-reference.md
deleted file mode 100644
index 6239381..0000000
--- a/learn-spec-kit/cli-commands-reference.md
+++ /dev/null
@@ -1,330 +0,0 @@
-# Spec-Kit CLI 命令参考
-
-## 概述
-
-Spec-Kit 提供了一个命令行工具 `specify`，用于创建和管理 spec-driven 开发项目。本文档详细说明了所有可用的命令和选项。
-
-## 安装和使用
-
-### 通过 uvx 使用（推荐）
-
-```bash
-# 初始化新项目
-uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>
-
-# 检查工具安装状态
-uvx --from git+https://github.com/github/spec-kit.git specify check
-```
-
-### 全局安装
-
-```bash
-# 安装到系统
-uv tool install --from git+https://github.com/github/spec-kit.git specify-cli
-
-# 使用命令
-specify init <PROJECT_NAME>
-specify check
-```
-
-## 命令列表
-
-### `specify init` - 初始化新项目
-
-创建新的 spec-driven 开发项目。
-
-#### 语法
-
-```bash
-specify init [PROJECT_NAME] [OPTIONS]
-```
-
-#### 参数
-
-- `PROJECT_NAME` (可选): 新项目的目录名称
-
-#### 选项
-
-| 选项 | 类型 | 默认值 | 描述 |
-|------|------|--------|------|
-| `--ai` | 字符串 | 交互选择 | 指定 AI 助手 (claude, gemini, copilot, cursor, qwen, opencode, windsurf, codex, kilocode, auggie, roo) |
-| `--script` | 字符串 | 自动检测 | 指定脚本类型 (sh, ps) |
-| `--ignore-agent-tools` | 布尔 | False | 跳过 AI 代理工具检查 |
-| `--no-git` | 布尔 | False | 跳过 Git 仓库初始化 |
-| `--here` | 布尔 | False | 在当前目录初始化项目 |
-| `--skip-tls` | 布尔 | False | 跳过 SSL/TLS 验证（不推荐） |
-| `--debug` | 布尔 | False | 显示详细的诊断输出 |
-
-#### 使用示例
-
-```bash
-# 基本用法 - 交互式选择 AI 助手
-specify init my-project
-
-# 指定 AI 助手
-specify init my-project --ai claude
-
-# 指定脚本类型
-specify init my-project --ai gemini --script sh
-
-# 在当前目录初始化
-specify init --here --ai copilot
-
-# 跳过 Git 初始化
-specify init my-project --no-git
-
-# 跳过工具检查
-specify init my-project --ignore-agent-tools
-
-# 调试模式
-specify init my-project --debug
-```
-
-#### 支持的 AI 助手
-
-1. **claude** - Claude Code
-   - 需要安装 Claude CLI
-   - 在 VS Code 中使用 `/` 命令
-
-2. **gemini** - Gemini CLI
-   - 需要安装 Gemini CLI
-   - 使用命令行工具
-
-3. **copilot** - GitHub Copilot
-   - 在 VS Code 中使用
-   - 支持 `/specify`, `/plan`, `/tasks` 命令
-
-4. **cursor** - Cursor IDE
-   - 在 Cursor 编辑器中使用
-   - 支持 AI 代理功能
-
-#### 支持的脚本类型
-
-1. **sh** - POSIX Shell (bash/zsh)
-   - 适用于 Unix-like 系统 (Linux, macOS)
-   - 默认在非 Windows 系统上
-
-2. **ps** - PowerShell
-   - 适用于 Windows 系统
-   - 默认在 Windows 系统上
-
-### `specify check` - 检查工具安装
-
-检查所有必需工具的安装状态。
-
-#### 语法
-
-```bash
-specify check
-```
-
-#### 功能
-
-- 检查 Git 版本控制工具
-- 检查 Claude CLI
-- 检查 Gemini CLI
-- 检查 VS Code（用于 GitHub Copilot）
-- 检查 Cursor IDE 代理（可选）
-
-#### 输出示例
-
-```
-███████╗██████╗ ███████╗ ██████╗██╗███████╗██╗   ██╗
-██╔════╝██╔══██╗██╔════╝██╔════╝██║██╔════╝╚██╗ ██╔╝
-███████╗██████╔╝█████╗  ██║     ██║█████╗   ╚████╔╝ 
-╚════██║██╔═══╝ ██╔══╝  ██║     ██║██╔══╝    ╚██╔╝  
-███████║██║     ███████╗╚██████╗██║██║        ██║   
-╚══════╝╚═╝     ╚══════╝ ╚═════╝╚═╝╚═╝        ╚═╝   
-
-Spec-Driven Development Toolkit
-
-Check Available Tools
-├─ ● git: Git version control (available)
-├─ ● claude: Claude Code CLI (available)
-├─ ○ gemini: Gemini CLI (not found - Install from: https://github.com/google-gemini/gemini-cli)
-├─ ● code: VS Code (for GitHub Copilot) (available)
-└─ ○ cursor-agent: Cursor IDE agent (optional) (not found - Install from: https://cursor.sh/)
-
-Specify CLI is ready to use!
-```
-
-## 交互式界面
-
-### AI 助手选择
-
-当未指定 `--ai` 选项时，工具会显示交互式选择菜单：
-
-```
-Choose your AI assistant:
-▶ copilot: GitHub Copilot
-  claude: Claude Code
-  gemini: Gemini CLI
-  cursor: Cursor
-  qwen: Qwen Code
-  opencode: opencode
-  windsurf: Windsurf
-  codex: Codex CLI
-  kilocode: Kilo Code
-  auggie: Auggie CLI
-  roo: Roo Code
-
-Use ↑/↓ to navigate, Enter to select, Esc to cancel
-```
-
-### 脚本类型选择
-
-当未指定 `--script` 选项时，工具会根据操作系统自动选择默认值，或在交互模式下提供选择：
-
-```
-Choose script type (or press Enter):
-▶ sh: POSIX Shell (bash/zsh)
-  ps: PowerShell
-
-Use ↑/↓ to navigate, Enter to select, Esc to cancel
-```
-
-## 项目初始化流程
-
-### 1. 参数验证
-
-- 检查项目名称和 `--here` 标志的互斥性
-- 验证 AI 助手和脚本类型选择
-
-### 2. 工具检查
-
-- 检查 Git 是否安装（除非使用 `--no-git`）
-- 检查所选 AI 助手的必需工具（除非使用 `--ignore-agent-tools`）
-
-### 3. 模板下载
-
-- 从 GitHub API 获取最新发布信息
-- 根据 AI 助手和脚本类型下载对应模板
-- 显示下载进度
-
-### 4. 项目创建
-
-- 创建项目目录（除非使用 `--here`）
-- 解压模板文件
-- 设置脚本执行权限
-- 初始化 Git 仓库（除非使用 `--no-git`）
-
-### 5. 完成提示
-
-显示项目创建完成信息和后续步骤指导。
-
-## 错误处理
-
-### 常见错误
-
-1. **目录已存在**
-   ```
-   Error: Directory 'my-project' already exists
-   ```
-
-2. **AI 工具未安装**
-   ```
-   Error: Claude CLI is required for Claude Code projects
-   Required AI tool is missing!
-   Tip: Use --ignore-agent-tools to skip this check
-   ```
-
-3. **网络连接问题**
-   ```
-   Error fetching release information
-   ```
-
-### 调试模式
-
-使用 `--debug` 选项获取详细的诊断信息：
-
-```bash
-specify init my-project --debug
-```
-
-调试信息包括：
-- Python 版本
-- 平台信息
-- 当前工作目录
-- 网络请求详情
-- 文件提取详情
-
-## 最佳实践
-
-### 1. 项目命名
-
-- 使用小写字母和连字符
-- 避免空格和特殊字符
-- 选择描述性的名称
-
-### 2. AI 助手选择
-
-- **Claude Code**: 适合 VS Code 用户，功能最全面
-- **Gemini CLI**: 适合命令行用户
-- **GitHub Copilot**: 适合已有 Copilot 订阅的用户
-- **Cursor**: 适合使用 Cursor 编辑器的用户
-
-### 3. 脚本类型
-
-- 通常使用默认选择即可
-- Windows 用户可能需要手动选择 PowerShell
-- Unix-like 系统用户使用 Bash
-
-### 4. Git 集成
-
-- 建议保持 Git 初始化（默认行为）
-- 使用 `--no-git` 仅在特殊情况下
-- 确保 Git 已正确配置用户信息
-
-## 故障排除
-
-### 1. 权限问题
-
-```bash
-# 确保脚本有执行权限
-chmod +x .specify/scripts/**/*.sh
-```
-
-### 2. 网络问题
-
-```bash
-# 使用调试模式查看网络详情
-specify init my-project --debug
-
-# 跳过 TLS 验证（不推荐）
-specify init my-project --skip-tls
-```
-
-### 3. 工具检查
-
-```bash
-# 检查所有工具状态
-specify check
-
-# 跳过工具检查
-specify init my-project --ignore-agent-tools
-```
-
-### 4. 清理和重试
-
-```bash
-# 删除失败的项目目录
-rm -rf my-project
-
-# 重新初始化
-specify init my-project
-```
-
-## 更新和维护
-
-### 检查更新
-
-```bash
-# 使用最新版本
-uvx --from git+https://github.com/github/spec-kit.git specify check
-```
-
-### 版本兼容性
-
-- 需要 Python 3.11 或更高版本
-- 支持最新的 uv 工具
-- 兼容主流操作系统
diff --git a/learn-spec-kit/constitution-architecture-guide.md b/learn-spec-kit/constitution-architecture-guide.md
deleted file mode 100644
index ab32d13..0000000
--- a/learn-spec-kit/constitution-architecture-guide.md
+++ /dev/null
@@ -1,329 +0,0 @@
-# Constitution 架构指南
-
-## 概述
-
-Constitution（宪法）是 spec-kit 项目的核心治理文档，定义了项目的非协商性原则和开发规范。本指南详细解释 Constitution 在整个 spec-driven 开发流程中的作用、架构设计以及如何正确使用它来指导项目开发。
-
-## Constitution 的核心作用
-
-### 1. 架构约束和原则定义
-
-Constitution 定义了 7 个核心开发原则，这些原则是不可协商的：
-
-#### Article I: Library-First（库优先）
-- 每个功能都必须从独立库开始
-- 库必须自包含、独立可测试、有文档
-- 需要明确目的，不允许仅组织性的库
-
-#### Article II: CLI Interface（CLI 接口）
-- 每个库都必须通过 CLI 暴露功能
-- 文本输入/输出协议：stdin/args → stdout，错误 → stderr
-- 支持 JSON 和人类可读格式
-
-#### Article III: Test-First（测试优先，不可协商）
-- TDD 强制要求：测试编写 → 用户批准 → 测试失败 → 然后实现
-- 严格执行红-绿-重构循环
-
-#### Article IV: Integration Testing（集成测试）
-- 需要集成测试的重点领域：
-  - 新库合约测试
-  - 合约变更
-  - 服务间通信
-  - 共享模式
-
-#### Article V: Observability（可观测性）
-- 文本 I/O 确保可调试性
-- 需要结构化日志记录
-
-#### Article VI: Versioning & Breaking Changes（版本控制和破坏性变更）
-- MAJOR.MINOR.BUILD 格式
-- 破坏性变更需要并行测试和迁移计划
-
-#### Article VII: Simplicity（简洁性）
-- 遵循 YAGNI 原则
-- 限制项目数量（最多 3 个）
-- 避免不必要的模式
-
-### 2. 工作流程中的质量门控
-
-Constitution 在 spec-kit 的工作流程中作为**质量门控**：
-
-#### 计划阶段检查
-在 `/templates/plan-template.md` 中，Constitution Check 是一个强制检查点：
-
-```markdown
-## Constitution Check
-*GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*
-
-**Simplicity**:
-- Projects: [#] (max 3 - e.g., api, cli, tests)
-- Using framework directly? (no wrapper classes)
-- Single data model? (no DTOs unless serialization differs)
-
-**Architecture**:
-- EVERY feature as library? (no direct app code)
-- Libraries listed: [name + purpose for each]
-- CLI per library: [commands with --help/--version/--format]
-
-**Testing (NON-NEGOTIABLE)**:
-- RED-GREEN-Refactor cycle enforced? (test MUST fail first)
-- Git commits show tests before implementation?
-- Order: Contract→Integration→E2E→Unit strictly followed?
-```
-
-#### 设计阶段重新评估
-在 Phase 1 完成后会重新评估 Constitution 合规性，如果发现新的违规行为，会要求重构设计。
-
-### 3. 模板系统的指导原则
-
-Constitution 直接影响所有模板的内容：
-
-- **plan-template.md**：包含 Constitution Check 部分，验证设计是否符合原则
-- **tasks-template.md**：任务生成遵循 TDD 和库优先原则
-- **spec-template.md**：规范生成符合宪法要求
-
-### 4. AI 助手的指导
-
-Constitution 为 AI 助手提供明确的开发指导：
-
-```markdown
-3. Read the constitution at `/memory/constitution.md` to understand constitutional requirements.
-```
-
-这确保 AI 生成的所有实现都符合宪法原则，提供明确的决策框架。
-
-## 技术栈特定规范的正确位置
-
-### 问题：技术规范应该放在哪里？
-
-当团队有特定的技术栈要求（如 iOS 开发必须使用 SwiftUI + View-Model 架构）时，这些规范应该放在哪里？
-
-### 答案：分层架构
-
-根据 spec-kit 的设计思路，应该采用分层架构：
-
-#### 1. 宪法层面（Constitution）- ❌ 不适合
-宪法应该保持**技术栈无关**的通用原则：
-
-```markdown
-## Constitution Check
-**Architecture**:
-- EVERY feature as library? (no direct app code)
-- Libraries listed: [name + purpose for each]
-- CLI per library: [commands with --help/--version/--format]
-```
-
-宪法关注的是**架构原则**，而不是具体的技术实现。
-
-#### 2. 技术上下文层面（Technical Context）- ✅ 主要位置
-在 `plan-template.md` 的 Technical Context 部分：
-
-```markdown
-## Technical Context
-**Language/Version**: Swift 5.9
-**Primary Dependencies**: SwiftUI, Combine
-**Target Platform**: iOS 15+
-**Project Type**: mobile
-```
-
-这里可以包含技术栈选择，但**不包含具体的开发规范细节**。
-
-#### 3. Agent 文件层面 - ✅ 最佳位置
-在 `agent-file-template.md` 中：
-
-```markdown
-## Active Technologies
-- Swift 5.9
-- SwiftUI
-- Combine
-
-## Code Style
-- SwiftUI + View-Model 架构
-- 必须使用 SwiftUI 进行 UI 开发
-- 必须采用 View-Model 原生架构
-- 禁止使用 UIKit 进行新功能开发
-- ViewModel 必须继承自 ObservableObject
-- 使用 @Published 属性包装器
-- 遵循 MVVM 模式
-```
-
-#### 4. 项目特定文档 - ✅ 补充位置
-创建 `ios-development-standards.md`：
-
-```markdown
-# iOS 开发规范
-
-## 架构要求
-- 必须使用 SwiftUI + Swift
-- 必须采用 View-Model 原生架构
-- 禁止使用 UIKit 进行新功能开发
-
-## 具体实现规范
-- ViewModel 必须继承自 ObservableObject
-- 使用 @Published 属性包装器
-- 遵循 MVVM 模式
-- 网络请求使用 Combine
-- 数据持久化使用 Core Data 或 SwiftData
-```
-
-## 推荐的完整方案
-
-### 1. 宪法保持通用性
-```markdown
-# Constitution
-## Core Principles
-### Article I: Library-First
-### Article II: CLI Interface  
-### Article III: Test-First
-### Article IV: Integration Testing
-### Article V: Observability
-### Article VI: Versioning
-### Article VII: Simplicity
-```
-
-### 2. 技术上下文指定技术栈
-```markdown
-## Technical Context
-**Language/Version**: Swift 5.9
-**Primary Dependencies**: SwiftUI, Combine, SwiftData
-**Target Platform**: iOS 15+
-**Project Type**: mobile
-**Architecture**: MVVM with SwiftUI
-```
-
-### 3. Agent 文件包含具体规范
-```markdown
-# iOS Development Guidelines
-
-## Architecture Requirements
-- MUST use SwiftUI for all UI development
-- MUST follow View-Model pattern
-- MUST use ObservableObject for ViewModels
-- MUST use @Published for reactive properties
-- FORBIDDEN: UIKit for new features
-
-## Code Style
-- ViewModels inherit from ObservableObject
-- Use @Published for reactive properties
-- Use Combine for networking
-- Use SwiftData for persistence
-```
-
-### 4. 项目文档补充细节
-创建 `docs/ios-standards.md` 包含详细的实现规范、代码示例、最佳实践等。
-
-## 为什么这样分层？
-
-### 1. 宪法保持稳定性
-技术栈可能变化，但架构原则不变。宪法应该关注通用的开发原则，而不是具体的技术实现。
-
-### 2. 技术上下文提供约束
-告诉 AI 使用什么技术栈，但不包含具体的实现细节。
-
-### 3. Agent 文件提供具体指导
-告诉 AI 如何正确使用这些技术，包含具体的开发规范。
-
-### 4. 项目文档提供细节
-供开发者参考具体实现，包含代码示例和最佳实践。
-
-## 治理和一致性维护
-
-### 版本控制
-Constitution 有版本号，变更需要文档化：
-
-```markdown
-**Version**: [CONSTITUTION_VERSION] | **Ratified**: [RATIFICATION_DATE] | **Last Amended**: [LAST_AMENDED_DATE]
-```
-
-### 更新检查清单
-通过 `/constitution` 命令确保所有相关文档同步更新：
-
-```markdown
-## Templates to Update
-### When adding/modifying ANY article:
-- [ ] `/templates/plan-template.md` - Update Constitution Check section
-- [ ] `/templates/spec-template.md` - Update if requirements/scope affected
-- [ ] `/templates/tasks-template.md` - Update if new task types needed
-```
-
-### 模板同步
-确保所有模板都反映最新的宪法要求，维护项目的一致性。
-
-## 质量保证机制
-
-### 错误处理
-如果违反宪法原则且无法合理证明，会触发 ERROR 状态：
-
-```markdown
-→ If violations exist: Document in Complexity Tracking
-→ If no justification possible: ERROR "Simplify approach first"
-```
-
-### 强制简化
-Constitution 强制简化复杂的设计，确保生成的代码具有一致性和可维护性。
-
-### 复杂度跟踪
-对于必须的违规行为，需要在 Complexity Tracking 中记录：
-
-```markdown
-## Complexity Tracking
-| Violation | Why Needed | Simpler Alternative Rejected Because |
-|-----------|------------|-------------------------------------|
-| [e.g., 4th project] | [current need] | [why 3 projects insufficient] |
-```
-
-## 实际应用示例
-
-### 场景：iOS 应用开发
-当开发 iOS 应用时：
-
-1. **宪法层面**：确保功能作为独立库开发，遵循 TDD
-2. **技术上下文**：指定 Swift 5.9 + SwiftUI
-3. **Agent 文件**：包含 SwiftUI + View-Model 架构要求
-4. **项目文档**：详细的 iOS 开发规范和代码示例
-
-### 场景：Web 应用开发
-当开发 Web 应用时：
-
-1. **宪法层面**：同样的架构原则
-2. **技术上下文**：指定 React + Node.js
-3. **Agent 文件**：包含 React 组件规范和 API 设计原则
-4. **项目文档**：Web 开发最佳实践
-
-## 最佳实践
-
-### 1. 保持宪法的通用性
-- 不要将技术栈特定的规范写入宪法
-- 关注架构原则，而不是具体实现
-- 确保宪法在技术栈变化时仍然有效
-
-### 2. 合理分层
-- 技术栈选择放在 Technical Context
-- 具体规范放在 Agent 文件
-- 详细实现放在项目文档
-
-### 3. 维护一致性
-- 使用更新检查清单确保同步
-- 定期验证模板与宪法的一致性
-- 记录版本变更和修改原因
-
-### 4. 强制执行
-- 在关键检查点验证宪法合规性
-- 对违规行为进行适当的错误处理
-- 记录必要的复杂度偏差
-
-## 总结
-
-Constitution 在 spec-kit 中不仅仅是文档，而是整个 spec-driven 开发流程的**核心治理机制**。它通过定义不可协商的原则、提供质量检查点、指导模板生成、强制执行开发规范等方式，确保整个项目保持一致性、简洁性和高质量。
-
-对于技术栈特定的规范，应该采用分层架构：
-- **宪法**：保持通用性和稳定性
-- **技术上下文**：指定技术栈
-- **Agent 文件**：包含具体规范
-- **项目文档**：提供实现细节
-
-这样的分层确保了 Constitution 作为项目治理核心的有效性，同时为不同层次的技术规范提供了合适的位置。它是 spec-kit 实现"规范驱动开发"理念的关键基础设施。
-
----
-
-*本指南基于 spec-kit Constitution v2.1.1 和实际项目经验编写。*
diff --git a/learn-spec-kit/installation-and-quickstart.md b/learn-spec-kit/installation-and-quickstart.md
deleted file mode 100644
index 70aa22d..0000000
--- a/learn-spec-kit/installation-and-quickstart.md
+++ /dev/null
@@ -1,108 +0,0 @@
-# 安装和快速开始指南
-
-## 概述
-
-本指南将帮助您快速安装 SpecKit 并创建第一个规范驱动开发项目。SpecKit 通过标准化的项目结构和 AI 助手集成，实现"规范优先"的开发模式。
-
-## 环境要求
-
-- **操作系统**: Windows 10+, macOS 10.15+, Linux (Ubuntu 18.04+)
-- **Python**: 3.11 或更高版本
-- **网络**: 需要访问 GitHub 和 AI 服务
-
-## 支持的 AI 助手
-
-SpecKit 支持 Claude Code、GitHub Copilot、Gemini CLI、Cursor 等
-
-**详细信息**: 请参考项目根目录的 [README.md](../README.md) 获取完整的Agent支持列表。
-
-## 安装 SpecKit
-
-### 新项目安装
-```bash
-# 创建新项目
-uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>
-```
-
-### 已有项目安装
-```bash
-# 在当前目录初始化
-uvx --from git+https://github.com/github/spec-kit.git specify init --here
-```
-
-**详细信息**: 请参考项目根目录的 [README.md](../README.md) 获取完整的安装指南。
-
-## 基本使用
-
-### 项目结构
-创建成功后，您将看到以下项目结构：
-
-```
-my-project/
-├── .specify/                   # SpecKit 核心配置
-│   ├── memory/                 # 项目记忆和宪法
-│   ├── scripts/                # 自动化脚本
-│   └── templates/              # 文档模板
-└── .claude/                    # AI 助手配置（根据选择的助手）
-    └── commands/               # 命令模板
-```
-
-### 基本命令
-在您的 AI 助手中，您将看到以下命令可用：
-
-1. `/constitution` - 创建项目原则和开发指南
-2. `/specify` - 定义要构建的内容（需求和用户故事）
-3. `/clarify` - 澄清不明确的区域
-4. `/plan` - 创建技术实现计划
-5. `/tasks` - 生成可执行的任务列表
-6. `/analyze` - 跨工件一致性和覆盖率分析
-7. `/implement` - 执行所有任务来构建功能
-
-## 基本使用流程
-
-### 1. 进入项目目录
-```bash
-cd my-project
-```
-
-### 2. 开始规范驱动开发
-
-在您的 AI 助手中按顺序使用以下命令：
-
-注意：constitution、clarify、analyze 在体验时可选择跳过
-
-```
-/constitution 创建专注于代码质量、测试标准、用户体验一致性和性能要求的原则
-/specify 构建一个可以帮助我整理照片的应用程序
-/clarify 澄清不明确的区域
-/plan 使用 Vite 和最少库数量的技术栈
-/tasks 生成可执行的任务列表
-/analyze 分析一致性
-/implement 执行所有任务来构建功能
-```
-
-**详细信息**: 请参考项目根目录的 [README.md](../README.md) 获取完整的使用指南。
-
-### 3. 查看生成的内容
-
-SpecKit 会根据命令生成相应的文档：
-
-- **`/constitution`**: 生成 `memory/constitution.md` - 项目原则和开发指南
-- **`/specify`**: 生成 `specs/001-功能名称/spec.md` - 功能规范文档
-- **`/plan`**: 生成多个文档：
-  - `specs/001-功能名称/plan.md` - 技术实现计划
-  - `specs/001-功能名称/research.md` - 技术研究文档
-  - `specs/001-功能名称/data-model.md` - 数据模型
-  - `specs/001-功能名称/quickstart.md` - 快速开始指南
-  - `specs/001-功能名称/contracts/` - API 合约文档
-- **`/tasks`**: 生成 `specs/001-功能名称/tasks.md` - 可执行任务列表
-- **`/implement`**: 执行任务并生成实际代码文件
-
-## 下一步学习
-
-现在您已经成功安装了 SpecKit 并创建了第一个项目，接下来可以：
-
-1. **深入学习**: 阅读 [SpecKit 命令详解](./speckit-commands-guide.md) 了解各个命令的详细用法
-2. **理解原理**: 学习 [SpecKit 命令原理](./speckit-commands-principles.md) 了解背后的工作机制
-3. **实战应用**: 参考 [实际项目开发流程指南](./practical-workflow-guide.md) 进行实际项目开发
-4. **深入技术**: 学习 [SpecKit 工程化原理](./speckit-engineering-principles.md) 了解技术实现
diff --git a/learn-spec-kit/memory-documents-guide.md b/learn-spec-kit/memory-documents-guide.md
deleted file mode 100644
index edfbdd0..0000000
--- a/learn-spec-kit/memory-documents-guide.md
+++ /dev/null
@@ -1,290 +0,0 @@
-# Memory 文档系统指南
-
-## 概述
-
-Memory 目录是 spec-kit 项目的核心记忆系统，包含了项目的"宪法"和治理文档。这些文档定义了项目的非协商性原则、开发规范和治理规则，为整个 spec-driven 开发流程提供指导。
-
-## 目录结构
-
-```
-memory/
-└── constitution.md                    # 项目宪法 - 核心原则和规范
-```
-
-## 核心文档详解
-
-### 1. constitution.md - 项目宪法
-
-**作用**: 定义项目的核心原则和不可协商的开发规范。
-
-#### 文档结构
-
-```markdown
-# [PROJECT_NAME] Constitution
-
-## Core Principles
-### [PRINCIPLE_1_NAME] - 核心原则1
-### [PRINCIPLE_2_NAME] - 核心原则2
-### [PRINCIPLE_3_NAME] - 核心原则3
-### [PRINCIPLE_4_NAME] - 核心原则4
-### [PRINCIPLE_5_NAME] - 核心原则5
-
-## [SECTION_2_NAME] - 附加约束
-## [SECTION_3_NAME] - 开发工作流
-## Governance - 治理规则
-```
-
-#### 核心原则模板
-
-文档提供了7个核心原则的模板结构：
-
-1. **原则1 - Library-First（库优先）**
-   - 每个功能都从独立库开始
-   - 库必须自包含、独立可测试、有文档
-   - 需要明确目的，不允许仅组织性的库
-
-2. **原则2 - CLI Interface（CLI 接口）**
-   - 每个库都通过 CLI 暴露功能
-   - 文本输入/输出协议：stdin/args → stdout，错误 → stderr
-   - 支持 JSON 和人类可读格式
-
-3. **原则3 - Test-First（测试优先，不可协商）**
-   - TDD 强制要求：测试编写 → 用户批准 → 测试失败 → 然后实现
-   - 严格执行红-绿-重构循环
-
-4. **原则4 - Integration Testing（集成测试）**
-   - 需要集成测试的重点领域：
-     - 新库合约测试
-     - 合约变更
-     - 服务间通信
-     - 共享模式
-
-5. **原则5 - Observability（可观测性）**
-   - 文本 I/O 确保可调试性
-   - 需要结构化日志记录
-
-6. **原则6 - Versioning & Breaking Changes（版本控制和破坏性变更）**
-   - MAJOR.MINOR.BUILD 格式
-   - 破坏性变更需要迁移计划
-
-7. **原则7 - Simplicity（简洁性）**
-   - 从简单开始，遵循 YAGNI 原则
-   - 避免过度设计
-
-#### 治理规则
-
-- **宪法至上**: 宪法超越所有其他实践
-- **修订要求**: 修订需要文档、批准、迁移计划
-- **合规验证**: 所有 PR/审查必须验证合规性
-- **复杂性证明**: 复杂性必须被证明合理
-
-#### 版本信息
-
-```markdown
-**Version**: [CONSTITUTION_VERSION] | **Ratified**: [RATIFICATION_DATE] | **Last Amended**: [LAST_AMENDED_DATE]
-```
-
-### 2. 宪法更新机制
-
-**作用**: 通过 `/constitution` 命令创建或更新项目宪法，确保宪法内容的完整性和一致性。
-
-#### 主要功能
-
-1. **宪法内容管理**
-   - 基于模板创建或更新宪法文件
-   - 自动填充占位符和版本信息
-   - 确保宪法结构的完整性
-
-2. **版本控制**
-   - 自动管理宪法版本号
-   - 记录批准和修订日期
-   - 维护宪法变更历史
-
-#### 宪法更新流程
-
-##### 1. 使用 `/constitution` 命令
-
-**命令执行**:
-- 加载现有宪法模板
-- 识别所有占位符标记
-- 收集或推导具体值
-- 填充模板内容
-
-##### 2. 版本管理
-
-**版本号规则**:
-- MAJOR: 向后不兼容的治理/原则移除或重新定义
-- MINOR: 新增原则/部分或实质性扩展指导
-- PATCH: 澄清、措辞、拼写修复、非语义性改进
-
-##### 3. 内容验证
-
-**宪法内容检查**:
-- 所有占位符都被替换
-- 版本行匹配报告
-- 日期格式正确 (YYYY-MM-DD)
-- 原则声明明确、可测试
-
-##### 4. 同步影响报告
-
-**自动生成报告**:
-- 版本变更: 旧版本 → 新版本
-- 修改的原则列表
-- 新增/移除的部分
-- 需要更新的模板文件
-
-## 使用工作流
-
-### 1. 项目初始化
-
-当创建新项目时：
-
-1. **复制宪法模板**:
-   ```bash
-   # 通过 /constitution 命令创建宪法文件
-   ```
-
-2. **自定义宪法内容**:
-   - 替换 `[PROJECT_NAME]` 为实际项目名称
-   - 填写具体的核心原则描述
-   - 添加项目特定的约束和工作流
-
-3. **设置版本信息**:
-   - 设置初始版本号
-   - 记录批准日期
-   - 建立修订历史
-
-### 2. 宪法修订流程
-
-当需要修改宪法时：
-
-1. **准备修订**:
-   - 明确修订原因和目标
-   - 评估对现有项目的影响
-   - 准备迁移计划
-
-2. **执行更新检查清单**:
-   - 使用 `/constitution` 命令进行宪法更新
-   - 更新所有相关模板
-   - 验证一致性
-
-3. **测试和验证**:
-   - 运行示例实现计划
-   - 确保所有要求都得到满足
-   - 检查文档间的一致性
-
-4. **提交和记录**:
-   - 更新版本号
-   - 记录修订日期
-   - 更新同步状态
-
-### 3. 日常使用
-
-在开发过程中：
-
-1. **参考宪法原则**:
-   - 在编写规范时遵循核心原则
-   - 在制定计划时考虑宪法要求
-   - 在生成任务时应用治理规则
-
-2. **合规检查**:
-   - 确保所有 PR 符合宪法要求
-   - 在代码审查中验证合规性
-   - 定期检查模板同步状态
-
-## 最佳实践
-
-### 1. 宪法设计
-
-- **保持简洁**: 原则应该清晰、简洁、易于理解
-- **避免冲突**: 确保原则之间没有矛盾
-- **考虑实用性**: 原则应该能够实际执行
-- **版本控制**: 使用语义化版本控制
-
-### 2. 更新管理
-
-- **渐进式更新**: 避免大幅修改，采用渐进式更新
-- **影响评估**: 每次更新前评估对现有项目的影响
-- **文档同步**: 确保所有相关文档保持同步
-- **测试验证**: 更新后通过实际项目验证
-
-### 3. 团队协作
-
-- **明确沟通**: 宪法变更需要团队明确沟通
-- **培训支持**: 为新原则提供培训和文档
-- **反馈机制**: 建立反馈机制收集使用体验
-- **定期审查**: 定期审查宪法的有效性和适用性
-
-## 与其他系统的集成
-
-### 1. 模板系统
-
-宪法与模板系统紧密集成：
-- 所有模板都引用宪法原则
-- 模板更新需要同步宪法变更
-- 宪法变更需要更新相关模板
-
-### 2. 脚本系统
-
-脚本系统帮助执行宪法要求：
-- `update-agent-context.sh` 可以更新宪法引用
-- 脚本可以验证宪法合规性
-- 自动化工具可以检查同步状态
-
-### 3. AI 代理系统
-
-AI 代理使用宪法作为指导：
-- Claude Code 通过 `CLAUDE.md` 引用宪法
-- Gemini CLI 通过 `GEMINI.md` 应用宪法原则
-- GitHub Copilot 通过指令文件遵循宪法
-
-## 故障排除
-
-### 常见问题
-
-1. **宪法与模板不同步**:
-   - 使用检查清单逐步同步
-   - 检查版本号是否一致
-   - 验证所有引用是否正确
-
-2. **原则冲突**:
-   - 重新审视原则的优先级
-   - 考虑合并或重新表述
-   - 寻求团队共识
-
-3. **执行困难**:
-   - 检查原则是否过于复杂
-   - 考虑提供更多指导文档
-   - 简化或分解复杂原则
-
-### 维护建议
-
-1. **定期审查**: 每季度审查宪法的有效性
-2. **版本管理**: 使用语义化版本控制
-3. **文档同步**: 建立自动化检查机制
-4. **团队培训**: 定期培训团队使用宪法
-
-## 扩展和自定义
-
-### 1. 添加新原则
-
-1. 在宪法中添加新原则
-2. 更新检查清单
-3. 修改相关模板
-4. 更新 AI 代理指令
-
-### 2. 领域特定定制
-
-不同项目类型可能需要不同的宪法：
-- **Web 项目**: 强调 API 设计和前端集成
-- **CLI 工具**: 强调命令行接口和用户体验
-- **库项目**: 强调 API 稳定性和文档
-
-### 3. 组织级宪法
-
-大型组织可以建立组织级宪法：
-- 定义跨项目的通用原则
-- 建立项目间的一致性标准
-- 提供共享的治理框架
-
-Memory 文档系统是 spec-kit 项目的核心治理机制，通过宪法和检查清单确保项目的一致性和质量。正确使用这些文档可以显著提高开发效率和代码质量。
diff --git a/learn-spec-kit/practical-workflow-guide.md b/learn-spec-kit/practical-workflow-guide.md
deleted file mode 100644
index 754495e..0000000
--- a/learn-spec-kit/practical-workflow-guide.md
+++ /dev/null
@@ -1,426 +0,0 @@
-# 实际项目开发流程指南 - Cursor 实战
-
-## 概述
-
-本指南以 Cursor 编辑器为环境，通过一个完整的项目开发实例，详细说明 spec-kit 项目中各个脚本和 MD 文档是如何协同工作的。我们将从项目初始化开始，逐步展示整个 spec-driven 开发流程。
-
-**注意**: 本指南以核心命令 /specify /plan /tasks 的协同工作机制为重点，其他命令建议大家有实践经验后带着问题试用。
-**注意**: 本指南基于 `--ai cursor` 参数创建的项目，因此只包含 Bash 脚本版本，不包含 PowerShell 脚本。
-
-## 项目背景
-
-假设我们要开发一个"用户认证系统"功能，这是一个典型的 Web 应用功能，包含用户注册、登录、密码重置等核心功能。
-
-## 完整开发流程
-
-### 阶段 1: 项目初始化
-
-#### 1.1 使用 uvx 创建项目
-
-```bash
-# 在 Cursor 终端中执行
-uvx --from git+https://github.com/github/spec-kit.git specify init user-auth-system --ai cursor
-```
-
-**执行过程**:
-1. `uvx` 从 GitHub 下载 spec-kit 项目
-2. 解析 `pyproject.toml` 配置
-3. 调用 `specify_cli:main` 函数
-4. 执行 `init` 命令，创建项目结构
-
-**生成的文件结构**:
-```
-user-auth-system/
-├── .specify/
-│   ├── memory/
-│   │   ├── constitution.md
-│   ├── scripts/
-│   │   └── bash/
-│   │       ├── common.sh
-│   │       ├── create-new-feature.sh
-│   │       ├── setup-plan.sh
-│   │       └── update-agent-context.sh
-│   └── templates/
-│       ├── spec-template.md
-│       ├── plan-template.md
-│       ├── tasks-template.md
-│       └── agent-file-template.md
-└── .cursor/
-    └── commands/
-        ├── analyze.md
-        ├── clarify.md
-        ├── constitution.md
-        ├── implement.md
-        ├── plan.md
-        ├── specify.md
-        └── tasks.md
-```
-
-#### 1.2 进入项目目录
-
-```bash
-cd user-auth-system
-```
-
-### 阶段 2: 功能规范创建
-
-#### 2.1 在 Cursor 中使用 /specify 命令
-
-在 Cursor 编辑器中，我们使用 `/specify` 命令来创建功能规范：
-
-```
-/specify 用户认证系统，包含用户注册、登录、密码重置功能，支持邮箱验证和 JWT 令牌
-```
-
-**Cursor 内部执行流程**:
-
-1. **命令解析**: Cursor 识别 `/specify` 命令
-2. **脚本调用**: 执行 `.specify/scripts/bash/create-new-feature.sh`
-3. **分支创建**: 创建 `001-user-authentication` 分支
-4. **目录结构**: 在 `specs/001-user-authentication/` 创建功能目录
-5. **模板复制**: 从 `.specify/templates/spec-template.md` 复制到 `spec.md`
-
-#### 2.2 脚本协同工作
-
-**`.specify/scripts/bash/create-new-feature.sh` 执行过程**:
-
-```bash
-# 1. 解析参数并生成分支名称
-BRANCH_NAME="001-user-authentication"
-
-# 2. 创建分支和目录结构
-git checkout -b "$BRANCH_NAME"
-mkdir -p "specs/$BRANCH_NAME"
-
-# 3. 复制规范模板
-cp ".specify/templates/spec-template.md" "specs/$BRANCH_NAME/spec.md"
-```
-
-**生成的文件**:
-```
-specs/001-user-authentication/
-└── spec.md  # 基于 spec-template.md 创建
-```
-
-#### 2.3 AI 代理填充规范内容
-
-Cursor 的 AI 代理读取 `templates/spec-template.md` 并填充内容：
-
-**`spec.md` 内容示例**:
-```markdown
-# Feature Specification: 用户认证系统
-
-## User Scenarios & Testing
-### Primary User Story
-用户需要能够注册新账户、登录系统、重置密码，并接收邮箱验证。
-
-### Acceptance Scenarios
-1. **Given** 用户访问注册页面, **When** 输入有效邮箱和密码, **Then** 系统创建账户并发送验证邮件
-2. **Given** 用户有有效账户, **When** 输入正确凭据, **Then** 系统返回 JWT 令牌
-
-## Requirements
-### Functional Requirements
-- **FR-001**: 系统必须允许用户使用邮箱和密码注册账户
-- **FR-002**: 系统必须验证邮箱格式的有效性
-- **FR-003**: 系统必须发送邮箱验证邮件
-- **FR-004**: 系统必须支持用户登录并返回 JWT 令牌
-```
-
-### 阶段 3: 实现计划生成
-
-#### 3.1 在 Cursor 中使用 /plan 命令
-
-```
-/plan Python 3.11, FastAPI, PostgreSQL, JWT, 邮箱服务集成
-```
-
-**Cursor 内部执行流程**:
-
-1. **命令解析**: Cursor 识别 `/plan` 命令
-2. **脚本调用**: 执行 `.specify/scripts/bash/setup-plan.sh --json`
-3. **模板加载**: 从 `.specify/templates/plan-template.md` 创建计划文件
-4. **AI 处理**: 基于规范和技术要求生成实现计划
-
-#### 3.2 脚本协同工作
-
-**`.specify/scripts/bash/setup-plan.sh` 执行过程**:
-
-```bash
-# 1. 获取功能路径
-eval $(get_feature_paths)
-
-# 2. 创建计划文件
-cp ".specify/templates/plan-template.md" "$IMPL_PLAN"
-
-# 3. 返回 JSON 输出
-printf '{"FEATURE_SPEC":"%s","IMPL_PLAN":"%s"}\n' "$FEATURE_SPEC" "$IMPL_PLAN"
-```
-
-#### 3.3 AI 代理生成实现计划
-
-**生成的 `plan.md` 内容示例**:
-```markdown
-# Implementation Plan: 用户认证系统
-
-## Technical Context
-**Language/Version**: Python 3.11
-**Primary Dependencies**: FastAPI, SQLAlchemy, Pydantic
-**Storage**: PostgreSQL
-**Testing**: pytest, httpx
-
-## Phase 0: Outline & Research
-1. **Research JWT implementation in FastAPI**
-2. **Research email service integration patterns**
-
-## Phase 1: Design & Contracts
-1. **Generate data-model.md**: User, AuthToken, PasswordReset entities
-2. **Generate API contracts**: POST /auth/register, POST /auth/login
-3. **Generate quickstart.md**: Manual testing scenarios
-```
-
-#### 3.4 生成设计文档
-
-**AI 代理自动生成以下文档**:
-
-1. **`research.md`**:
-```markdown
-# Research: 用户认证系统
-
-## JWT Implementation
-**Decision**: 使用 PyJWT 库实现 JWT 令牌
-**Rationale**: 轻量级、标准兼容、易于集成
-
-## Email Service Integration
-**Decision**: 使用 SendGrid API 发送邮件
-**Rationale**: 可靠、易于集成、支持模板
-```
-
-2. **`data-model.md`**:
-```markdown
-# Data Model: 用户认证系统
-
-## User Entity
-- id: UUID (Primary Key)
-- email: String (Unique, Not Null)
-- password_hash: String (Not Null)
-- is_verified: Boolean (Default: False)
-
-## AuthToken Entity
-- id: UUID (Primary Key)
-- user_id: UUID (Foreign Key)
-- token: String (Not Null)
-- expires_at: DateTime
-```
-
-3. **`quickstart.md`**:
-```markdown
-# Quickstart: 用户认证系统
-
-## 手动测试步骤
-1. **启动服务**: `python -m uvicorn main:app --reload`
-2. **测试注册**: `curl -X POST http://localhost:8000/auth/register`
-3. **测试登录**: `curl -X POST http://localhost:8000/auth/login`
-```
-
-#### 3.5 更新 Cursor 代理上下文
-
-**`.specify/scripts/bash/update-agent-context.sh` 执行过程**:
-
-```bash
-# 1. 解析计划文件中的技术信息
-NEW_LANG="Python 3.11"
-NEW_FRAMEWORK="FastAPI"
-NEW_DB="PostgreSQL"
-
-# 2. 更新 Cursor 代理文件
-update_agent_file "$CURSOR_FILE" "Cursor"
-```
-
-**更新的 `.cursor/commands/` 内容**:
-```markdown
-# user-auth-system Development Guidelines
-
-## Active Technologies
-- Python 3.11 + FastAPI
-- PostgreSQL
-
-## Commands
-cd backend && python -m uvicorn main:app --reload
-cd backend && pytest
-```
-
-### 阶段 4: 任务生成
-
-#### 4.1 在 Cursor 中使用 /tasks 命令
-
-```
-/tasks
-```
-
-**Cursor 内部执行流程**:
-
-1. **命令解析**: Cursor 识别 `/tasks` 命令
-2. **脚本调用**: 执行 `.specify/scripts/bash/check-prerequisites.sh --json`
-3. **文档分析**: 分析所有设计文档
-4. **任务生成**: 基于模板生成具体任务
-
-#### 4.2 脚本协同工作
-
-**`.specify/scripts/bash/check-prerequisites.sh` 执行过程**:
-
-```bash
-# 1. 检查功能目录和计划文件
-if [[ ! -d "$FEATURE_DIR" ]] || [[ ! -f "$IMPL_PLAN" ]]; then
-  echo "ERROR: Missing required files"
-  exit 1
-fi
-
-# 2. 检查可选文档
-docs=()
-[[ -f "$RESEARCH" ]] && docs+=("research.md")
-[[ -f "$DATA_MODEL" ]] && docs+=("data-model.md")
-[[ -d "$CONTRACTS_DIR" ]] && docs+=("contracts/")
-[[ -f "$QUICKSTART" ]] && docs+=("quickstart.md")
-
-# 3. 返回 JSON 输出
-printf '{"FEATURE_DIR":"%s","AVAILABLE_DOCS":%s}\n' "$FEATURE_DIR" "$json_docs"
-```
-
-#### 4.3 AI 代理生成任务列表
-
-**生成的 `tasks.md` 内容示例**:
-```markdown
-# Tasks: 用户认证系统
-
-## Phase 3.1: Setup
-- [ ] T001 Create project structure per implementation plan
-- [ ] T002 Initialize Python 3.11 project with FastAPI dependencies
-
-## Phase 3.2: Tests First (TDD)
-- [ ] T004 [P] Contract test POST /auth/register
-- [ ] T005 [P] Contract test POST /auth/login
-- [ ] T006 [P] Integration test user registration
-
-## Phase 3.3: Core Implementation
-- [ ] T010 [P] User model in src/models/user.py
-- [ ] T011 [P] AuthToken model in src/models/auth_token.py
-- [ ] T012 [P] UserService CRUD in src/services/user_service.py
-- [ ] T016 POST /auth/register endpoint in src/api/auth_routes.py
-- [ ] T017 POST /auth/login endpoint in src/api/auth_routes.py
-
-## Dependencies
-- Tests (T004-T006) before implementation (T010-T017)
-- T010-T011 blocks T012
-- T012 blocks T016-T017
-```
-
-### 阶段 5: 任务执行
-
-#### 5.1 在 Cursor 中执行任务
-
-现在我们可以开始执行任务。在 Cursor 中，使用简单的命令：
-
-```
-实现 tasks
-```
-
-Cursor 会自动：
-1. **并行执行测试任务** (T004-T006)
-2. **顺序执行实现任务** (T010-T017)
-3. **按照依赖关系执行** 确保正确的执行顺序
-
-#### 5.2 脚本和文档的持续协同
-
-在执行任务过程中，各种脚本和文档继续协同工作：
-
-1. **`check-prerequisites.sh --paths-only`**: 提供当前功能的路径信息
-2. **`update-agent-context.sh`**: 在技术栈变更时更新代理上下文
-3. **模板系统**: 为新的文档和代码提供结构
-4. **宪法检查**: 确保实现符合项目原则
-
-### 阶段 6: 验证和完成
-
-#### 6.1 运行测试
-
-```bash
-# 在 Cursor 终端中执行
-cd backend
-pytest tests/ -v
-```
-
-#### 6.2 执行快速开始
-
-```bash
-# 启动服务
-python -m uvicorn main:app --reload
-
-# 在另一个终端测试 API
-curl -X POST http://localhost:8000/auth/register \
-  -H "Content-Type: application/json" \
-  -d '{"email": "test@example.com", "password": "password123"}'
-```
-
-#### 6.3 更新进度跟踪
-
-在 `plan.md` 中更新进度：
-
-```markdown
-## Progress Tracking
-
-**Phase Status**:
-- [x] Phase 0: Research complete (/plan command)
-- [x] Phase 1: Design complete (/plan command)
-- [x] Phase 2: Task planning complete (/plan command - describe approach only)
-- [x] Phase 3: Tasks generated (/tasks command)
-- [x] Phase 4: Implementation complete
-- [x] Phase 5: Validation passed
-
-**Gate Status**:
-- [x] Initial Constitution Check: PASS
-- [x] Post-Design Constitution Check: PASS
-- [x] All NEEDS CLARIFICATION resolved
-- [x] Complexity deviations documented
-```
-
-## 协同工作机制总结
-
-### 1. 脚本系统协同
-
-| 脚本 | 调用时机 | 主要功能 | 输出 |
-|------|---------|---------|------|
-| `.specify/scripts/bash/create-new-feature.sh` | `/specify` 命令 | 创建功能分支和目录 | 分支名、规范文件路径 |
-| `.specify/scripts/bash/setup-plan.sh` | `/plan` 命令 | 创建实现计划文件 | 计划文件路径 |
-| `.specify/scripts/bash/check-prerequisites.sh` | `/tasks` 命令 | 检查前置条件 | 可用文档列表 |
-| `.specify/scripts/bash/check-prerequisites.sh --paths-only` | 需要路径信息时 | 提供功能路径 | 所有相关路径 |
-| `.specify/scripts/bash/update-agent-context.sh` | 技术栈变更时 | 更新代理上下文 | 更新的代理文件 |
-
-### 2. 模板系统协同
-
-| 模板 | 使用时机 | 主要功能 | 生成内容 |
-|------|---------|---------|---------|
-| `.specify/templates/spec-template.md` | 创建规范时 | 提供规范结构 | `spec.md` |
-| `.specify/templates/plan-template.md` | 创建计划时 | 提供计划结构 | `plan.md` |
-| `.specify/templates/tasks-template.md` | 生成任务时 | 提供任务结构 | `tasks.md` |
-| `.specify/templates/agent-file-template.md` | 更新代理时 | 提供代理结构 | `CLAUDE.md`, `GEMINI.md` 等 |
-| `.specify/templates/commands/*.md` | 执行命令时 | 提供命令指导 | 命令执行流程 |
-
-### 3. 文档系统协同
-
-| 文档 | 创建时机 | 主要功能 | 依赖关系 |
-|------|---------|---------|---------|
-| `spec.md` | `/specify` 命令 | 功能规范定义 | 无 |
-| `plan.md` | `/plan` 命令 | 实现计划 | 依赖 `spec.md` |
-| `research.md` | `/plan` 命令 | 技术研究 | 依赖 `plan.md` |
-| `data-model.md` | `/plan` 命令 | 数据模型 | 依赖 `plan.md` |
-| `contracts/` | `/plan` 命令 | API 合约 | 依赖 `plan.md` |
-| `quickstart.md` | `/plan` 命令 | 快速开始 | 依赖 `plan.md` |
-| `tasks.md` | `/tasks` 命令 | 任务列表 | 依赖所有设计文档 |
-
-### 4. Cursor 代理系统协同
-
-| 代理文件 | 更新时机 | 主要功能 | 内容来源 |
-|----------|---------|---------|---------|
-| `.cursor/commands/` | 技术栈变更时 | Cursor 上下文 | `plan.md` 技术信息 |
-| `.cursor/rules/` | 技术栈变更时 | Cursor 规则 | `plan.md` 技术信息 |
-
-通过这个完整的实战流程，我们可以看到 spec-kit 项目中的各个组件是如何协同工作的，形成了一个完整的 spec-driven 开发生态系统。每个脚本、模板和文档都有其特定的作用，它们相互配合，确保开发流程的标准化和自动化。
diff --git a/learn-spec-kit/project-structure-overview.md b/learn-spec-kit/project-structure-overview.md
deleted file mode 100644
index 23e4d2b..0000000
--- a/learn-spec-kit/project-structure-overview.md
+++ /dev/null
@@ -1,167 +0,0 @@
-# Spec-Kit 项目结构概览
-
-## 项目目录结构
-
-```
-spec-kit/
-├── AGENTS.md                       # AI 代理支持文档
-├── CHANGELOG.md                    # 项目变更日志
-├── CODE_OF_CONDUCT.md             # 行为准则
-├── CONTRIBUTING.md                # 贡献指南
-├── docs/                          # 文档目录
-│   ├── docfx.json                # DocFX 配置文件
-│   ├── index.md                  # 文档首页
-│   ├── installation.md           # 安装指南
-│   ├── local-development.md      # 本地开发指南
-│   ├── quickstart.md             # 快速开始
-│   ├── README.md                 # 文档说明
-│   └── toc.yml                   # 文档目录结构
-├── LICENSE                        # 许可证文件
-├── media/                         # 媒体资源
-│   ├── bootstrap-claude-code.gif # Claude Code 引导动画
-│   ├── logo_large.webp           # 大尺寸 Logo
-│   ├── logo_small.webp           # 小尺寸 Logo
-│   ├── spec-kit-video-header.jpg # 视频头部图片
-│   └── specify_cli.gif           # CLI 演示动画
-├── memory/                        # 项目记忆/宪法
-│   └── constitution.md            # 项目宪法
-├── pyproject.toml                 # Python 项目配置
-├── README.md                      # 项目主说明文档
-├── scripts/                       # 脚本目录
-│   ├── bash/                     # Bash 脚本
-│   │   ├── check-prerequisites.sh
-│   │   ├── common.sh
-│   │   ├── create-new-feature.sh
-│   │   ├── setup-plan.sh
-│   │   └── update-agent-context.sh
-│   └── powershell/               # PowerShell 脚本
-│       ├── check-prerequisites.ps1
-│       ├── common.ps1
-│       ├── create-new-feature.ps1
-│       ├── setup-plan.ps1
-│       └── update-agent-context.ps1
-├── SECURITY.md                    # 安全策略
-├── spec-driven.md                 # 规范驱动开发说明
-├── src/                          # 源代码目录
-│   └── specify_cli/              # CLI 工具源码
-│       └── __init__.py           # 主程序文件
-├── SUPPORT.md                     # 支持信息
-└── templates/                     # 模板目录
-    ├── agent-file-template.md    # 代理文件模板
-    ├── commands/                 # 命令模板
-    │   ├── analyze.md           # 分析命令模板
-    │   ├── clarify.md           # 澄清命令模板
-    │   ├── constitution.md       # 宪法命令模板
-    │   ├── implement.md         # 实现命令模板
-    │   ├── plan.md              # 计划命令模板
-    │   ├── specify.md           # 规范命令模板
-    │   └── tasks.md             # 任务命令模板
-    ├── plan-template.md          # 计划模板
-    ├── spec-template.md          # 规范模板
-    └── tasks-template.md         # 任务模板
-```
-
-## 核心组件说明
-
-### 1. 源代码 (`src/specify_cli/`)
-
-- **`__init__.py`**: 包含完整的 CLI 工具实现
-  - 主入口函数 `main()`
-  - 命令行应用定义（使用 typer）
-  - 所有子命令的实现
-  - 交互式界面和进度跟踪
-
-### 2. AI 代理支持 (`AGENTS.md`)
-
-- **代理集成**: 支持 11 种 AI 代理的集成指南
-- **命令模板**: 为不同代理提供标准化的命令模板
-- **目录结构**: 定义各代理的目录和文件组织方式
-- **扩展机制**: 如何添加新的 AI 代理支持
-
-### 3. 配置文件 (`pyproject.toml`)
-
-- **项目元数据**: 名称、版本、描述
-- **依赖管理**: 所需的 Python 包
-- **脚本入口点**: 定义 `specify` 命令
-- **构建配置**: 使用 hatchling 作为构建后端
-
-### 4. 模板系统 (`templates/`)
-
-- **命令模板**: 为不同 AI 助手提供标准化的命令模板
-- **项目模板**: 包含规范、计划、任务等模板文件
-- **代理模板**: 用于创建 AI 代理配置文件
-
-### 5. 脚本工具 (`scripts/`)
-
-- **跨平台支持**: 同时提供 Bash 和 PowerShell 版本
-- **功能脚本**: 包含项目创建、计划设置、上下文更新等功能
-- **通用脚本**: 提供共享的脚本功能和工具
-
-### 6. 文档系统 (`docs/`)
-
-- **DocFX 配置**: 使用 DocFX 生成文档网站
-- **多语言支持**: 包含安装、开发、快速开始等指南
-- **结构化文档**: 通过 toc.yml 组织文档层次结构
-
-### 7. 媒体资源 (`media/`)
-
-- **品牌资源**: Logo 和品牌图片
-- **演示资源**: GIF 动画展示工具功能
-- **文档资源**: 支持文档的图片和视频
-
-## 项目特点
-
-### 1. 自包含设计
-
-- 单个 Python 文件包含所有功能
-- 支持 PEP 723 脚本元数据格式
-- 可以通过 uvx 直接执行，无需安装
-
-### 2. 跨平台兼容
-
-- 支持 Windows (PowerShell) 和 Unix-like (Bash) 系统
-- 自动检测操作系统并选择合适的脚本类型
-- 统一的命令行接口
-
-### 3. 模块化架构
-
-- 清晰的目录结构分离不同功能
-- 模板系统支持多种 AI 助手
-- 可扩展的脚本和模板系统
-
-### 4. 用户友好
-
-- 丰富的交互式界面
-- 详细的错误信息和帮助文档
-- 渐进式的项目初始化流程
-
-## 开发工作流
-
-### 1. 本地开发
-
-- 使用 `docs/local-development.md` 中的指南
-- 通过 `pyproject.toml` 管理依赖
-- 使用 hatchling 构建系统
-
-### 2. 贡献流程
-
-- 遵循 `CONTRIBUTING.md` 中的指南
-- 使用 `CODE_OF_CONDUCT.md` 中的行为准则
-- 通过 `CHANGELOG.md` 记录变更
-
-### 3. 发布流程
-
-- 通过 GitHub Releases 发布新版本
-- 自动生成模板 ZIP 文件
-- 更新文档和变更日志
-
-## 扩展性
-
-项目设计支持以下扩展：
-
-1. **新的 AI 助手**: 通过添加新的模板和脚本支持
-2. **新的脚本类型**: 扩展跨平台脚本支持
-3. **新的命令**: 通过模板系统添加新的 CLI 命令
-4. **新的功能**: 通过模块化架构添加新功能
-
-这种结构化的设计使得 spec-kit 既易于使用，又便于维护和扩展。
diff --git a/learn-spec-kit/quickstart-learning-guide.md b/learn-spec-kit/quickstart-learning-guide.md
deleted file mode 100644
index 414d2db..0000000
--- a/learn-spec-kit/quickstart-learning-guide.md
+++ /dev/null
@@ -1,382 +0,0 @@
-# Quickstart 学习指南
-
-## 概述
-
-本指南深入解析 spec-kit 中 quickstart 的作用、定位以及与其他开发流程的关系。通过详细分析 quickstart 在 spec-driven 开发工作流中的具体作用，帮助开发者正确理解和使用 quickstart 功能。
-
-## 目录
-
-- [Quickstart 的定义与定位](#quickstart-的定义与定位)
-- [Quickstart 的核心作用](#quickstart-的核心作用)
-- [Quickstart 与用户交互流程的关系](#quickstart-与用户交互流程的关系)
-- [Quickstart 与页面设计的关系](#quickstart-与页面设计的关系)
-- [Quickstart 与页面拆解的关系](#quickstart-与页面拆解的关系)
-- [Quickstart 在工作流中的位置](#quickstart-在工作流中的位置)
-- [实际应用示例](#实际应用示例)
-- [最佳实践建议](#最佳实践建议)
-- [常见误区](#常见误区)
-
-## Quickstart 的定义与定位
-
-### 什么是 Quickstart
-
-在 spec-kit 工作流中，quickstart 有两个层面的含义：
-
-#### 1. 用户指南层面的 quickstart
-- **文件位置**: `/docs/quickstart.md`
-- **内容**: 如何使用 spec-kit 的 4 步流程指南
-- **目标用户**: 初次使用 spec-kit 的开发者
-
-#### 2. 功能规范层面的 quickstart
-- **文件位置**: `/specs/[feature]/quickstart.md`
-- **生成阶段**: Phase 1 设计阶段输出
-- **内容**: 用户故事和测试场景定义
-- **目标用户**: 开发团队和测试人员
-
-### Quickstart 的定位
-
-```mermaid
-graph TD
-    A[用户需求描述] --> B[spec.md<br/>功能规范]
-    B --> C[quickstart.md<br/>测试场景]
-    C --> D[data-model.md<br/>数据模型]
-    D --> E[contracts/<br/>API 契约]
-    E --> F[tasks.md<br/>开发任务]
-    
-    style C fill:#e1f5fe
-    style C stroke:#01579b
-    style C stroke-width:3px
-```
-
-**核心定位**：
-- ✅ **测试场景定义文档**
-- ✅ **用户故事验证标准**
-- ✅ **功能验收基准**
-- ❌ **不是可视化原型设计**
-- ❌ **不是页面拆解文档**
-
-## Quickstart 的核心作用
-
-### 1. 测试场景验证 (Test Scenario Validation)
-
-quickstart 是测试场景的重要来源：
-
-```markdown
-# 在 tasks-template.md 中的体现
-- 第113行: "Quickstart scenarios → validation tasks"
-- 第174行: "Quickstart test = story validation steps"
-```
-
-**作用**：
-- 定义用户行为的测试用例
-- 确保功能实现符合用户期望
-- 提供验收测试的具体标准
-
-### 2. 用户故事测试 (User Story Testing)
-
-quickstart 包含从用户故事中提取的测试场景：
-
-```markdown
-# 示例：Taskify 项目的用户故事
-"When you first launch Taskify, it's going to give you a list of the five users to pick from"
-"When you click on a user, you go into the main view, which displays the list of projects"
-"When you click on a project, you open the Kanban board for that project"
-```
-
-**作用**：
-- 每个用户故事生成对应的集成测试任务
-- 验证功能是否符合用户需求
-- 作为测试驱动开发(TDD)的测试用例来源
-
-### 3. Phase 1 设计阶段输出
-
-quickstart 是 Phase 1 设计阶段的重要输出：
-
-```markdown
-# 在 plan-template.md 中的体现
-├── quickstart.md        # Phase 1 output (/plan command)
-```
-
-**生成时机**：
-- 在 `/plan` 命令执行时生成
-- 基于功能规范中的用户故事
-- 作为后续任务生成的重要输入
-
-### 4. 任务生成的重要输入
-
-quickstart 是生成开发任务的重要输入源：
-
-```markdown
-# 在 tasks-template.md 中的体现
-- 第16行: "IF EXISTS: Read quickstart.md for test scenarios"
-- 第191行: "Generate tasks from Phase 1 design docs (contracts, data model, quickstart)"
-```
-
-## Quickstart 与用户交互流程的关系
-
-### 交互流程定义
-
-quickstart 详细描述用户交互流程，但不涉及视觉设计：
-
-```text
-# 用户交互流程描述示例
-✅ 定义用户操作序列: 点击 → 跳转 → 显示
-✅ 描述交互逻辑: 拖拽、颜色区分、权限控制
-✅ 明确功能边界: 什么能做，什么不能做
-❌ 不涉及视觉设计: 颜色、布局、字体等
-```
-
-### 与可视化原型设计的关系
-
-**quickstart 不能代替可视化原型设计**：
-
-#### Quickstart 的局限性：
-- **缺乏视觉信息**：没有布局、颜色、字体、图标等设计元素
-- **缺乏空间关系**：不知道元素在页面上的具体位置
-- **缺乏交互反馈**：没有动画、过渡效果等细节
-- **缺乏品牌表达**：没有体现产品的视觉风格和品牌调性
-
-#### 可视化原型设计的价值：
-- **空间布局**：元素的位置、大小、层次关系
-- **视觉层次**：重要信息的突出显示
-- **交互细节**：按钮状态、悬停效果、加载动画
-- **用户体验**：直观的界面流程和操作反馈
-
-### 协作关系
-
-```mermaid
-graph TD
-    A[用户需求] --> B[spec-template.md<br/>功能规范]
-    B --> C[quickstart.md<br/>用户交互流程]
-    C --> D[可视化原型设计<br/>UI/UX设计]
-    D --> E[plan-template.md<br/>技术实现计划]
-    E --> F[tasks-template.md<br/>开发任务]
-    
-    C --> G[测试场景定义]
-    D --> H[视觉规范定义]
-    
-    style C fill:#e1f5fe
-    style D fill:#f3e5f5
-```
-
-**理想工作流程**：
-1. **quickstart** → 定义用户交互逻辑和功能流程
-2. **可视化原型** → 设计具体的界面布局和视觉表现
-3. **技术实现** → 基于两者进行开发
-
-## Quickstart 与页面设计的关系
-
-### 页面设计定位
-
-quickstart 在页面设计中的定位：
-
-- **功能需求文档**：为设计师提供清晰的功能需求
-- **验收标准**：确保原型设计不偏离用户需求
-- **测试基准**：作为功能验收的标准
-
-### 设计协作流程
-
-```mermaid
-sequenceDiagram
-    participant PM as 产品经理
-    participant Designer as UI/UX设计师
-    participant Dev as 开发团队
-    
-    PM->>Designer: 提供 quickstart.md
-    Note over Designer: 基于用户交互流程设计界面
-    Designer->>Dev: 提供可视化原型 + quickstart
-    Note over Dev: 基于两者进行开发实现
-    Dev->>PM: 交付符合 quickstart 标准的功能
-```
-
-## Quickstart 与页面拆解的关系
-
-### 页面拆解不包含在 Quickstart 中
-
-**明确结论**：quickstart 不包含页面拆解。
-
-### 页面拆解的实际位置
-
-从 `plan-template.md` 可以看出，页面拆解应该在：
-
-```markdown
-# Option 2: Web application (when "frontend" + "backend" detected)
-frontend/
-├── src/
-│   ├── components/    # ← UI 组件在这里
-│   ├── pages/         # ← 页面拆解在这里
-│   └── services/
-```
-
-**页面拆解发生时机**：
-- **Phase 1 设计阶段**：通过 `data-model.md` 和 `contracts/` 定义功能
-- **Phase 2 任务生成**：通过 `tasks.md` 生成具体的组件开发任务
-- **Phase 3 实现阶段**：实际开发 UI 组件和页面
-
-### 页面拆解与 Quickstart 的关系
-
-```mermaid
-graph TD
-    A[用户需求] --> B[spec.md<br/>功能规范]
-    B --> C[quickstart.md<br/>测试场景]
-    C --> D[data-model.md<br/>数据模型]
-    D --> E[contracts/<br/>API 契约]
-    E --> F[tasks.md<br/>开发任务]
-    F --> G[页面拆解<br/>UI 组件开发]
-    
-    style C fill:#e1f5fe
-    style G fill:#f3e5f5
-```
-
-**关系说明**：
-- quickstart 提供**测试验收标准**
-- 页面拆解基于 quickstart 的测试场景进行
-- quickstart 确保页面功能符合用户期望
-
-## Quickstart 在工作流中的位置
-
-### 完整工作流
-
-```mermaid
-graph TD
-    A[用户需求描述] --> B[/specify 命令]
-    B --> C[spec.md<br/>功能规范]
-    C --> D[/plan 命令]
-    D --> E[Phase 0: research.md]
-    E --> F[Phase 1: 设计阶段]
-    F --> G[data-model.md]
-    F --> H[contracts/]
-    F --> I[quickstart.md]
-    F --> J[agent-specific 文件]
-    I --> K[/tasks 命令]
-    K --> L[tasks.md<br/>开发任务]
-    L --> M[页面拆解<br/>UI 组件开发]
-    
-    style I fill:#e1f5fe
-    style I stroke:#01579b
-    style I stroke-width:3px
-```
-
-### 各阶段输出
-
-| 阶段 | 命令 | 输出文件 | Quickstart 作用 |
-|------|------|----------|----------------|
-| Phase 0 | `/plan` | `research.md` | 无 |
-| Phase 1 | `/plan` | `quickstart.md` | **生成测试场景** |
-| Phase 2 | `/tasks` | `tasks.md` | **作为任务生成输入** |
-| Phase 3+ | 实现 | 代码实现 | **作为验收标准** |
-
-## 实际应用示例
-
-### Taskify 项目示例
-
-基于 quickstart 中的用户故事进行页面拆解：
-
-```text
-# Quickstart 中的用户故事
-"When you first launch Taskify, it's going to give you a list of the five users to pick from"
-"When you click on a user, you go into the main view, which displays the list of projects"
-"When you click on a project, you open the Kanban board for that project"
-"You'll be able to drag and drop cards back and forth between different columns"
-```
-
-**基于此生成的页面拆解**：
-- 用户选择页面 (UserSelectionPage)
-- 项目列表页面 (ProjectListPage)  
-- 看板页面 (KanbanBoardPage)
-- 任务卡片组件 (TaskCard)
-- 评论组件 (CommentSection)
-
-### 测试场景定义
-
-```markdown
-# quickstart.md 中的测试场景示例
-## 用户选择测试
-- Given: 用户访问应用首页
-- When: 页面加载完成
-- Then: 显示 5 个用户选择按钮
-
-## 项目列表测试  
-- Given: 用户已选择身份
-- When: 点击进入主视图
-- Then: 显示 3 个示例项目列表
-
-## 看板操作测试
-- Given: 用户进入项目看板
-- When: 拖拽任务卡片到不同列
-- Then: 任务状态更新，卡片颜色区分
-```
-
-## 最佳实践建议
-
-### 1. Quickstart 编写原则
-
-- **聚焦用户行为**：描述用户做什么，而不是系统如何实现
-- **具体可测试**：每个场景都应该能够编写自动化测试
-- **完整覆盖**：包含正常流程、异常流程和边界条件
-- **避免技术细节**：不涉及具体的技术实现方案
-
-### 2. 与设计团队的协作
-
-- **提供清晰需求**：quickstart 为设计师提供明确的功能需求
-- **保持沟通**：确保设计师理解用户交互流程
-- **验收标准**：将 quickstart 作为设计验收的标准
-
-### 3. 与开发团队的协作
-
-- **测试驱动**：基于 quickstart 编写测试用例
-- **功能验证**：确保实现符合 quickstart 中定义的场景
-- **持续更新**：随着需求变化及时更新 quickstart
-
-## 常见误区
-
-### ❌ 误区 1：Quickstart 可以代替原型设计
-
-**错误认知**：认为 quickstart 包含了足够的界面设计信息
-**实际情况**：quickstart 只定义功能流程，不包含视觉设计
-**正确做法**：quickstart + 可视化原型设计
-
-### ❌ 误区 2：Quickstart 包含页面拆解
-
-**错误认知**：认为 quickstart 会自动生成页面拆解
-**实际情况**：页面拆解在 tasks.md 生成阶段进行
-**正确做法**：基于 quickstart 的测试场景进行页面拆解
-
-### ❌ 误区 3：Quickstart 是技术实现文档
-
-**错误认知**：在 quickstart 中描述技术实现细节
-**实际情况**：quickstart 专注于用户行为和业务需求
-**正确做法**：技术细节在 plan.md 和 tasks.md 中描述
-
-### ❌ 误区 4：Quickstart 可以跳过
-
-**错误认知**：认为 quickstart 是可选的文档
-**实际情况**：quickstart 是测试场景的重要来源
-**正确做法**：每个功能都应该有对应的 quickstart
-
-## 总结
-
-Quickstart 在 spec-kit 工作流中扮演着**测试场景定义和用户故事验证**的关键角色：
-
-### 核心价值
-- ✅ **测试场景定义**：为功能测试提供具体标准
-- ✅ **用户故事验证**：确保实现符合用户期望
-- ✅ **验收基准**：作为功能验收的客观标准
-- ✅ **任务生成输入**：为开发任务生成提供重要信息
-
-### 定位边界
-- ❌ **不是可视化原型设计**：缺乏视觉和空间信息
-- ❌ **不是页面拆解文档**：不包含 UI 组件分析
-- ❌ **不是技术实现文档**：专注于业务需求而非技术细节
-
-### 最佳实践
-- 与设计团队协作，提供清晰的功能需求
-- 与开发团队协作，确保测试驱动开发
-- 保持文档的及时更新和准确性
-- 避免常见误区，正确理解 quickstart 的作用边界
-
-通过正确理解和使用 quickstart，可以显著提高 spec-driven 开发的质量和效率，确保最终产品真正满足用户需求。
-
----
-
-*本文档基于 spec-kit 项目分析整理，如有疑问请参考项目源码或相关文档。*
diff --git a/learn-spec-kit/scripts-reference-guide.md b/learn-spec-kit/scripts-reference-guide.md
deleted file mode 100644
index 7c9172d..0000000
--- a/learn-spec-kit/scripts-reference-guide.md
+++ /dev/null
@@ -1,449 +0,0 @@
-# Spec-Kit Scripts 脚本参考指南
-
-## 概述
-
-Spec-Kit 项目包含了一套完整的脚本工具，用于支持 spec-driven 开发工作流。这些脚本分为两个版本：Bash（适用于 Unix-like 系统）和 PowerShell（适用于 Windows 系统），提供相同的功能但使用不同的脚本语言实现。
-
-## 脚本目录结构
-
-```
-scripts/
-├── bash/                          # Bash 脚本（Unix-like 系统）
-│   ├── common.sh                  # 通用函数和变量
-│   ├── check-prerequisites.sh     # 统一的前置条件检查
-│   ├── create-new-feature.sh      # 创建新功能
-│   ├── setup-plan.sh              # 设置计划
-│   └── update-agent-context.sh    # 更新代理上下文
-└── powershell/                    # PowerShell 脚本（Windows 系统）
-    ├── common.ps1                 # 通用函数和变量
-    ├── check-prerequisites.ps1     # 统一的前置条件检查
-    ├── create-new-feature.ps1     # 创建新功能
-    ├── setup-plan.ps1             # 设置计划
-    └── update-agent-context.ps1   # 更新代理上下文
-```
-
-## 通用脚本 (common)
-
-### Bash: `common.sh`
-
-**作用**: 提供所有 Bash 脚本共享的通用函数和变量。
-
-**主要功能**:
-
-1. **Git 操作函数**:
-   ```bash
-   get_repo_root()           # 获取仓库根目录
-   get_current_branch()      # 获取当前分支名
-   ```
-
-2. **分支验证**:
-   ```bash
-   check_feature_branch()    # 验证是否为功能分支（格式：001-feature-name）
-   ```
-
-3. **路径管理**:
-   ```bash
-   get_feature_dir()         # 获取功能目录路径
-   get_feature_paths()       # 获取所有功能相关路径的环境变量
-   ```
-
-4. **文件检查**:
-   ```bash
-   check_file()              # 检查文件是否存在
-   check_dir()               # 检查目录是否存在且非空
-   ```
-
-**环境变量输出**:
-```bash
-REPO_ROOT='...'              # 仓库根目录
-CURRENT_BRANCH='...'         # 当前分支
-FEATURE_DIR='...'            # 功能目录
-FEATURE_SPEC='...'           # 功能规范文件
-IMPL_PLAN='...'              # 实现计划文件
-TASKS='...'                  # 任务文件
-RESEARCH='...'               # 研究文件
-DATA_MODEL='...'             # 数据模型文件
-QUICKSTART='...'             # 快速开始文件
-CONTRACTS_DIR='...'          # 合约目录
-```
-
-### PowerShell: `common.ps1`
-
-**作用**: 提供所有 PowerShell 脚本共享的通用函数和变量。
-
-**主要功能**:
-
-1. **Git 操作函数**:
-   ```powershell
-   Get-RepoRoot              # 获取仓库根目录
-   Get-CurrentBranch         # 获取当前分支名
-   ```
-
-2. **分支验证**:
-   ```powershell
-   Test-FeatureBranch        # 验证是否为功能分支
-   ```
-
-3. **路径管理**:
-   ```powershell
-   Get-FeatureDir            # 获取功能目录路径
-   Get-FeaturePathsEnv       # 获取所有功能相关路径的对象
-   ```
-
-4. **文件检查**:
-   ```powershell
-   Test-FileExists           # 检查文件是否存在
-   Test-DirHasFiles          # 检查目录是否存在且包含文件
-   ```
-
-## 功能管理脚本
-
-### 1. 创建新功能
-
-#### Bash: `create-new-feature.sh`
-
-**作用**: 创建新的功能分支和目录结构。
-
-**用法**:
-```bash
-./create-new-feature.sh [--json] <feature_description>
-```
-
-**功能**:
-1. **自动编号**: 扫描现有功能，自动生成下一个编号（001, 002, 003...）
-2. **分支创建**: 基于功能描述创建格式化的分支名（如：`001-user-authentication`）
-3. **目录结构**: 在 `specs/` 目录下创建功能目录
-4. **模板复制**: 从 `templates/spec-template.md` 复制规范模板
-
-**输出示例**:
-```bash
-BRANCH_NAME: 001-user-authentication
-SPEC_FILE: /path/to/specs/001-user-authentication/spec.md
-FEATURE_NUM: 001
-```
-
-**JSON 模式**:
-```bash
-./create-new-feature.sh --json "user authentication system"
-# 输出: {"BRANCH_NAME":"001-user-authentication","SPEC_FILE":"...","FEATURE_NUM":"001"}
-```
-
-#### PowerShell: `create-new-feature.ps1`
-
-**作用**: PowerShell 版本的创建新功能脚本。
-
-**用法**:
-```powershell
-./create-new-feature.ps1 [-Json] <feature_description>
-```
-
-**功能**: 与 Bash 版本相同，但使用 PowerShell 语法实现。
-
-### 2. 获取功能路径
-
-#### Bash: `check-prerequisites.sh`
-
-**作用**: 显示当前功能的所有相关路径信息。
-
-**用法**:
-```bash
-./check-prerequisites.sh --paths-only
-```
-
-**输出**:
-```bash
-REPO_ROOT: /path/to/repo
-BRANCH: 001-user-authentication
-FEATURE_DIR: /path/to/repo/specs/001-user-authentication
-FEATURE_SPEC: /path/to/repo/specs/001-user-authentication/spec.md
-IMPL_PLAN: /path/to/repo/specs/001-user-authentication/plan.md
-TASKS: /path/to/repo/specs/001-user-authentication/tasks.md
-```
-
-#### PowerShell: `check-prerequisites.ps1`
-
-**作用**: PowerShell 版本的获取功能路径脚本。
-
-**功能**: 与 Bash 版本相同，输出当前功能的所有路径信息。
-
-### 3. 设置计划
-
-#### Bash: `setup-plan.sh`
-
-**作用**: 为当前功能创建实现计划文件。
-
-**用法**:
-```bash
-./setup-plan.sh [--json]
-```
-
-**功能**:
-1. **验证分支**: 确保当前在功能分支上
-2. **创建目录**: 确保功能目录存在
-3. **复制模板**: 从 `templates/plan-template.md` 复制计划模板到 `plan.md`
-
-**输出示例**:
-```bash
-FEATURE_SPEC: /path/to/specs/001-user-authentication/spec.md
-IMPL_PLAN: /path/to/specs/001-user-authentication/plan.md
-SPECS_DIR: /path/to/specs/001-user-authentication
-BRANCH: 001-user-authentication
-```
-
-#### PowerShell: `setup-plan.ps1`
-
-**作用**: PowerShell 版本的设置计划脚本。
-
-**功能**: 与 Bash 版本相同，创建实现计划文件。
-
-## 任务和上下文管理脚本
-
-### 1. 检查任务前置条件
-
-#### Bash: `check-prerequisites.sh`
-
-**作用**: 检查当前功能的任务前置条件是否满足。
-
-**用法**:
-```bash
-./check-prerequisites.sh [--json]
-```
-
-**检查项目**:
-1. **功能目录**: 确保 `specs/<branch>/` 目录存在
-2. **实现计划**: 确保 `plan.md` 文件存在
-3. **可选文档**: 检查以下文件是否存在：
-   - `research.md` - 研究文档
-   - `data-model.md` - 数据模型文档
-   - `contracts/` - 合约目录（非空）
-   - `quickstart.md` - 快速开始文档
-
-**输出示例**:
-```bash
-FEATURE_DIR:/path/to/specs/001-user-authentication
-AVAILABLE_DOCS:
-  ✓ research.md
-  ✗ data-model.md
-  ✓ contracts/
-  ✗ quickstart.md
-```
-
-**JSON 模式**:
-```bash
-./check-prerequisites.sh --json
-# 输出: {"FEATURE_DIR":"...","AVAILABLE_DOCS":["research.md","contracts/"]}
-```
-
-#### PowerShell: `check-prerequisites.ps1`
-
-**作用**: PowerShell 版本的检查任务前置条件脚本。
-
-**功能**: 与 Bash 版本相同，检查任务前置条件。
-
-### 2. 更新代理上下文
-
-#### Bash: `update-agent-context.sh`
-
-**作用**: 根据当前功能的实现计划更新 AI 代理的上下文文件。
-
-**用法**:
-```bash
-./update-agent-context.sh [claude|gemini|copilot]
-```
-
-**功能**:
-1. **解析计划**: 从 `plan.md` 中提取技术信息：
-   - 编程语言/版本
-   - 主要依赖
-   - 存储方案
-   - 项目类型
-
-2. **更新代理文件**:
-   - **Claude Code**: 更新 `CLAUDE.md`
-   - **Gemini CLI**: 更新 `GEMINI.md`
-   - **GitHub Copilot**: 更新 `.github/copilot-instructions.md`
-
-3. **智能更新**:
-   - 如果文件不存在，从模板创建
-   - 如果文件存在，智能合并新信息
-   - 保留手动添加的内容
-
-**更新内容**:
-- **活跃技术**: 添加新的编程语言和框架
-- **项目结构**: 根据项目类型设置目录结构
-- **测试命令**: 根据编程语言设置测试和检查命令
-- **最近变更**: 记录最新的功能添加
-
-**输出示例**:
-```bash
-=== Updating agent context files for feature 001-user-authentication ===
-Updating Claude Code context file: /path/to/CLAUDE.md
-✅ Claude Code context file updated successfully
-
-Summary of changes:
-- Added language: Python 3.11
-- Added framework: FastAPI
-- Added database: PostgreSQL
-```
-
-#### PowerShell: `update-agent-context.ps1`
-
-**作用**: PowerShell 版本的更新代理上下文脚本。
-
-**功能**: 与 Bash 版本相同，但使用 PowerShell 语法实现。
-
-## 使用工作流
-
-### 典型的功能开发流程
-
-1. **创建新功能**:
-   ```bash
-   # Bash
-   ./scripts/bash/create-new-feature.sh "user authentication system"
-   
-   # PowerShell
-   ./scripts/powershell/create-new-feature.ps1 "user authentication system"
-   ```
-
-2. **编写功能规范**:
-   - 编辑 `specs/001-user-authentication/spec.md`
-
-3. **设置实现计划**:
-   ```bash
-   # Bash
-   ./scripts/bash/setup-plan.sh
-   
-   # PowerShell
-   ./scripts/powershell/setup-plan.ps1
-   ```
-
-4. **编写实现计划**:
-   - 编辑 `specs/001-user-authentication/plan.md`
-
-5. **更新代理上下文**:
-   ```bash
-   # Bash
-   ./scripts/bash/update-agent-context.sh claude
-   
-   # PowerShell
-   ./scripts/powershell/update-agent-context.ps1 claude
-   ```
-
-6. **检查任务前置条件**:
-   ```bash
-   # Bash
-   ./scripts/bash/check-prerequisites.sh
-   
-   # PowerShell
-   ./scripts/powershell/check-prerequisites.ps1
-   ```
-
-7. **获取路径信息**:
-   ```bash
-   # Bash
-   ./scripts/bash/check-prerequisites.sh --paths-only
-   
-   # PowerShell
-   ./scripts/powershell/check-prerequisites.ps1 -PathsOnly
-   ```
-
-## 脚本特性
-
-### 1. 跨平台兼容
-
-- **Bash 版本**: 适用于 Linux、macOS 等 Unix-like 系统
-- **PowerShell 版本**: 适用于 Windows 系统
-- **功能对等**: 两个版本提供完全相同的功能
-
-### 2. JSON 输出支持
-
-大多数脚本支持 `--json` 参数，提供机器可读的输出格式，便于与其他工具集成。
-
-### 3. 错误处理
-
-- **严格模式**: 使用 `set -e`（Bash）和 `$ErrorActionPreference = 'Stop'`（PowerShell）
-- **详细错误信息**: 提供清晰的错误消息和解决建议
-- **优雅失败**: 在遇到错误时提供有用的提示
-
-### 4. 分支命名规范
-
-- **格式**: `001-feature-name`
-- **编号**: 自动递增的三位数字
-- **名称**: 基于功能描述自动生成，使用小写字母和连字符
-
-### 5. 模板系统
-
-- **规范模板**: `templates/spec-template.md`
-- **计划模板**: `templates/plan-template.md`
-- **代理模板**: `templates/agent-file-template.md`
-
-## 集成和扩展
-
-### 1. 与 AI 代理集成
-
-脚本设计为与以下 AI 代理无缝集成：
-- **Claude Code**: 通过 `CLAUDE.md` 文件
-- **Gemini CLI**: 通过 `GEMINI.md` 文件
-- **GitHub Copilot**: 通过 `.github/copilot-instructions.md` 文件
-
-### 2. 自定义扩展
-
-可以通过以下方式扩展脚本功能：
-- **添加新的检查项**: 在 `check-prerequisites` 脚本中添加新的文件检查
-- **自定义模板**: 修改模板文件以适应特定项目需求
-- **新的输出格式**: 添加新的输出格式支持
-
-### 3. 自动化集成
-
-脚本支持 JSON 输出，可以轻松集成到 CI/CD 流水线或其他自动化工具中。
-
-## 最佳实践
-
-### 1. 分支管理
-
-- 始终在功能分支上运行脚本
-- 使用描述性的功能名称
-- 遵循编号命名规范
-
-### 2. 文档维护
-
-- 及时更新代理上下文文件
-- 保持规范、计划和任务文档的同步
-- 使用脚本检查前置条件
-
-### 3. 错误处理
-
-- 在运行脚本前检查当前分支
-- 确保必要的模板文件存在
-- 查看详细的错误信息
-
-### 4. 版本控制
-
-- 将脚本更改提交到版本控制
-- 使用脚本的 JSON 输出进行自动化
-- 保持 Bash 和 PowerShell 版本的功能同步
-
-## 故障排除
-
-### 常见问题
-
-1. **"Not on a feature branch" 错误**:
-   - 确保当前分支名称以三位数字开头（如：`001-feature-name`）
-
-2. **"Feature directory not found" 错误**:
-   - 先运行 `create-new-feature.sh` 创建功能结构
-
-3. **"plan.md not found" 错误**:
-   - 先运行 `setup-plan.sh` 创建计划文件
-
-4. **模板文件缺失**:
-   - 确保 `templates/` 目录包含必要的模板文件
-
-### 调试技巧
-
-1. **使用 JSON 输出**: 便于程序化处理错误
-2. **检查文件权限**: 确保脚本有执行权限
-3. **验证 Git 状态**: 确保在正确的仓库和分支上
-4. **查看详细输出**: 脚本提供详细的路径和状态信息
-
-这套脚本系统为 spec-driven 开发提供了完整的工具链支持，确保开发流程的规范化和自动化。
diff --git a/learn-spec-kit/sdd-theory-guide.md b/learn-spec-kit/sdd-theory-guide.md
deleted file mode 100644
index 8119d6a..0000000
--- a/learn-spec-kit/sdd-theory-guide.md
+++ /dev/null
@@ -1,167 +0,0 @@
-# SDD 理论介绍
-
-## 概述
-
-Specification-Driven Development (SDD) 是一种全新的软件开发方法论，它从根本上改变了我们对软件开发的理解。在传统的开发模式中，代码是核心，规范文档只是辅助工具。而 SDD 将这种关系完全颠倒：**规范成为核心，代码成为规范的表达**。
-
-## 核心思想转变
-
-### 从"代码为王"到"规范为王"
-
-#### 传统开发模式的问题
-
-在传统的软件开发中，我们面临以下问题：
-
-1. **规范与代码的脱节**: 需求文档、设计文档往往在开发过程中逐渐过时，最终代码成为唯一的真实来源
-2. **维护困难**: 当需求变更时，需要手动同步更新文档、设计、代码等多个层面
-3. **知识流失**: 项目中的业务逻辑和设计决策往往只存在于代码中，难以传承
-4. **协作效率低**: 不同角色（产品、设计、开发）之间的沟通成本高，理解偏差大
-
-#### SDD 的解决方案
-
-SDD 通过以下方式解决这些问题：
-
-1. **规范作为单一真实来源**: 所有业务逻辑、设计决策都明确记录在规范中
-2. **自动化代码生成**: 基于规范自动生成代码，确保规范与代码的一致性
-3. **持续同步**: 规范变更时，代码自动更新，无需手动维护
-4. **知识沉淀**: 所有设计决策和业务逻辑都沉淀在规范中，便于传承和复用
-
-## SDD 工作流程
-
-### 1. 规范制定阶段
-
-```
-想法 → 需求澄清 → 产品需求文档(PRD) → 技术规范 → 实现计划
-```
-
-- **需求澄清**: 通过 AI 助手进行深度对话，澄清模糊需求
-- **PRD 编写**: 将需求转化为结构化的产品需求文档
-- **技术规范**: 基于 PRD 制定详细的技术实现规范
-- **实现计划**: 将技术规范分解为具体的实现任务
-
-### 2. 实现阶段
-
-```
-规范 → AI 分析 → 测试生成 → 代码生成 → 部署准备
-```
-
-- **AI 分析**: AI 助手理解规范，分析技术选型和架构设计
-- **测试生成**: 基于验收标准生成测试用例
-- **代码生成**: 基于规范生成符合要求的代码
-- **部署准备**: 生成部署配置和文档
-
-**实现策略选择**: SDD 支持多种实现策略，包括测试优先、代码优先或并行开发，具体选择取决于项目需求和团队偏好。
-
-### 3. 迭代优化阶段
-
-```
-反馈 → 规范更新 → 自动重新生成 → 验证 → 部署
-```
-
-- **反馈收集**: 从用户、测试、生产环境收集反馈
-- **规范更新**: 根据反馈更新相关规范
-- **自动重新生成**: 基于更新后的规范重新生成代码
-- **验证部署**: 验证更新后的系统并部署
-
-## 为什么现在需要 SDD
-
-### 技术条件成熟
-
-1. **AI 能力突破**: 现代 AI 已经能够理解复杂的自然语言规范，并生成高质量的代码
-2. **工具链完善**: 从规范到代码的自动化工具链已经成熟
-3. **开发效率需求**: 现代软件开发对效率和质量的追求需要新的方法论
-
-### 业务需求驱动
-
-1. **快速迭代**: 现代产品需要快速响应市场变化
-2. **质量要求**: 用户对软件质量的要求越来越高
-3. **团队协作**: 跨职能团队需要更好的协作方式
-4. **知识管理**: 企业需要更好的知识沉淀和传承机制
-
-## SDD 的核心原则
-
-### 1. 规范作为单一真实来源
-
-- 所有业务逻辑都明确记录在规范中
-- 规范是团队协作的基础
-- 规范变更驱动代码变更
-
-### 2. 测试与质量保证
-
-SDD 强调测试在质量保证中的重要作用，支持多种实现方式：
-
-- **规范指导测试**: 基于详细规范编写测试用例，确保覆盖所有功能需求
-- **测试验证规范**: 通过测试用例验证规范的正确性和完整性
-- **持续质量反馈**: 测试提供快速反馈，帮助发现和修正问题
-- **多种实现策略**: SDD 支持多种测试方法，包括测试优先、代码优先或并行开发
-
-**TDD 与 SDD 的高度契合**: 虽然 SDD 不强制特定的测试流程，但测试驱动开发（TDD）与 SDD 理念高度契合。TDD 的"红-绿-重构"循环与 SDD 的"规范-实现-验证"流程天然匹配，两者都强调质量、可维护性和快速反馈。许多 SDD 实现选择 TDD 作为核心测试策略。
-
-### 3. 自动化代码生成
-
-- 基于规范自动生成代码
-- 确保规范与代码的一致性
-- 减少手工编码的错误
-
-### 4. 规范优先机制
-
-- 规范变更时自动更新代码
-- 代码变更必须以规范更新为前提
-- 保持规范与实现的一致性
-
-### 5. 知识沉淀与传承
-
-- 设计决策记录在规范中
-- 业务逻辑清晰可读
-- 便于团队知识传承
-
-## SDD 与传统开发的区别
-
-| 方面 | 传统开发 | SDD |
-|------|----------|-----|
-| 核心资产 | 代码 | 规范 |
-| 文档作用 | 辅助工具 | 核心驱动 |
-| 变更流程 | 手动同步 | 规范优先 |
-| 知识管理 | 分散在代码中 | 集中在规范中 |
-| 团队协作 | 基于代码 | 基于规范 |
-| 质量保证 | 测试驱动（可选） | 测试策略灵活选择 |
-| 测试生成 | 代码后编写测试 | 基于规范生成测试 |
-| 测试与代码关系 | 测试验证代码 | 测试和代码都来自规范 |
-
-## 实施 SDD 的挑战
-
-### 1. 思维转变
-
-- 从代码思维转向规范思维
-- 重新定义开发者的角色
-- 适应新的工作流程
-
-### 2. 工具支持
-
-- 需要完善的规范管理工具
-- 需要强大的代码生成能力
-- 需要持续的同步机制
-
-### 3. 团队协作
-
-- 需要跨职能团队的深度协作
-- 需要建立新的协作模式
-- 需要培养新的技能
-
-## 总结
-
-SDD 代表了软件开发方法论的一次根本性转变。它将规范提升为核心资产，通过自动化代码生成实现规范与代码的一致性，为现代软件开发提供了新的思路和解决方案。
-
-**SDD 的核心创新**：
-1. **规范驱动**: 规范成为单一真实来源
-2. **规范优先**: 任何变更都必须先更新规范，再生成代码
-3. **自动化生成**: 基于规范生成测试和代码
-4. **测试策略灵活**: 支持多种测试方法，可根据项目需求选择
-
-虽然实施 SDD 面临一些挑战，但随着 AI 技术的成熟和工具链的完善，SDD 将成为未来软件开发的重要趋势。
-
----
-
-**扩展阅读**: 
-- [spec-driven.md](../spec-driven.md) - 官方 SDD 理论文档
-- [SpecKit 理论介绍](./speckit-theory-guide.md) - 了解如何通过工具实现 SDD
diff --git a/learn-spec-kit/speckit-engineering-principles.md b/learn-spec-kit/speckit-engineering-principles.md
deleted file mode 100644
index 1bdc5f0..0000000
--- a/learn-spec-kit/speckit-engineering-principles.md
+++ /dev/null
@@ -1,1039 +0,0 @@
-# SpecKit 工程化原理
-
-## 概述
-
-本文档深入解析 SpecKit CLI 的工程化实现原理，包括如何支持多 AI Agent、发布机制、安装机制以及扩展性设计。这些技术实现细节对于理解 SpecKit 的工作原理和进行二次开发具有重要意义。
-
-## 整体架构设计
-
-### 系统架构图
-
-```mermaid
-graph TB
-    subgraph "用户层"
-        A[用户命令] --> B[uvx 执行器]
-    end
-    
-    subgraph "SpecKit CLI 层"
-        B --> C[CLI 入口点]
-        C --> D[命令路由器]
-        D --> E[参数解析器]
-        E --> F[环境检查器]
-    end
-    
-    subgraph "AI Agent 层"
-        F --> G[Agent 路由器]
-        G --> H[Claude Agent]
-        G --> I[Gemini Agent]
-        G --> J[Cursor Agent]
-        G --> K[Copilot Agent]
-    end
-    
-    subgraph "模板系统层"
-        H --> L[模板引擎]
-        I --> L
-        J --> L
-        K --> L
-        L --> M[模板渲染器]
-        M --> N[内容生成器]
-    end
-    
-    subgraph "文档系统层"
-        N --> O[文档管理器]
-        O --> P[版本控制器]
-        P --> Q[项目更新器]
-    end
-    
-    subgraph "发布系统层"
-        Q --> R[GitHub Actions]
-        R --> S[构建系统]
-        S --> T[发布管理]
-    end
-```
-
-### 核心组件关系
-
-```mermaid
-graph LR
-    A[CLI 核心] --> B[Agent 管理]
-    A --> C[模板系统]
-    A --> D[文档系统]
-    A --> E[项目管理]
-    
-    B --> F[多 Agent 支持]
-    C --> G[模板渲染]
-    D --> H[文档生成]
-    E --> I[项目结构]
-    
-    F --> J[AI 集成]
-    G --> K[内容生成]
-    H --> L[版本控制]
-    I --> M[文件管理]
-```
-
-## 多 AI Agent 支持机制
-
-### 1. Agent 抽象层设计
-
-#### Agent 接口定义
-
-```python
-# Agent 抽象基类
-from abc import ABC, abstractmethod
-from typing import Dict, Any, Optional
-
-class BaseAgent(ABC):
-    """AI Agent 抽象基类"""
-    
-    def __init__(self, config: Dict[str, Any]):
-        self.config = config
-        self.name = self.__class__.__name__
-    
-    @abstractmethod
-    def execute_command(self, command: str, context: Dict[str, Any]) -> str:
-        """执行命令并返回结果"""
-        pass
-    
-    @abstractmethod
-    def check_availability(self) -> bool:
-        """检查 Agent 是否可用"""
-        pass
-    
-    @abstractmethod
-    def get_capabilities(self) -> List[str]:
-        """获取 Agent 能力列表"""
-        pass
-```
-
-#### 具体 Agent 实现
-
-```python
-# Claude Agent 实现
-class ClaudeAgent(BaseAgent):
-    def __init__(self, config: Dict[str, Any]):
-        super().__init__(config)
-        self.api_key = config.get('api_key')
-        self.model = config.get('model', 'claude-3-sonnet')
-    
-    def execute_command(self, command: str, context: Dict[str, Any]) -> str:
-        """执行 Claude 命令"""
-        try:
-            # 准备请求数据
-            request_data = self._prepare_request(command, context)
-            
-            # 调用 Claude API
-            response = self._call_claude_api(request_data)
-            
-            # 处理响应
-            return self._process_response(response)
-            
-        except Exception as e:
-            return self._handle_error(e)
-    
-    def check_availability(self) -> bool:
-        """检查 Claude API 是否可用"""
-        try:
-            # 测试 API 连接
-            test_response = self._call_claude_api({
-                'prompt': 'test',
-                'max_tokens': 1
-            })
-            return test_response is not None
-        except:
-            return False
-    
-    def get_capabilities(self) -> List[str]:
-        """获取 Claude 能力列表"""
-        return [
-            'code_generation',
-            'specification_analysis',
-            'technical_planning',
-            'code_review'
-        ]
-```
-
-### 2. Agent 路由器
-
-#### 路由策略
-
-```python
-class AgentRouter:
-    """AI Agent 路由器"""
-    
-    def __init__(self):
-        self.agents = {}
-        self.routing_strategies = {
-            'command_based': self._route_by_command,
-            'project_type': self._route_by_project_type,
-            'user_preference': self._route_by_preference,
-            'performance': self._route_by_performance
-        }
-    
-    def register_agent(self, agent: BaseAgent):
-        """注册 Agent"""
-        self.agents[agent.name] = agent
-    
-    def route_command(self, command: str, context: Dict[str, Any]) -> BaseAgent:
-        """路由命令到合适的 Agent"""
-        # 获取路由策略
-        strategy = context.get('routing_strategy', 'command_based')
-        
-        # 执行路由
-        if strategy in self.routing_strategies:
-            return self.routing_strategies[strategy](command, context)
-        else:
-            return self._default_route(command, context)
-    
-    def _route_by_command(self, command: str, context: Dict[str, Any]) -> BaseAgent:
-        """基于命令类型路由"""
-        command_type = self._classify_command(command)
-        
-        # 根据命令类型选择最适合的 Agent
-        if command_type == 'code_generation':
-            return self.agents.get('claude') or self._get_available_agent()
-        elif command_type == 'specification':
-            return self.agents.get('gemini') or self._get_available_agent()
-        else:
-            return self._get_available_agent()
-    
-    def _route_by_project_type(self, command: str, context: Dict[str, Any]) -> BaseAgent:
-        """基于项目类型路由"""
-        project_type = context.get('project_type', 'general')
-        
-        # 根据项目类型选择 Agent
-        if project_type == 'web_app':
-            return self.agents.get('cursor') or self._get_available_agent()
-        elif project_type == 'mobile_app':
-            return self.agents.get('claude') or self._get_available_agent()
-        else:
-            return self._get_available_agent()
-```
-
-### 3. Agent 配置管理
-
-#### 配置文件结构
-
-```yaml
-# agent-config.yaml
-agents:
-  claude:
-    enabled: true
-    api_key: ${CLAUDE_API_KEY}
-    model: claude-3-sonnet
-    capabilities:
-      - code_generation
-      - specification_analysis
-      - technical_planning
-  
-  gemini:
-    enabled: true
-    api_key: ${GEMINI_API_KEY}
-    model: gemini-pro
-    capabilities:
-      - multi_modal_understanding
-      - cross_platform_development
-  
-  cursor:
-    enabled: true
-    executable: cursor-agent
-    capabilities:
-      - modern_development
-      - full_stack_development
-  
-  copilot:
-    enabled: true
-    vscode_extension: true
-    capabilities:
-      - ide_integration
-      - real_time_assistance
-
-routing:
-  default_strategy: command_based
-  fallback_agent: claude
-  performance_threshold: 0.8
-```
-
-#### 配置加载机制
-
-```python
-class AgentConfigManager:
-    """Agent 配置管理器"""
-    
-    def __init__(self, config_path: str):
-        self.config_path = config_path
-        self.config = self._load_config()
-    
-    def _load_config(self) -> Dict[str, Any]:
-        """加载配置文件"""
-        try:
-            with open(self.config_path, 'r') as f:
-                config = yaml.safe_load(f)
-            return config
-        except Exception as e:
-            return self._get_default_config()
-    
-    def get_agent_config(self, agent_name: str) -> Dict[str, Any]:
-        """获取 Agent 配置"""
-        return self.config.get('agents', {}).get(agent_name, {})
-    
-    def is_agent_enabled(self, agent_name: str) -> bool:
-        """检查 Agent 是否启用"""
-        agent_config = self.get_agent_config(agent_name)
-        return agent_config.get('enabled', False)
-    
-    def get_routing_config(self) -> Dict[str, Any]:
-        """获取路由配置"""
-        return self.config.get('routing', {})
-```
-
-## 发布机制
-
-### 1. GitHub Actions 工作流
-
-#### 主工作流文件
-
-```yaml
-# .github/workflows/release.yml
-name: Release
-
-on:
-  push:
-    tags:
-      - 'v*'
-  workflow_dispatch:
-
-jobs:
-  release:
-    runs-on: ubuntu-latest
-    
-    steps:
-    - name: Checkout
-      uses: actions/checkout@v4
-      
-    - name: Set up Python
-      uses: actions/setup-python@v4
-      with:
-        python-version: '3.11'
-        
-    - name: Install uv
-      uses: astral-sh/setup-uv@v2
-      
-    - name: Install dependencies
-      run: uv sync
-      
-    - name: Run tests
-      run: uv run pytest
-      
-    - name: Build package
-      run: uv build
-      
-    - name: Create release
-      uses: actions/create-release@v1
-      env:
-        GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
-      with:
-        tag_name: ${{ github.ref }}
-        release_name: Release ${{ github.ref }}
-        draft: false
-        prerelease: false
-```
-
-#### 多平台构建
-
-```yaml
-# .github/workflows/build-packages.yml
-name: Build Packages
-
-on:
-  push:
-    tags:
-      - 'v*'
-
-jobs:
-  build:
-    strategy:
-      matrix:
-        os: [ubuntu-latest, windows-latest, macos-latest]
-        python-version: ['3.11', '3.12']
-    
-    runs-on: ${{ matrix.os }}
-    
-    steps:
-    - name: Checkout
-      uses: actions/checkout@v4
-      
-    - name: Set up Python
-      uses: actions/setup-python@v4
-      with:
-        python-version: ${{ matrix.python-version }}
-        
-    - name: Install uv
-      uses: astral-sh/setup-uv@v2
-      
-    - name: Build wheel
-      run: uv build
-      
-    - name: Upload artifacts
-      uses: actions/upload-artifact@v3
-      with:
-        name: wheel-${{ matrix.os }}-py${{ matrix.python-version }}
-        path: dist/*.whl
-```
-
-### 2. 包构建系统
-
-#### pyproject.toml 配置
-
-```toml
-[build-system]
-requires = ["hatchling"]
-build-backend = "hatchling.build"
-
-[project]
-name = "specify-cli"
-version = "0.0.4"
-description = "Specification-Driven Development CLI"
-authors = [
-    {name = "SpecKit Team", email = "team@speckit.dev"}
-]
-readme = "README.md"
-license = {text = "MIT"}
-requires-python = ">=3.11"
-classifiers = [
-    "Development Status :: 4 - Beta",
-    "Intended Audience :: Developers",
-    "License :: OSI Approved :: MIT License",
-    "Programming Language :: Python :: 3",
-    "Programming Language :: Python :: 3.11",
-    "Programming Language :: Python :: 3.12",
-]
-dependencies = [
-    "typer>=0.9.0",
-    "rich>=13.0.0",
-    "httpx>=0.24.0",
-    "pyyaml>=6.0",
-    "jinja2>=3.1.0",
-]
-
-[project.optional-dependencies]
-dev = [
-    "pytest>=7.0.0",
-    "pytest-cov>=4.0.0",
-    "black>=23.0.0",
-    "isort>=5.12.0",
-    "mypy>=1.0.0",
-]
-
-[project.scripts]
-specify = "specify_cli:main"
-
-[project.urls]
-Homepage = "https://github.com/github/spec-kit"
-Repository = "https://github.com/github/spec-kit"
-Documentation = "https://github.com/github/spec-kit#readme"
-Issues = "https://github.com/github/spec-kit/issues"
-
-[tool.hatch.build.targets.wheel]
-packages = ["src/specify_cli"]
-```
-
-#### 构建脚本
-
-```python
-# scripts/build.py
-import subprocess
-import sys
-from pathlib import Path
-
-def build_package():
-    """构建包"""
-    try:
-        # 清理之前的构建
-        subprocess.run([sys.executable, "-m", "build", "--clean"], check=True)
-        
-        # 构建包
-        subprocess.run([sys.executable, "-m", "build"], check=True)
-        
-        print("✅ 包构建成功")
-        
-    except subprocess.CalledProcessError as e:
-        print(f"❌ 构建失败: {e}")
-        sys.exit(1)
-
-if __name__ == "__main__":
-    build_package()
-```
-
-### 3. 发布管理
-
-#### 版本管理
-
-```python
-# scripts/version.py
-import re
-from pathlib import Path
-
-class VersionManager:
-    def __init__(self, project_root: Path):
-        self.project_root = project_root
-        self.pyproject_path = project_root / "pyproject.toml"
-    
-    def get_current_version(self) -> str:
-        """获取当前版本"""
-        content = self.pyproject_path.read_text()
-        match = re.search(r'version = "([^"]+)"', content)
-        if match:
-            return match.group(1)
-        raise ValueError("无法找到版本号")
-    
-    def bump_version(self, bump_type: str) -> str:
-        """升级版本"""
-        current_version = self.get_current_version()
-        major, minor, patch = map(int, current_version.split('.'))
-        
-        if bump_type == "major":
-            new_version = f"{major + 1}.0.0"
-        elif bump_type == "minor":
-            new_version = f"{major}.{minor + 1}.0"
-        elif bump_type == "patch":
-            new_version = f"{major}.{minor}.{patch + 1}"
-        else:
-            raise ValueError(f"不支持的版本升级类型: {bump_type}")
-        
-        # 更新 pyproject.toml
-        content = self.pyproject_path.read_text()
-        new_content = re.sub(
-            r'version = "[^"]+"',
-            f'version = "{new_version}"',
-            content
-        )
-        self.pyproject_path.write_text(new_content)
-        
-        return new_version
-    
-    def create_release_notes(self, version: str) -> str:
-        """创建发布说明"""
-        # 获取变更日志
-        changelog_path = self.project_root / "CHANGELOG.md"
-        if changelog_path.exists():
-            content = changelog_path.read_text()
-            # 提取版本相关的变更
-            pattern = rf"## {re.escape(version)}\s*\n(.*?)(?=\n## |$)"
-            match = re.search(pattern, content, re.DOTALL)
-            if match:
-                return match.group(1).strip()
-        
-        return f"Release {version}"
-```
-
-## 安装机制
-
-### 1. uvx 命令实现
-
-#### uvx 工作原理
-
-```python
-# uvx 命令解析
-def parse_uvx_command(command: str) -> Dict[str, str]:
-    """解析 uvx 命令"""
-    # 命令格式: uvx --from <source> <package> <command> [args]
-    parts = command.split()
-    
-    if len(parts) < 4:
-        raise ValueError("无效的 uvx 命令格式")
-    
-    return {
-        'source': parts[2],  # --from 后的源
-        'package': parts[3], # 包名
-        'command': parts[4] if len(parts) > 4 else None, # 命令
-        'args': parts[5:] if len(parts) > 5 else [] # 参数
-    }
-```
-
-#### 包下载和安装
-
-```python
-# 包下载机制
-class PackageDownloader:
-    def __init__(self):
-        self.cache_dir = Path.home() / ".cache" / "uvx"
-        self.cache_dir.mkdir(parents=True, exist_ok=True)
-    
-    def download_package(self, source: str) -> Path:
-        """下载包到缓存"""
-        # 生成缓存键
-        cache_key = hashlib.md5(source.encode()).hexdigest()
-        cache_path = self.cache_dir / cache_key
-        
-        # 检查缓存
-        if cache_path.exists():
-            return cache_path
-        
-        # 下载包
-        if source.startswith("git+"):
-            return self._download_from_git(source, cache_path)
-        elif source.startswith("https://"):
-            return self._download_from_url(source, cache_path)
-        else:
-            raise ValueError(f"不支持的源格式: {source}")
-    
-    def _download_from_git(self, source: str, cache_path: Path) -> Path:
-        """从 Git 仓库下载"""
-        # 解析 Git URL
-        git_url = source[4:]  # 移除 "git+" 前缀
-        
-        # 克隆仓库
-        subprocess.run([
-            "git", "clone", "--depth", "1", git_url, str(cache_path)
-        ], check=True)
-        
-        return cache_path
-```
-
-### 2. 项目初始化流程
-
-#### 初始化脚本
-
-```python
-# 项目初始化流程
-class ProjectInitializer:
-    def __init__(self, project_name: str, ai_agent: str):
-        self.project_name = project_name
-        self.ai_agent = ai_agent
-        self.project_path = Path(project_name)
-    
-    def initialize_project(self):
-        """初始化项目"""
-        try:
-            # 1. 创建项目目录
-            self._create_project_structure()
-            
-            # 2. 生成配置文件
-            self._generate_config_files()
-            
-            # 3. 设置 AI Agent
-            self._setup_ai_agent()
-            
-            # 4. 生成初始文档
-            self._generate_initial_docs()
-            
-            # 5. 初始化 Git 仓库
-            self._initialize_git_repo()
-            
-            print(f"✅ 项目 {self.project_name} 初始化成功")
-            
-        except Exception as e:
-            print(f"❌ 项目初始化失败: {e}")
-            raise
-    
-    def _create_project_structure(self):
-        """创建项目结构"""
-        directories = [
-            "memory",
-            "scripts/bash",
-            "scripts/powershell",
-            "templates/commands",
-            "update-notes",
-            f".{self.ai_agent}/commands"
-        ]
-        
-        for directory in directories:
-            (self.project_path / directory).mkdir(parents=True, exist_ok=True)
-    
-    def _generate_config_files(self):
-        """生成配置文件"""
-        # 生成 README.md
-        readme_content = self._generate_readme()
-        (self.project_path / "README.md").write_text(readme_content)
-        
-        # 生成项目宪法
-        constitution_content = self._generate_constitution()
-        (self.project_path / "memory" / "constitution.md").write_text(constitution_content)
-    
-    def _setup_ai_agent(self):
-        """设置 AI Agent"""
-        agent_config = {
-            'claude': self._setup_claude,
-            'gemini': self._setup_gemini,
-            'cursor': self._setup_cursor,
-            'copilot': self._setup_copilot
-        }
-        
-        if self.ai_agent in agent_config:
-            agent_config[self.ai_agent]()
-        else:
-            raise ValueError(f"不支持的 AI Agent: {self.ai_agent}")
-    
-    def _setup_claude(self):
-        """设置 Claude Agent"""
-        claude_dir = self.project_path / ".claude" / "commands"
-        claude_dir.mkdir(parents=True, exist_ok=True)
-        
-        # 生成 Claude 命令模板
-        for command in ['plan', 'specify', 'clarify', 'tasks', 'implement', 'analyze']:
-            template_content = self._generate_command_template(command, 'claude')
-            (claude_dir / f"{command}.md").write_text(template_content)
-```
-
-### 3. 跨平台支持
-
-#### 平台检测
-
-```python
-# 平台检测和脚本生成
-class PlatformManager:
-    def __init__(self):
-        self.platform = platform.system().lower()
-        self.script_extensions = {
-            'windows': '.ps1',
-            'linux': '.sh',
-            'darwin': '.sh'
-        }
-    
-    def get_script_extension(self) -> str:
-        """获取脚本扩展名"""
-        return self.script_extensions.get(self.platform, '.sh')
-    
-    def generate_scripts(self, project_path: Path):
-        """生成平台特定的脚本"""
-        if self.platform == 'windows':
-            self._generate_powershell_scripts(project_path)
-        else:
-            self._generate_bash_scripts(project_path)
-    
-    def _generate_powershell_scripts(self, project_path: Path):
-        """生成 PowerShell 脚本"""
-        scripts_dir = project_path / "scripts" / "powershell"
-        scripts_dir.mkdir(parents=True, exist_ok=True)
-        
-        # 生成 PowerShell 脚本
-        for script_name in ['check-prerequisites', 'setup-plan', 'create-new-feature']:
-            script_content = self._generate_powershell_script(script_name)
-            (scripts_dir / f"{script_name}.ps1").write_text(script_content)
-    
-    def _generate_bash_scripts(self, project_path: Path):
-        """生成 Bash 脚本"""
-        scripts_dir = project_path / "scripts" / "bash"
-        scripts_dir.mkdir(parents=True, exist_ok=True)
-        
-        # 生成 Bash 脚本
-        for script_name in ['check-prerequisites', 'setup-plan', 'create-new-feature']:
-            script_content = self._generate_bash_script(script_name)
-            (scripts_dir / f"{script_name}.sh").write_text(script_content)
-```
-
-## 扩展性设计
-
-### 1. 新 AI Agent 集成
-
-#### Agent 注册机制
-
-```python
-# Agent 注册系统
-class AgentRegistry:
-    def __init__(self):
-        self.agents = {}
-        self.agent_factories = {}
-    
-    def register_agent_factory(self, agent_name: str, factory_func):
-        """注册 Agent 工厂函数"""
-        self.agent_factories[agent_name] = factory_func
-    
-    def create_agent(self, agent_name: str, config: Dict[str, Any]) -> BaseAgent:
-        """创建 Agent 实例"""
-        if agent_name in self.agent_factories:
-            return self.agent_factories[agent_name](config)
-        else:
-            raise ValueError(f"未注册的 Agent: {agent_name}")
-    
-    def get_available_agents(self) -> List[str]:
-        """获取可用的 Agent 列表"""
-        return list(self.agent_factories.keys())
-
-# 注册新 Agent 的示例
-def register_new_agent():
-    """注册新 Agent 的示例"""
-    def create_custom_agent(config: Dict[str, Any]) -> BaseAgent:
-        return CustomAgent(config)
-    
-    registry = AgentRegistry()
-    registry.register_agent_factory('custom', create_custom_agent)
-```
-
-#### Agent 配置模板
-
-```yaml
-# 新 Agent 配置模板
-agents:
-  custom:
-    enabled: true
-    api_key: ${CUSTOM_API_KEY}
-    endpoint: https://api.custom.com/v1
-    model: custom-model
-    capabilities:
-      - custom_feature_1
-      - custom_feature_2
-    parameters:
-      temperature: 0.7
-      max_tokens: 4000
-      timeout: 30
-```
-
-### 2. 模板系统扩展
-
-#### 自定义模板
-
-```python
-# 模板系统扩展
-class TemplateManager:
-    def __init__(self, templates_dir: Path):
-        self.templates_dir = templates_dir
-        self.template_cache = {}
-    
-    def register_template(self, name: str, template_path: Path):
-        """注册新模板"""
-        if template_path.exists():
-            self.template_cache[name] = template_path
-        else:
-            raise FileNotFoundError(f"模板文件不存在: {template_path}")
-    
-    def render_template(self, name: str, context: Dict[str, Any]) -> str:
-        """渲染模板"""
-        if name not in self.template_cache:
-            raise ValueError(f"未注册的模板: {name}")
-        
-        template_path = self.template_cache[name]
-        template_content = template_path.read_text()
-        
-        # 使用 Jinja2 渲染模板
-        from jinja2 import Template
-        template = Template(template_content)
-        return template.render(**context)
-    
-    def create_custom_template(self, name: str, content: str):
-        """创建自定义模板"""
-        template_path = self.templates_dir / f"{name}.md"
-        template_path.write_text(content)
-        self.register_template(name, template_path)
-```
-
-### 3. 插件系统
-
-#### 插件接口
-
-```python
-# 插件系统接口
-class PluginInterface(ABC):
-    @abstractmethod
-    def get_name(self) -> str:
-        """获取插件名称"""
-        pass
-    
-    @abstractmethod
-    def get_version(self) -> str:
-        """获取插件版本"""
-        pass
-    
-    @abstractmethod
-    def get_capabilities(self) -> List[str]:
-        """获取插件能力"""
-        pass
-    
-    @abstractmethod
-    def execute(self, command: str, context: Dict[str, Any]) -> Any:
-        """执行插件功能"""
-        pass
-
-# 插件管理器
-class PluginManager:
-    def __init__(self):
-        self.plugins = {}
-        self.plugin_configs = {}
-    
-    def load_plugin(self, plugin_path: Path):
-        """加载插件"""
-        try:
-            # 动态导入插件模块
-            import importlib.util
-            spec = importlib.util.spec_from_file_location("plugin", plugin_path)
-            module = importlib.util.module_from_spec(spec)
-            spec.loader.exec_module(module)
-            
-            # 获取插件实例
-            plugin_instance = module.Plugin()
-            
-            # 注册插件
-            self.plugins[plugin_instance.get_name()] = plugin_instance
-            
-        except Exception as e:
-            print(f"加载插件失败: {e}")
-    
-    def execute_plugin(self, plugin_name: str, command: str, context: Dict[str, Any]):
-        """执行插件"""
-        if plugin_name in self.plugins:
-            plugin = self.plugins[plugin_name]
-            return plugin.execute(command, context)
-        else:
-            raise ValueError(f"未找到插件: {plugin_name}")
-```
-
-## 性能优化
-
-### 1. 缓存机制
-
-#### 多级缓存系统
-
-```python
-# 缓存系统
-class CacheManager:
-    def __init__(self):
-        self.memory_cache = {}
-        self.disk_cache = Path.home() / ".cache" / "speckit"
-        self.disk_cache.mkdir(parents=True, exist_ok=True)
-    
-    def get(self, key: str) -> Optional[Any]:
-        """获取缓存"""
-        # 1. 内存缓存
-        if key in self.memory_cache:
-            return self.memory_cache[key]
-        
-        # 2. 磁盘缓存
-        cache_file = self.disk_cache / f"{key}.json"
-        if cache_file.exists():
-            try:
-                import json
-                with open(cache_file, 'r') as f:
-                    data = json.load(f)
-                self.memory_cache[key] = data
-                return data
-            except:
-                pass
-        
-        return None
-    
-    def set(self, key: str, value: Any, ttl: int = 3600):
-        """设置缓存"""
-        # 内存缓存
-        self.memory_cache[key] = value
-        
-        # 磁盘缓存
-        cache_file = self.disk_cache / f"{key}.json"
-        try:
-            import json
-            with open(cache_file, 'w') as f:
-                json.dump(value, f)
-        except:
-            pass
-    
-    def clear(self, pattern: str = None):
-        """清理缓存"""
-        if pattern:
-            # 清理匹配的缓存
-            for key in list(self.memory_cache.keys()):
-                if pattern in key:
-                    del self.memory_cache[key]
-        else:
-            # 清理所有缓存
-            self.memory_cache.clear()
-            for cache_file in self.disk_cache.glob("*.json"):
-                cache_file.unlink()
-```
-
-### 2. 异步处理
-
-#### 异步命令执行
-
-```python
-# 异步处理系统
-import asyncio
-from concurrent.futures import ThreadPoolExecutor
-
-class AsyncCommandExecutor:
-    def __init__(self):
-        self.executor = ThreadPoolExecutor(max_workers=4)
-        self.semaphore = asyncio.Semaphore(10)  # 限制并发数
-    
-    async def execute_command(self, command: str, context: Dict[str, Any]) -> str:
-        """异步执行命令"""
-        async with self.semaphore:
-            # 在线程池中执行阻塞操作
-            loop = asyncio.get_event_loop()
-            result = await loop.run_in_executor(
-                self.executor,
-                self._execute_sync,
-                command,
-                context
-            )
-            return result
-    
-    def _execute_sync(self, command: str, context: Dict[str, Any]) -> str:
-        """同步执行命令"""
-        # 实际的命令执行逻辑
-        pass
-    
-    async def execute_multiple_commands(self, commands: List[Tuple[str, Dict[str, Any]]]) -> List[str]:
-        """并发执行多个命令"""
-        tasks = [
-            self.execute_command(command, context)
-            for command, context in commands
-        ]
-        return await asyncio.gather(*tasks)
-```
-
-### 3. 资源管理
-
-#### 连接池管理
-
-```python
-# 连接池管理
-class ConnectionPool:
-    def __init__(self, max_connections: int = 10):
-        self.max_connections = max_connections
-        self.connections = []
-        self.available_connections = []
-        self.lock = asyncio.Lock()
-    
-    async def get_connection(self):
-        """获取连接"""
-        async with self.lock:
-            if self.available_connections:
-                return self.available_connections.pop()
-            elif len(self.connections) < self.max_connections:
-                connection = await self._create_connection()
-                self.connections.append(connection)
-                return connection
-            else:
-                # 等待可用连接
-                while not self.available_connections:
-                    await asyncio.sleep(0.1)
-                return self.available_connections.pop()
-    
-    async def release_connection(self, connection):
-        """释放连接"""
-        async with self.lock:
-            self.available_connections.append(connection)
-    
-    async def _create_connection(self):
-        """创建新连接"""
-        # 创建连接的逻辑
-        pass
-```
-
-## 总结
-
-SpecKit 的工程化实现体现了现代软件开发的最佳实践：
-
-1. **模块化设计**: 清晰的组件分离和接口定义
-2. **可扩展架构**: 支持新 AI Agent 和插件的集成
-3. **跨平台支持**: 统一的接口，平台特定的实现
-4. **性能优化**: 多级缓存、异步处理、资源管理
-5. **质量保证**: 自动化测试、持续集成、版本管理
-
-这种设计确保了 SpecKit 的可靠性、可维护性和可扩展性，为规范驱动开发提供了强大的技术基础。
-
----
-
-**相关文档**:
-- [SpecKit 命令原理](./speckit-commands-principles.md) - 深入了解命令工作机制
-- [uvx 命令实现原理详解](./uvx-implementation-guide.md) - 安装机制详解
-- [实际项目开发流程指南](./practical-workflow-guide.md) - 实战应用
diff --git a/learn-spec-kit/speckit-theory-guide.md b/learn-spec-kit/speckit-theory-guide.md
deleted file mode 100644
index f75839c..0000000
--- a/learn-spec-kit/speckit-theory-guide.md
+++ /dev/null
@@ -1,121 +0,0 @@
-# SpecKit 理论介绍
-
-## 与 SDD 的关系
-
-**SpecKit 是 SDD（Specification-Driven Development）方法论的具体实现工具**
-
-### SDD 理论的具体化
-**规范可执行化**: 理论 → 通过结构化模板和AI助手实现 → 确保规范与实现一致性  
-**多步骤细化**: 理论 → 规范→计划→任务→实现流程 → 提高开发质量和可维护性  
-**技术无关性**: 理论 → 支持多种AI助手和技术栈 → 适应不同团队需求
-
-### SDD 理论的扩展
-**组织约束集成**: 自动集成企业级约束 → 提高企业适用性 → 通过模板和配置实现  
-**创意探索支持**: 支持并行实现和探索 → 鼓励创新实验 → 通过多方案支持实现  
-**团队协作优化**: 优化团队协作和知识共享 → 提高开发效率 → 通过标准化流程实现
-
-## 核心理念
-
-**SpecKit 让规范成为可执行的开发指令**
-
-传统开发中，规范文档往往与代码实现脱节，最终代码成为唯一的真实来源。SpecKit 颠覆了这种模式：**规范成为核心，代码成为规范的表达**。
-
-## 三大核心理论
-
-### 1. 规范可执行化
-**问题**: 规范文档与代码实现脱节，维护困难（如：需求文档写完后无人维护，最终代码成为唯一真实来源）  
-**解决**: 将静态规范转化为可执行的开发指令，规范成为单一真实来源（如：通过模板将用户故事自动转化为测试用例和API接口）
-
-### 2. 多步骤细化  
-**问题**: 一次性代码生成复杂且容易出错（如：直接让AI生成整个系统，结果质量参差不齐）  
-**解决**: 通过多步骤细化降低复杂性，每个步骤专注特定层面（如：先写规范，再做技术选型，再分解任务，最后实现）
-
-```
-需求 → 规范 → 计划 → 任务 → 实现
-（用户故事）（功能规范）（技术架构）（具体任务）（代码实现）
-```
-
-### 3. AI 助手集成
-**问题**: AI 助手被当作代码生成器使用（如：直接让AI写代码，缺乏规范指导）  
-**解决**: 将 AI 作为规范解释器，帮助理解、验证和优化规范（如：AI帮助澄清需求、验证规范完整性、优化架构设计）
-
-## 实现策略
-
-### 测试驱动开发（TDD）
-**核心理念**: 测试优先，确保质量（先写测试，再写代码）  
-**实现流程**: 规范 → 测试生成 → 测试失败 → 代码实现 → 测试通过  
-**价值**: 质量保证、规范验证、快速反馈（如：用户注册功能，先写测试用例验证邮箱格式，再实现注册逻辑）
-
-### 结构化规范
-**核心理念**: 通过模板确保规范完整性（避免遗漏重要信息）  
-**三层结构**: 功能规范层（用户故事） → 实现计划层（技术架构） → 任务分解层（具体任务）  
-**价值**: 完整性保证、一致性维护、可追溯性（如：从"用户登录"需求到"JWT认证实现"任务的完整追溯）
-
-### 模板自包含可执行
-**核心理念**: 每个模板都是独立可执行的完整流程（如：plan-template.md包含完整的9步执行流程）  
-**特点**: 自包含（内置验证逻辑）、可执行（明确输入输出）、可预测（相同输入相同输出）、可维护（逻辑清晰）  
-**价值**: 可预测性、可重复性、可验证性（如：每次运行plan命令都产生相同格式的实现计划）
-
-### 持续集成
-**核心理念**: 规范变更自动触发验证（规范更新时自动检查一致性）  
-**机制**: 多阶段验证（完整性→一致性→可执行性→可测试性）、自动化反馈（验证结果实时反馈）  
-**价值**: 质量保证、风险控制、团队协作（如：规范更新后自动生成测试用例，确保实现与规范一致）
-
-## 实践应用
-
-### 意图驱动开发
-**核心理念**: 从用户意图出发，逐步细化实现（如：用户说"我要一个购物车"，逐步细化为具体的功能规范）  
-**流程**: 用户意图 → 功能规范 → 实现计划 → 任务分解 → 具体实现  
-**价值**: 用户中心、逐步细化、质量保证（如：从"购物车"意图到"添加商品到购物车"的具体实现任务）
-
-### 组织约束集成
-**核心理念**: 自动集成企业级约束和合规要求（如：自动应用公司的技术栈选择和代码规范）  
-**约束类型**: 技术约束（React+TypeScript）、合规约束（GDPR数据保护）、团队约束（代码审查流程）  
-**价值**: 企业适用性、合规保证、团队协作（如：新项目自动继承公司的技术栈和开发规范）
-
-### 创意探索支持
-**核心理念**: 支持并行实现和创意探索（如：同时尝试不同的UI设计方案）  
-**探索模式**: 多方案探索（A/B测试不同实现）、技术栈多样性（React vs Vue）、用户体验实验（不同交互模式）  
-**价值**: 创新驱动、风险控制、学习价值（如：并行开发两个版本，对比效果后选择最佳方案）
-
-## 架构设计
-
-### 模板驱动架构
-**核心理念**: 通过模板实现规范结构化（如：所有项目都使用相同的spec-template.md结构）  
-**模板层次**: 规范模板层（spec/plan/tasks） + 命令模板层（commands/scripts/config）  
-**设计特点**: 自包含可执行，每个模板都是独立完整的流程（如：plan-template.md包含完整的9步执行流程）  
-**价值**: 标准化、可维护性、可执行性（如：新项目自动继承标准化的文档结构和开发流程）
-
-### 分层架构
-**核心理念**: 关注点分离，每层专注特定职责（如：UI层只处理用户交互，业务层只处理逻辑）  
-**三层结构**: 表示层（UI/命令） → 业务层（规范/模板/验证） → 数据层（存储/管理）  
-**价值**: 关注点分离、可测试性、可维护性（如：修改UI不影响业务逻辑，修改业务逻辑不影响数据存储）
-
-## 总结
-
-### 核心贡献
-SpecKit 通过7大理论创新实现规范驱动开发：
-1. **规范可执行化** - 静态规范 → 可执行指令
-2. **多步骤细化** - 降低复杂性，提高质量
-3. **测试驱动开发** - TDD作为核心策略
-4. **模板自包含可执行** - 独立完整的执行流程
-5. **技术无关性** - 关注过程而非技术
-6. **组织约束集成** - 企业级约束自动集成
-7. **创意探索支持** - 并行实现和实验
-
-### 核心价值
-- **开发效率**: 结构化开发流程
-- **质量保证**: 多阶段验证机制
-- **团队协作**: 标准化协作模式
-- **企业适用性**: 适应企业级需求
-- **创新驱动**: 鼓励创意和实验
-
-### 理论意义
-SpecKit 不仅是工具，更是新的开发理论体系。它帮助团队从"代码优先"转向"规范优先"，为现代软件开发提供新思路。
-
----
-
-**下一步学习**:
-- [安装和简单使用](./installation-and-quickstart.md) - 开始使用 SpecKit
-- [SpecKit 命令详解](./speckit-commands-guide.md) - 深入了解各个命令
-- [实际项目开发流程指南](./practical-workflow-guide.md) - 实战应用
diff --git a/learn-spec-kit/tasks-implicit-page-design-guide.md b/learn-spec-kit/tasks-implicit-page-design-guide.md
deleted file mode 100644
index 209fd75..0000000
--- a/learn-spec-kit/tasks-implicit-page-design-guide.md
+++ /dev/null
@@ -1,450 +0,0 @@
-# Tasks 隐式页面设计指南
-
-## 概述
-
-本指南深入解析 spec-kit 中 tasks 命令的隐式页面设计机制。通过分析 tasks 命令如何基于用户故事自动生成页面级别的开发任务，帮助开发者理解 spec-driven 开发中页面拆解的自动化过程。
-
-## 目录
-
-- [Tasks 隐式页面设计的概念](#tasks-隐式页面设计的概念)
-- [隐式页面设计的机制](#隐式页面设计的机制)
-- [任务生成规则分析](#任务生成规则分析)
-- [页面拆解的具体实现](#页面拆解的具体实现)
-- [与显式页面设计的关系](#与显式页面设计的关系)
-- [实际应用示例](#实际应用示例)
-- [优势与局限性](#优势与局限性)
-- [最佳实践建议](#最佳实践建议)
-- [常见问题解答](#常见问题解答)
-
-## Tasks 隐式页面设计的概念
-
-### 什么是隐式页面设计
-
-**隐式页面设计**是指在 tasks 命令执行过程中，基于用户故事自动生成页面级别开发任务的过程。这个过程不需要手动进行页面拆解，而是通过分析 quickstart.md 中的用户故事，自动推导出需要实现的页面和组件。
-
-### 与显式页面设计的区别
-
-| 方面 | 隐式页面设计 | 显式页面设计 |
-|------|-------------|-------------|
-| **触发时机** | tasks 命令执行时自动生成 | 设计师手动创建 |
-| **输入来源** | quickstart.md 中的用户故事 | 产品需求和设计规范 |
-| **输出内容** | 功能性的页面和组件任务 | 视觉化的界面设计 |
-| **关注重点** | 用户交互逻辑和功能实现 | 视觉表现和用户体验 |
-| **技术细节** | 不涉及具体的技术实现 | 包含布局、颜色、字体等 |
-
-## 隐式页面设计的机制
-
-### 1. 输入分析阶段
-
-```mermaid
-graph TD
-    A[quickstart.md<br/>用户故事] --> B[tasks 命令]
-    B --> C[解析用户故事]
-    C --> D[识别页面需求]
-    D --> E[生成 UI 任务]
-    
-    style B fill:#e1f5fe
-    style E fill:#f3e5f5
-```
-
-**输入来源**：
-- `quickstart.md` 中的用户故事
-- `data-model.md` 中的数据实体
-- `contracts/` 中的 API 端点
-- `plan.md` 中的技术栈信息
-
-### 2. 故事解析过程
-
-tasks 命令会分析用户故事中的关键信息：
-
-```text
-# 用户故事示例
-"When you first launch Taskify, it's going to give you a list of the five users to pick from"
-"When you click on a user, you go into the main view, which displays the list of projects"
-"When you click on a project, you open the Kanban board for that project"
-```
-
-**解析结果**：
-- 识别页面：用户选择页面、项目列表页面、看板页面
-- 识别组件：用户选择器、项目卡片、任务卡片
-- 识别交互：点击、拖拽、状态更新
-
-### 3. 任务生成规则
-
-基于 `templates/commands/tasks.md` 中的规则：
-
-```markdown
-4. Task generation rules:
-   - Each contract file → contract test task marked [P]
-   - Each entity in data-model → model creation task marked [P]
-   - Each endpoint → implementation task (not parallel if shared files)
-   - Each user story → integration test marked [P]  # ← 关键规则
-   - Different files = can be parallel [P]
-   - Same file = sequential (no [P])
-```
-
-## 任务生成规则分析
-
-### 1. 路径约定规则
-
-从 `templates/tasks-template.md` 第39-43行：
-
-```markdown
-## Path Conventions
-- **Single project**: `src/`, `tests/` at repository root
-- **Web app**: `backend/src/`, `frontend/src/`  # ← 支持前端项目
-- **Mobile**: `api/src/`, `ios/src/` or `android/src/`
-```
-
-**关键点**：
-- 自动识别项目类型（单项目/Web应用/移动应用）
-- 根据项目类型生成对应的目录结构
-- 为前端项目生成 `frontend/src/` 路径
-
-### 2. 任务分类规则
-
-```markdown
-3. Generate tasks following the template:
-   - **Setup tasks**: Project init, dependencies, linting
-   - **Test tasks [P]**: One per contract, one per integration scenario
-   - **Core tasks**: One per entity, service, CLI command, endpoint
-   - **Integration tasks**: DB connections, middleware, logging
-   - **Polish tasks [P]**: Unit tests, performance, docs
-```
-
-**UI 相关任务归类**：
-- **Core tasks**：页面组件、UI 服务
-- **Integration tasks**：前端与后端的集成
-- **Test tasks**：UI 组件的测试
-
-### 3. 依赖排序规则
-
-从 `plan-template.md` 第199行：
-
-```markdown
-**Ordering Strategy**:
-- TDD order: Tests before implementation 
-- Dependency order: Models before services before UI  # ← UI 任务排序
-- Mark [P] for parallel execution (independent files)
-```
-
-**排序逻辑**：
-1. **Setup** → 项目初始化
-2. **Tests** → 测试用例编写
-3. **Models** → 数据模型
-4. **Services** → 业务服务
-5. **UI** → 页面和组件实现
-6. **Integration** → 系统集成
-7. **Polish** → 优化和文档
-
-## 页面拆解的具体实现
-
-### 1. 基于用户故事的任务生成
-
-```mermaid
-graph TD
-    A[用户故事] --> B[故事分析]
-    B --> C[页面识别]
-    B --> D[组件识别]
-    B --> E[交互识别]
-    
-    C --> F[页面任务]
-    D --> G[组件任务]
-    E --> H[功能任务]
-    
-    F --> I[具体实现任务]
-    G --> I
-    H --> I
-    
-    style I fill:#e1f5fe
-```
-
-### 2. 实际任务生成示例
-
-基于 Taskify 项目的用户故事：
-
-```markdown
-# 生成的页面任务示例
-## Phase 3.3: Core Implementation
-- [ ] T008 [P] User selection page in frontend/src/pages/UserSelectionPage.vue
-- [ ] T009 [P] Project list page in frontend/src/pages/ProjectListPage.vue
-- [ ] T010 [P] Kanban board page in frontend/src/pages/KanbanBoardPage.vue
-- [ ] T011 [P] Task card component in frontend/src/components/TaskCard.vue
-- [ ] T012 [P] Comment section component in frontend/src/components/CommentSection.vue
-- [ ] T013 [P] Drag and drop functionality in frontend/src/utils/dragDrop.js
-- [ ] T014 [P] User authentication state management in frontend/src/stores/auth.js
-```
-
-### 3. 任务依赖关系
-
-```mermaid
-graph TD
-    A[T008: 用户选择页面] --> B[T009: 项目列表页面]
-    B --> C[T010: 看板页面]
-    D[T011: 任务卡片组件] --> C
-    E[T012: 评论组件] --> C
-    F[T013: 拖拽功能] --> C
-    G[T014: 状态管理] --> A
-    G --> B
-    G --> C
-    
-    style A fill:#e1f5fe
-    style B fill:#e1f5fe
-    style C fill:#e1f5fe
-```
-
-## 与显式页面设计的关系
-
-### 1. 互补关系
-
-```mermaid
-graph TD
-    A[用户需求] --> B[quickstart.md<br/>用户故事]
-    B --> C[tasks 命令<br/>隐式页面设计]
-    C --> D[功能页面任务]
-    
-    A --> E[产品设计<br/>显式页面设计]
-    E --> F[视觉原型]
-    E --> G[交互设计]
-    E --> H[品牌规范]
-    
-    D --> I[开发实现]
-    F --> I
-    G --> I
-    H --> I
-    
-    style C fill:#e1f5fe
-    style E fill:#f3e5f5
-```
-
-### 2. 协作模式
-
-**理想协作流程**：
-1. **产品经理**：提供用户故事和功能需求
-2. **tasks 命令**：基于用户故事生成功能页面任务
-3. **UI/UX 设计师**：基于功能页面任务进行视觉设计
-4. **开发团队**：结合功能任务和视觉设计进行实现
-
-### 3. 信息传递
-
-```mermaid
-sequenceDiagram
-    participant PM as 产品经理
-    participant Tasks as Tasks 命令
-    participant Designer as UI/UX 设计师
-    participant Dev as 开发团队
-    
-    PM->>Tasks: 提供 quickstart.md
-    Tasks->>Tasks: 生成页面任务
-    Tasks->>Designer: 提供功能页面列表
-    Designer->>Designer: 进行视觉设计
-    Designer->>Dev: 提供设计规范 + 功能任务
-    Dev->>Dev: 实现功能 + 视觉
-```
-
-## 实际应用示例
-
-### 1. 电商网站示例
-
-**用户故事**：
-```text
-"As a customer, I want to browse products by category so that I can find what I'm looking for"
-"As a customer, I want to add items to my cart so that I can purchase them later"
-"As a customer, I want to checkout securely so that I can complete my purchase"
-```
-
-**生成的页面任务**：
-```markdown
-- [ ] T008 [P] Product category page in frontend/src/pages/CategoryPage.vue
-- [ ] T009 [P] Product listing component in frontend/src/components/ProductList.vue
-- [ ] T010 [P] Product card component in frontend/src/components/ProductCard.vue
-- [ ] T011 [P] Shopping cart page in frontend/src/pages/CartPage.vue
-- [ ] T012 [P] Cart item component in frontend/src/components/CartItem.vue
-- [ ] T013 [P] Checkout page in frontend/src/pages/CheckoutPage.vue
-- [ ] T014 [P] Payment form component in frontend/src/components/PaymentForm.vue
-```
-
-### 2. 博客系统示例
-
-**用户故事**：
-```text
-"As a reader, I want to see a list of blog posts so that I can choose what to read"
-"As a reader, I want to read individual blog posts so that I can get the information I need"
-"As a reader, I want to search for posts so that I can find specific topics"
-```
-
-**生成的页面任务**：
-```markdown
-- [ ] T008 [P] Blog home page in frontend/src/pages/BlogHomePage.vue
-- [ ] T009 [P] Post list component in frontend/src/components/PostList.vue
-- [ ] T010 [P] Post card component in frontend/src/components/PostCard.vue
-- [ ] T011 [P] Post detail page in frontend/src/pages/PostDetailPage.vue
-- [ ] T012 [P] Search functionality in frontend/src/components/SearchBar.vue
-- [ ] T013 [P] Search results page in frontend/src/pages/SearchResultsPage.vue
-```
-
-## 优势与局限性
-
-### 优势
-
-#### 1. 自动化程度高
-- ✅ **无需手动拆解**：基于用户故事自动生成页面任务
-- ✅ **减少重复工作**：避免每次都要手动分析页面结构
-- ✅ **提高效率**：快速生成可执行的开发任务
-
-#### 2. 功能导向
-- ✅ **用户需求驱动**：确保页面实现符合用户期望
-- ✅ **测试驱动**：每个页面任务都有对应的测试场景
-- ✅ **业务逻辑清晰**：基于用户故事的业务流程生成任务
-
-#### 3. 开发效率
-- ✅ **任务粒度合适**：每个任务都是可独立完成的功能单元
-- ✅ **依赖关系明确**：自动处理任务之间的依赖关系
-- ✅ **并行执行支持**：标记可并行执行的任务
-
-### 局限性
-
-#### 1. 缺乏视觉设计
-- ❌ **无布局信息**：不知道元素在页面上的具体位置
-- ❌ **无颜色方案**：没有定义页面的色彩搭配
-- ❌ **无字体规范**：没有指定字体类型和大小
-- ❌ **无图标设计**：没有定义图标和视觉元素
-
-#### 2. 缺乏交互细节
-- ❌ **无动画效果**：没有定义页面过渡和交互动画
-- ❌ **无状态反馈**：没有定义加载、错误等状态的表现
-- ❌ **无响应式设计**：没有考虑不同屏幕尺寸的适配
-
-#### 3. 缺乏品牌表达
-- ❌ **无品牌风格**：没有体现产品的视觉风格
-- ❌ **无情感设计**：没有考虑用户的情感体验
-- ❌ **无差异化**：生成的页面可能缺乏独特性
-
-## 最佳实践建议
-
-### 1. 结合显式设计
-
-**推荐工作流程**：
-```mermaid
-graph TD
-    A[用户需求] --> B[quickstart.md]
-    B --> C[tasks 命令]
-    C --> D[功能页面任务]
-    
-    A --> E[UI/UX 设计]
-    E --> F[视觉原型]
-    E --> G[交互规范]
-    
-    D --> H[开发实现]
-    F --> H
-    G --> H
-    
-    style C fill:#e1f5fe
-    style E fill:#f3e5f5
-    style H fill:#e8f5e8
-```
-
-### 2. 任务细化策略
-
-**对于复杂页面**：
-- 将大页面拆分为多个小组件任务
-- 为每个组件定义清晰的职责边界
-- 确保组件之间的接口设计合理
-
-**示例**：
-```markdown
-# 复杂页面的任务拆分
-- [ ] T008 [P] User dashboard layout in frontend/src/layouts/DashboardLayout.vue
-- [ ] T009 [P] Navigation sidebar in frontend/src/components/NavigationSidebar.vue
-- [ ] T010 [P] User profile section in frontend/src/components/UserProfile.vue
-- [ ] T011 [P] Activity feed component in frontend/src/components/ActivityFeed.vue
-- [ ] T012 [P] Quick actions panel in frontend/src/components/QuickActions.vue
-```
-
-### 3. 测试策略
-
-**为每个页面任务编写测试**：
-```markdown
-# 测试任务示例
-- [ ] T008 [P] User selection page in frontend/src/pages/UserSelectionPage.vue
-- [ ] T009 [P] Test user selection page in frontend/src/tests/pages/UserSelectionPage.test.js
-- [ ] T010 [P] Test user selection component in frontend/src/tests/components/UserSelection.test.js
-```
-
-### 4. 文档化策略
-
-**为生成的页面任务添加文档**：
-```markdown
-# 任务文档示例
-## T008: User Selection Page
-**Purpose**: Allow users to select their identity when launching the application
-**Dependencies**: T001-T007 (Setup and tests)
-**Acceptance Criteria**:
-- Display 5 user selection buttons
-- Handle user click events
-- Navigate to main view after selection
-**Files**: frontend/src/pages/UserSelectionPage.vue
-```
-
-## 常见问题解答
-
-### Q1: 隐式页面设计能完全替代显式设计吗？
-
-**A**: 不能。隐式页面设计专注于功能实现，而显式设计专注于用户体验。两者应该结合使用：
-- **隐式设计**：确保功能完整性
-- **显式设计**：确保用户体验质量
-
-### Q2: 如何确保生成的页面任务质量？
-
-**A**: 通过以下方式确保质量：
-- **详细的用户故事**：在 quickstart.md 中提供清晰的用户故事
-- **测试驱动**：为每个页面任务编写对应的测试
-- **代码审查**：在实现过程中进行代码审查
-- **用户反馈**：通过用户测试验证页面功能
-
-### Q3: 生成的页面任务可以修改吗？
-
-**A**: 可以。tasks 命令生成的是建议性的任务列表，开发团队可以根据实际情况进行调整：
-- **添加任务**：补充遗漏的功能
-- **删除任务**：移除不必要的功能
-- **修改任务**：调整任务的实现方式
-- **重新排序**：调整任务的执行顺序
-
-### Q4: 如何处理复杂的页面交互？
-
-**A**: 对于复杂交互，建议：
-- **拆分为多个任务**：将复杂交互分解为多个简单任务
-- **定义中间状态**：明确交互过程中的中间状态
-- **编写详细测试**：为复杂交互编写全面的测试用例
-- **原型验证**：在实现前创建交互原型进行验证
-
-### Q5: 隐式页面设计适合所有类型的项目吗？
-
-**A**: 适合大多数项目，但有一些限制：
-- **适合**：功能导向的 Web 应用、管理后台、工具类应用
-- **不太适合**：高度定制化的品牌网站、游戏界面、艺术类应用
-- **需要补充**：所有项目都需要显式设计来完善用户体验
-
-## 总结
-
-Tasks 命令的隐式页面设计是 spec-driven 开发的一个重要特性，它通过自动化页面任务生成，显著提高了开发效率。然而，它不能完全替代显式页面设计，两者应该结合使用：
-
-### 核心价值
-- ✅ **自动化页面拆解**：基于用户故事自动生成页面任务
-- ✅ **功能导向开发**：确保页面实现符合用户需求
-- ✅ **提高开发效率**：减少手动页面拆解的工作量
-- ✅ **测试驱动开发**：为每个页面任务提供测试支持
-
-### 使用建议
-- 将隐式页面设计作为功能开发的基础
-- 结合显式设计完善用户体验
-- 根据项目特点调整任务生成策略
-- 持续优化和改进页面任务质量
-
-通过正确理解和使用隐式页面设计，可以显著提高 spec-driven 开发的效率和质量，同时为后续的显式设计提供良好的功能基础。
-
----
-
-*本文档基于 spec-kit 项目分析整理，如有疑问请参考项目源码或相关文档。*
-
-
diff --git a/learn-spec-kit/templates-system-guide.md b/learn-spec-kit/templates-system-guide.md
deleted file mode 100644
index a9cbc98..0000000
--- a/learn-spec-kit/templates-system-guide.md
+++ /dev/null
@@ -1,491 +0,0 @@
-# Templates 模板系统指南
-
-## 概述
-
-Templates 目录是 spec-kit 项目的模板系统核心，包含了用于生成项目文档、计划和任务的标准化模板。这些模板为 spec-driven 开发流程提供了结构化的文档框架，确保项目的一致性和完整性。
-
-## 目录结构
-
-```
-templates/
-├── agent-file-template.md          # AI 代理文件模板
-├── commands/                       # 命令模板目录
-│   ├── analyze.md                  # 分析命令模板
-│   ├── clarify.md                  # 澄清命令模板
-│   ├── constitution.md              # 宪法命令模板
-│   ├── implement.md                # 实现命令模板
-│   ├── plan.md                     # 计划命令模板
-│   ├── specify.md                  # 规范命令模板
-│   └── tasks.md                    # 任务命令模板
-├── plan-template.md                # 实现计划模板
-├── spec-template.md                # 功能规范模板
-└── tasks-template.md               # 任务列表模板
-```
-
-## 核心模板详解
-
-### 1. spec-template.md - 功能规范模板
-
-**作用**: 为功能规范文档提供标准化结构，确保所有功能都有完整、一致的规范定义。
-
-#### 文档结构
-
-```markdown
-# Feature Specification: [FEATURE NAME]
-**Feature Branch**: `[###-feature-name]`
-**Created**: [DATE]
-**Status**: Draft
-**Input**: User description: "$ARGUMENTS"
-```
-
-#### 核心部分
-
-1. **执行流程 (Execution Flow)**
-   - 定义了规范创建的主要步骤
-   - 包含错误处理和验证逻辑
-   - 确保规范的完整性和质量
-
-2. **快速指南 (Quick Guidelines)**
-   - ✅ 专注于用户需求和原因
-   - ❌ 避免实现细节（技术栈、API、代码结构）
-   - 👥 为业务利益相关者编写，而非开发者
-
-3. **用户场景和测试 (User Scenarios & Testing)**
-   - **主要用户故事**: 描述主要用户旅程
-   - **验收场景**: Given-When-Then 格式
-   - **边界情况**: 处理边界条件和错误场景
-
-4. **需求 (Requirements)**
-   - **功能需求**: 具体的、可测试的能力要求
-   - **关键实体**: 涉及数据时的实体定义
-   - **模糊需求标记**: 使用 `[NEEDS CLARIFICATION]` 标记
-
-5. **审查和验收检查清单**
-   - **内容质量**: 无实现细节、专注用户价值
-   - **需求完整性**: 无模糊标记、可测试、可测量
-
-#### 使用场景
-
-- 创建新功能时作为起始模板
-- 确保规范文档的标准化
-- 指导 AI 代理生成规范内容
-
-### 2. plan-template.md - 实现计划模板
-
-**作用**: 为功能实现提供详细的技术规划和设计指导。
-
-#### 文档结构
-
-```markdown
-# Implementation Plan: [FEATURE]
-**Branch**: `[###-feature-name]` | **Date**: [DATE] | **Spec**: [link]
-**Input**: Feature specification from `/specs/[###-feature-name]/spec.md`
-```
-
-#### 核心部分
-
-1. **执行流程 (/plan 命令范围)**
-   - 定义了计划创建的主要步骤
-   - 包含宪法检查和验证逻辑
-   - 分阶段执行：研究 → 设计 → 任务规划
-
-2. **技术上下文 (Technical Context)**
-   - 编程语言/版本
-   - 主要依赖
-   - 存储方案
-   - 测试框架
-   - 目标平台
-   - 项目类型
-   - 性能目标
-   - 约束条件
-   - 规模/范围
-
-3. **宪法检查 (Constitution Check)**
-   - **简洁性**: 项目数量、框架使用、数据模型
-   - **架构**: 库优先、CLI 接口、文档要求
-   - **测试**: TDD 强制、测试顺序、真实依赖
-   - **可观测性**: 结构化日志、错误上下文
-   - **版本控制**: 版本号、破坏性变更处理
-
-4. **项目结构 (Project Structure)**
-   - 文档结构（功能相关）
-   - 源代码结构（单项目/Web应用/移动应用）
-   - 结构决策逻辑
-
-5. **分阶段执行**
-   - **Phase 0**: 研究和概述
-   - **Phase 1**: 设计和合约
-   - **Phase 2**: 任务规划方法
-   - **Phase 3+**: 未来实现
-
-#### 使用场景
-
-- 从功能规范生成实现计划
-- 指导技术选型和架构设计
-- 确保符合项目宪法要求
-
-### 3. tasks-template.md - 任务列表模板
-
-**作用**: 为功能实现提供具体的、可执行的任务列表。
-
-#### 文档结构
-
-```markdown
-# Tasks: [FEATURE NAME]
-**Input**: Design documents from `/specs/[###-feature-name]/`
-**Prerequisites**: plan.md (required), research.md, data-model.md, contracts/
-```
-
-#### 核心部分
-
-1. **执行流程 (Execution Flow)**
-   - 定义任务生成的主要步骤
-   - 包含任务验证和完整性检查
-   - 确保任务的可执行性
-
-2. **任务格式**
-   - `[ID] [P?] Description` 格式
-   - `[P]` 标记可并行执行的任务
-   - 包含确切的文件路径
-
-3. **分阶段任务**
-   - **Phase 3.1**: 设置（项目结构、依赖、工具）
-   - **Phase 3.2**: 测试优先（TDD 强制）
-   - **Phase 3.3**: 核心实现
-   - **Phase 3.4**: 集成
-   - **Phase 3.5**: 完善
-
-4. **依赖关系**
-   - 测试在实现之前
-   - 模型在服务之前
-   - 服务在端点之前
-   - 实现在完善之前
-
-5. **并行执行示例**
-   - 展示可并行执行的任务组
-   - 提供具体的执行命令
-
-#### 使用场景
-
-- 从设计文档生成具体任务
-- 指导开发团队按顺序执行
-- 支持并行开发工作
-
-### 4. agent-file-template.md - AI 代理文件模板
-
-**作用**: 为 AI 代理提供项目上下文和开发指导。
-
-#### 文档结构
-
-```markdown
-# [PROJECT NAME] Development Guidelines
-Auto-generated from all feature plans. Last updated: [DATE]
-```
-
-#### 核心部分
-
-1. **活跃技术 (Active Technologies)**
-   - 从所有计划文件中提取的技术栈
-   - 包含编程语言、框架、工具
-
-2. **项目结构 (Project Structure)**
-   - 基于实际计划的项目结构
-   - 反映当前的项目组织
-
-3. **命令 (Commands)**
-   - 仅包含活跃技术的命令
-   - 提供具体的执行指令
-
-4. **代码风格 (Code Style)**
-   - 语言特定的编码规范
-   - 仅包含正在使用的语言
-
-5. **最近变更 (Recent Changes)**
-   - 最后3个功能及其添加内容
-   - 保持变更历史的简洁性
-
-6. **手动添加部分**
-   - 保留手动添加的内容
-   - 支持自定义指导
-
-#### 使用场景
-
-- 为 AI 代理提供项目上下文
-- 确保 AI 建议符合项目标准
-- 维护开发指导的一致性
-
-### 5. commands/ 命令模板目录
-
-**作用**: 为不同 AI 代理提供标准化的命令执行模板。
-
-#### 命令模板详解
-
-##### 1. commands/specify.md - 规范命令模板
-- 定义 `/specify` 命令的执行逻辑
-- 调用 `create-new-feature.sh` 脚本
-- 生成功能规范文档
-
-##### 2. commands/plan.md - 计划命令模板  
-- 定义 `/plan` 命令的执行逻辑
-- 调用 `setup-plan.sh` 脚本
-- 生成实现计划文档
-
-##### 3. commands/tasks.md - 任务命令模板
-- 定义 `/tasks` 命令的执行逻辑
-- 调用 `check-prerequisites.sh` 脚本
-- 生成任务列表文档
-
-##### 4. commands/clarify.md - 澄清命令模板
-- 定义 `/clarify` 命令的执行逻辑
-- 识别规范中的模糊点
-- 通过交互式问答澄清需求
-
-##### 5. commands/analyze.md - 分析命令模板
-- 定义 `/analyze` 命令的执行逻辑
-- 执行跨文档一致性分析
-- 生成质量分析报告
-
-##### 6. commands/constitution.md - 宪法命令模板
-- 定义 `/constitution` 命令的执行逻辑
-- 创建或更新项目宪法
-- 管理宪法版本和同步
-
-##### 7. commands/implement.md - 实现命令模板
-- 定义 `/implement` 命令的执行逻辑
-- 执行任务列表中的实现步骤
-- 按阶段完成功能开发
-
-## 命令模板详解
-
-### 1. commands/specify.md - 规范命令模板
-
-**作用**: 定义 `/specify` 命令的执行逻辑和脚本调用。
-
-#### 核心功能
-
-1. **脚本调用**
-   - Bash: `scripts/bash/create-new-feature.sh --json "{ARGS}"`
-   - PowerShell: `scripts/powershell/create-new-feature.ps1 -Json "{ARGS}"`
-
-2. **执行步骤**
-   - 运行脚本并解析 JSON 输出
-   - 加载规范模板
-   - 写入规范文件
-   - 报告完成状态
-
-3. **输出信息**
-   - 分支名称
-   - 规范文件路径
-   - 下一阶段准备状态
-
-#### 使用场景
-
-- AI 代理执行规范创建命令
-- 确保规范创建流程的一致性
-- 提供标准化的命令接口
-
-### 2. commands/plan.md - 计划命令模板
-
-**作用**: 定义 `/plan` 命令的执行逻辑和实现计划生成。
-
-#### 核心功能
-
-1. **脚本调用**
-   - Bash: `scripts/bash/setup-plan.sh --json`
-   - PowerShell: `scripts/powershell/setup-plan.ps1 -Json`
-
-2. **执行步骤**
-   - 运行脚本并解析输出
-   - 读取和分析功能规范
-   - 读取宪法要求
-   - 执行实现计划模板
-   - 验证执行完成
-
-3. **生成文档**
-   - Phase 0: research.md
-   - Phase 1: data-model.md, contracts/, quickstart.md
-   - Phase 2: tasks.md
-
-#### 使用场景
-
-- AI 代理执行计划创建命令
-- 确保计划生成流程的一致性
-- 提供标准化的计划接口
-
-### 3. commands/tasks.md - 任务命令模板
-
-**作用**: 定义 `/tasks` 命令的执行逻辑和任务生成。
-
-#### 核心功能
-
-1. **脚本调用**
-   - Bash: `scripts/bash/check-prerequisites.sh --json`
-   - PowerShell: `scripts/powershell/check-prerequisites.ps1 -Json`
-
-2. **执行步骤**
-   - 运行脚本并解析输出
-   - 加载和分析设计文档
-   - 生成任务列表
-   - 应用任务规则
-   - 创建任务文件
-
-3. **任务生成规则**
-   - 从合约生成合约测试任务
-   - 从数据模型生成模型任务
-   - 从用户故事生成集成测试任务
-   - 按依赖关系排序任务
-
-#### 使用场景
-
-- AI 代理执行任务生成命令
-- 确保任务生成流程的一致性
-- 提供标准化的任务接口
-
-## 模板系统特点
-
-### 1. 结构化设计
-
-- **标准化格式**: 所有模板都遵循一致的结构
-- **占位符系统**: 使用 `[PLACEHOLDER]` 标记需要替换的内容
-- **版本控制**: 模板包含版本信息和更新日期
-
-### 2. 自动化集成
-
-- **脚本集成**: 模板与脚本系统紧密集成
-- **AI 代理支持**: 为 AI 代理提供标准化的执行指导
-- **跨平台兼容**: 支持 Bash 和 PowerShell 两种脚本
-
-### 3. 质量保证
-
-- **验证检查**: 模板包含质量验证检查清单
-- **错误处理**: 定义明确的错误处理逻辑
-- **完整性检查**: 确保生成文档的完整性
-
-### 4. 可扩展性
-
-- **模块化设计**: 模板可以独立使用或组合使用
-- **自定义支持**: 支持手动添加和自定义内容
-- **版本管理**: 支持模板的版本控制和更新
-
-## 使用工作流
-
-### 1. 功能开发流程
-
-1. **创建规范**:
-   ```bash
-   # 使用 specify 命令
-   /specify "用户认证系统"
-   # 生成 spec.md 文件
-   ```
-
-2. **生成计划**:
-   ```bash
-   # 使用 plan 命令
-   /plan "Python 3.11, FastAPI, PostgreSQL"
-   # 生成 plan.md, research.md, data-model.md 等
-   ```
-
-3. **创建任务**:
-   ```bash
-   # 使用 tasks 命令
-   /tasks
-   # 生成 tasks.md 文件
-   ```
-
-### 2. 模板自定义
-
-1. **修改现有模板**:
-   - 编辑模板文件
-   - 更新占位符和结构
-   - 测试模板生成
-
-2. **创建新模板**:
-   - 基于现有模板创建
-   - 定义新的结构和占位符
-   - 集成到命令系统中
-
-### 3. 质量保证
-
-1. **模板验证**:
-   - 检查占位符完整性
-   - 验证结构一致性
-   - 测试生成流程
-
-2. **文档审查**:
-   - 检查生成文档的质量
-   - 验证内容完整性
-   - 确保符合项目标准
-
-## 最佳实践
-
-### 1. 模板设计
-
-- **保持简洁**: 模板应该清晰、简洁、易于理解
-- **避免重复**: 避免在模板中重复相同的内容
-- **明确占位符**: 使用清晰的占位符命名
-- **版本控制**: 为模板添加版本信息
-
-### 2. 内容生成
-
-- **遵循结构**: 严格按照模板结构生成内容
-- **填充占位符**: 确保所有占位符都被正确替换
-- **质量检查**: 生成后检查内容质量
-- **验证完整性**: 确保生成文档的完整性
-
-### 3. 维护更新
-
-- **定期审查**: 定期审查模板的有效性
-- **版本同步**: 保持模板版本与项目版本同步
-- **文档更新**: 及时更新相关文档
-- **测试验证**: 更新后测试模板生成
-
-## 故障排除
-
-### 常见问题
-
-1. **占位符未替换**:
-   - 检查占位符格式是否正确
-   - 验证替换逻辑是否完整
-   - 确认数据源是否可用
-
-2. **结构不完整**:
-   - 检查模板结构是否完整
-   - 验证必需部分是否包含
-   - 确认生成逻辑是否正确
-
-3. **质量检查失败**:
-   - 检查内容是否符合要求
-   - 验证格式是否正确
-   - 确认完整性是否满足
-
-### 调试技巧
-
-1. **使用调试模式**: 启用详细的调试输出
-2. **检查中间结果**: 查看生成过程中的中间文件
-3. **验证输入数据**: 确认输入数据的正确性
-4. **测试模板**: 使用测试数据验证模板
-
-## 扩展和自定义
-
-### 1. 添加新模板
-
-1. 创建新的模板文件
-2. 定义模板结构和占位符
-3. 集成到命令系统中
-4. 更新相关文档
-
-### 2. 修改现有模板
-
-1. 备份原始模板
-2. 进行必要的修改
-3. 测试修改后的模板
-4. 更新版本信息
-
-### 3. 集成新功能
-
-1. 分析新功能需求
-2. 设计相应的模板结构
-3. 实现模板生成逻辑
-4. 集成到现有工作流
-
-Templates 模板系统是 spec-kit 项目的核心组件，通过标准化的模板确保项目文档的一致性和质量。正确使用这些模板可以显著提高开发效率和文档质量。
diff --git a/learn-spec-kit/uvx-implementation-guide.md b/learn-spec-kit/uvx-implementation-guide.md
deleted file mode 100644
index 8b41517..0000000
--- a/learn-spec-kit/uvx-implementation-guide.md
+++ /dev/null
@@ -1,220 +0,0 @@
-# uvx 命令实现原理详解
-
-## 概述
-
-本文档详细说明了 spec-kit 项目如何实现 `uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>` 命令的工作原理。
-
-## 命令解析
-
-### uvx 工具
-`uvx` 是 uv 包管理器的一个子命令，用于执行 Python 脚本或包，类似于 `npx` 对于 Node.js 的作用。
-
-### 命令结构
-```bash
-uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>
-```
-
-- `uvx`: uv 的执行命令
-- `--from git+https://github.com/github/spec-kit.git`: 指定从 Git 仓库安装包
-- `specify`: 包中定义的命令行入口点
-- `init`: specify 命令的子命令
-- `<PROJECT_NAME>`: 项目名称参数
-
-## 项目配置分析
-
-### 1. pyproject.toml 配置
-
-项目的核心配置在 `pyproject.toml` 文件中：
-
-```toml
-[project]
-name = "specify-cli"
-version = "0.0.4"
-description = "Setup tool for Specify spec-driven development projects"
-requires-python = ">=3.11"
-dependencies = [
-    "typer",
-    "rich",
-    "httpx[socks]",
-    "platformdirs",
-    "readchar",
-    "truststore>=0.10.4",
-]
-
-[project.scripts]
-specify = "specify_cli:main"
-
-[build-system]
-requires = ["hatchling"]
-build-backend = "hatchling.build"
-
-[tool.hatch.build.targets.wheel]
-packages = ["src/specify_cli"]
-```
-
-**关键配置说明：**
-
-1. **项目脚本入口点**：
-   ```toml
-   [project.scripts]
-   specify = "specify_cli:main"
-   ```
-   这定义了 `specify` 命令指向 `specify_cli` 模块的 `main` 函数。
-
-2. **包结构**：
-   ```toml
-   [tool.hatch.build.targets.wheel]
-   packages = ["src/specify_cli"]
-   ```
-   指定了包的源代码位置。
-
-### 2. 源代码结构
-
-```
-src/specify_cli/
-└── __init__.py  # 包含完整的 CLI 实现
-```
-
-`__init__.py` 文件包含了完整的命令行工具实现，包括：
-- 主入口函数 `main()`
-- CLI 应用定义
-- 所有子命令的实现
-
-## 执行流程
-
-### 1. uvx 执行过程
-
-当运行 `uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>` 时：
-
-1. **下载和安装**：
-   - uvx 从指定的 Git 仓库下载项目
-   - 解析 `pyproject.toml` 文件
-   - 安装项目依赖
-   - 创建临时的虚拟环境
-
-2. **命令解析**：
-   - 根据 `[project.scripts]` 配置找到 `specify` 命令
-   - 调用 `specify_cli:main` 函数
-
-3. **执行**：
-   - 运行 `specify init <PROJECT_NAME>` 子命令
-
-### 2. specify init 命令实现
-
-在 `__init__.py` 中，`init` 命令的实现包括：
-
-```python
-@app.command()
-def init(
-    project_name: str = typer.Argument(None, help="Name for your new project directory"),
-    ai_assistant: str = typer.Option(None, "--ai", help="AI assistant to use"),
-    script_type: str = typer.Option(None, "--script", help="Script type to use"),
-    # ... 其他参数
-):
-    """
-    Initialize a new Specify project from the latest template.
-    """
-    # 实现逻辑...
-```
-
-**主要功能：**
-
-1. **参数验证**：
-   - 检查项目名称和 `--here` 标志的互斥性
-   - 验证 AI 助手选择
-   - 验证脚本类型选择
-
-2. **工具检查**：
-   - 检查 Git 是否安装
-   - 检查 AI 助手工具（Claude、Gemini 等）
-
-3. **模板下载**：
-   - 从 GitHub API 获取最新发布信息
-   - 下载对应的模板 ZIP 文件
-   - 根据 AI 助手和脚本类型选择正确的模板
-
-4. **项目初始化**：
-   - 创建项目目录
-   - 解压模板文件
-   - 设置脚本执行权限
-   - 初始化 Git 仓库
-
-## 技术特点
-
-### 1. 自包含脚本
-
-项目使用了 PEP 723 的脚本元数据格式：
-
-```python
-#!/usr/bin/env python3
-# /// script
-# requires-python = ">=3.11"
-# dependencies = [
-#     "typer",
-#     "rich",
-#     "platformdirs",
-#     "readchar",
-#     "httpx",
-# ]
-# ///
-```
-
-这使得单个 Python 文件可以包含所有依赖信息，uvx 可以自动处理依赖安装。
-
-### 2. 交互式界面
-
-使用 `typer` 和 `rich` 库创建了美观的命令行界面：
-
-- ASCII 艺术横幅
-- 交互式选择菜单（支持箭头键导航）
-- 实时进度跟踪
-- 彩色输出和面板显示
-
-### 3. 跨平台支持
-
-- 支持 POSIX Shell 和 PowerShell 脚本
-- 跨平台的键盘输入处理
-- 自动检测操作系统并选择合适的脚本类型
-
-### 4. 错误处理
-
-- 网络请求超时和重试
-- 详细的错误信息和调试输出
-- 优雅的失败处理和清理
-
-## 模板系统
-
-### 1. 模板下载
-
-项目从 GitHub Releases 下载预构建的模板：
-
-```python
-def download_template_from_github(ai_assistant: str, download_dir: Path, *, script_type: str = "sh"):
-    # 从 GitHub API 获取最新发布
-    api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/releases/latest"
-    
-    # 根据 AI 助手和脚本类型选择模板
-    pattern = f"spec-kit-template-{ai_assistant}-{script_type}"
-    matching_assets = [
-        asset for asset in release_data.get("assets", [])
-        if pattern in asset["name"] and asset["name"].endswith(".zip")
-    ]
-```
-
-### 2. 模板类型
-
-支持多种 AI 助手和脚本类型的组合：
-- AI 助手：claude, gemini, copilot, cursor
-- 脚本类型：sh (POSIX Shell), ps (PowerShell)
-
-## 总结
-
-spec-kit 项目通过以下方式实现了 `uvx` 命令：
-
-1. **标准化的 Python 包配置**：使用 `pyproject.toml` 定义包元数据和入口点
-2. **自包含的脚本格式**：支持 PEP 723 脚本元数据
-3. **完整的 CLI 实现**：使用 typer 构建命令行界面
-4. **模板化项目生成**：从 GitHub Releases 下载和部署项目模板
-5. **跨平台兼容性**：支持多种操作系统和脚本类型
-
-这种设计使得用户可以通过一个简单的命令快速创建和初始化新的 spec-driven 开发项目，而无需手动安装或配置任何工具。
diff --git a/memory/constitution.md b/memory/constitution.md
index 1ed8d77..a4670ff 100644
--- a/memory/constitution.md
+++ b/memory/constitution.md
@@ -47,4 +47,4 @@
 <!-- Example: All PRs/reviews must verify compliance; Complexity must be justified; Use [GUIDANCE_FILE] for runtime development guidance -->
 
 **Version**: [CONSTITUTION_VERSION] | **Ratified**: [RATIFICATION_DATE] | **Last Amended**: [LAST_AMENDED_DATE]
-<!-- Example: Version: 2.1.1 | Ratified: 2025-06-13 | Last Amended: 2025-07-16 -->
\ No newline at end of file
+<!-- Example: Version: 2.1.1 | Ratified: 2025-06-13 | Last Amended: 2025-07-16 -->
diff --git a/pyproject.toml b/pyproject.toml
index 559bad2..567d48c 100644
--- a/pyproject.toml
+++ b/pyproject.toml
@@ -1,6 +1,6 @@
 [project]
 name = "specify-cli"
-version = "0.0.17"
+version = "0.0.20"
 description = "Specify CLI, part of GitHub Spec Kit. A tool to bootstrap your projects for Spec-Driven Development (SDD)."
 requires-python = ">=3.11"
 dependencies = [
@@ -21,3 +21,4 @@ build-backend = "hatchling.build"
 
 [tool.hatch.build.targets.wheel]
 packages = ["src/specify_cli"]
+
diff --git a/scripts/bash/check-prerequisites.sh b/scripts/bash/check-prerequisites.sh
index f32b624..54f32ec 100644
--- a/scripts/bash/check-prerequisites.sh
+++ b/scripts/bash/check-prerequisites.sh
@@ -102,20 +102,20 @@ fi
 # Validate required directories and files
 if [[ ! -d "$FEATURE_DIR" ]]; then
     echo "ERROR: Feature directory not found: $FEATURE_DIR" >&2
-    echo "Run /specify first to create the feature structure." >&2
+    echo "Run /speckit.specify first to create the feature structure." >&2
     exit 1
 fi
 
 if [[ ! -f "$IMPL_PLAN" ]]; then
     echo "ERROR: plan.md not found in $FEATURE_DIR" >&2
-    echo "Run /plan first to create the implementation plan." >&2
+    echo "Run /speckit.plan first to create the implementation plan." >&2
     exit 1
 fi
 
 # Check for tasks.md if required
 if $REQUIRE_TASKS && [[ ! -f "$TASKS" ]]; then
     echo "ERROR: tasks.md not found in $FEATURE_DIR" >&2
-    echo "Run /tasks first to create the task list." >&2
+    echo "Run /speckit.tasks first to create the task list." >&2
     exit 1
 fi
 
@@ -163,4 +163,4 @@ else
     if $INCLUDE_TASKS; then
         check_file "$TASKS" "tasks.md"
     fi
-fi
\ No newline at end of file
+fi
diff --git a/scripts/bash/common.sh b/scripts/bash/common.sh
index 34e5d4b..6931ecc 100644
--- a/scripts/bash/common.sh
+++ b/scripts/bash/common.sh
@@ -19,21 +19,21 @@ get_current_branch() {
         echo "$SPECIFY_FEATURE"
         return
     fi
-    
+
     # Then check git if available
     if git rev-parse --abbrev-ref HEAD >/dev/null 2>&1; then
         git rev-parse --abbrev-ref HEAD
         return
     fi
-    
+
     # For non-git repos, try to find the latest feature directory
     local repo_root=$(get_repo_root)
     local specs_dir="$repo_root/specs"
-    
+
     if [[ -d "$specs_dir" ]]; then
         local latest_feature=""
         local highest=0
-        
+
         for dir in "$specs_dir"/*; do
             if [[ -d "$dir" ]]; then
                 local dirname=$(basename "$dir")
@@ -47,13 +47,13 @@ get_current_branch() {
                 fi
             fi
         done
-        
+
         if [[ -n "$latest_feature" ]]; then
             echo "$latest_feature"
             return
         fi
     fi
-    
+
     echo "main"  # Final fallback
 }
 
@@ -65,35 +65,77 @@ has_git() {
 check_feature_branch() {
     local branch="$1"
     local has_git_repo="$2"
-    
+
     # For non-git repos, we can't enforce branch naming but still provide output
     if [[ "$has_git_repo" != "true" ]]; then
         echo "[specify] Warning: Git repository not detected; skipped branch validation" >&2
         return 0
     fi
-    
+
     if [[ ! "$branch" =~ ^[0-9]{3}- ]]; then
         echo "ERROR: Not on a feature branch. Current branch: $branch" >&2
         echo "Feature branches should be named like: 001-feature-name" >&2
         return 1
     fi
-    
+
     return 0
 }
 
 get_feature_dir() { echo "$1/specs/$2"; }
 
+# Find feature directory by numeric prefix instead of exact branch match
+# This allows multiple branches to work on the same spec (e.g., 004-fix-bug, 004-add-feature)
+find_feature_dir_by_prefix() {
+    local repo_root="$1"
+    local branch_name="$2"
+    local specs_dir="$repo_root/specs"
+
+    # Extract numeric prefix from branch (e.g., "004" from "004-whatever")
+    if [[ ! "$branch_name" =~ ^([0-9]{3})- ]]; then
+        # If branch doesn't have numeric prefix, fall back to exact match
+        echo "$specs_dir/$branch_name"
+        return
+    fi
+
+    local prefix="${BASH_REMATCH[1]}"
+
+    # Search for directories in specs/ that start with this prefix
+    local matches=()
+    if [[ -d "$specs_dir" ]]; then
+        for dir in "$specs_dir"/"$prefix"-*; do
+            if [[ -d "$dir" ]]; then
+                matches+=("$(basename "$dir")")
+            fi
+        done
+    fi
+
+    # Handle results
+    if [[ ${#matches[@]} -eq 0 ]]; then
+        # No match found - return the branch name path (will fail later with clear error)
+        echo "$specs_dir/$branch_name"
+    elif [[ ${#matches[@]} -eq 1 ]]; then
+        # Exactly one match - perfect!
+        echo "$specs_dir/${matches[0]}"
+    else
+        # Multiple matches - this shouldn't happen with proper naming convention
+        echo "ERROR: Multiple spec directories found with prefix '$prefix': ${matches[*]}" >&2
+        echo "Please ensure only one spec directory exists per numeric prefix." >&2
+        echo "$specs_dir/$branch_name"  # Return something to avoid breaking the script
+    fi
+}
+
 get_feature_paths() {
     local repo_root=$(get_repo_root)
     local current_branch=$(get_current_branch)
     local has_git_repo="false"
-    
+
     if has_git; then
         has_git_repo="true"
     fi
-    
-    local feature_dir=$(get_feature_dir "$repo_root" "$current_branch")
-    
+
+    # Use prefix-based lookup to support multiple branches per spec
+    local feature_dir=$(find_feature_dir_by_prefix "$repo_root" "$current_branch")
+
     cat <<EOF
 REPO_ROOT='$repo_root'
 CURRENT_BRANCH='$current_branch'
@@ -111,3 +153,4 @@ EOF
 
 check_file() { [[ -f "$1" ]] && echo "  ✓ $2" || echo "  ✗ $2"; }
 check_dir() { [[ -d "$1" && -n $(ls -A "$1" 2>/dev/null) ]] && echo "  ✓ $2" || echo "  ✗ $2"; }
+
diff --git a/scripts/bash/create-new-feature.sh b/scripts/bash/create-new-feature.sh
index 5cb17fa..53adbce 100644
--- a/scripts/bash/create-new-feature.sh
+++ b/scripts/bash/create-new-feature.sh
@@ -3,18 +3,52 @@
 set -e
 
 JSON_MODE=false
+SHORT_NAME=""
 ARGS=()
-for arg in "$@"; do
+i=1
+while [ $i -le $# ]; do
+    arg="${!i}"
     case "$arg" in
-        --json) JSON_MODE=true ;;
-        --help|-h) echo "Usage: $0 [--json] <feature_description>"; exit 0 ;;
-        *) ARGS+=("$arg") ;;
+        --json) 
+            JSON_MODE=true 
+            ;;
+        --short-name)
+            if [ $((i + 1)) -gt $# ]; then
+                echo 'Error: --short-name requires a value' >&2
+                exit 1
+            fi
+            i=$((i + 1))
+            next_arg="${!i}"
+            # Check if the next argument is another option (starts with --)
+            if [[ "$next_arg" == --* ]]; then
+                echo 'Error: --short-name requires a value' >&2
+                exit 1
+            fi
+            SHORT_NAME="$next_arg"
+            ;;
+        --help|-h) 
+            echo "Usage: $0 [--json] [--short-name <name>] <feature_description>"
+            echo ""
+            echo "Options:"
+            echo "  --json              Output in JSON format"
+            echo "  --short-name <name> Provide a custom short name (2-4 words) for the branch"
+            echo "  --help, -h          Show this help message"
+            echo ""
+            echo "Examples:"
+            echo "  $0 'Add user authentication system' --short-name 'user-auth'"
+            echo "  $0 'Implement OAuth2 integration for API'"
+            exit 0
+            ;;
+        *) 
+            ARGS+=("$arg") 
+            ;;
     esac
+    i=$((i + 1))
 done
 
 FEATURE_DESCRIPTION="${ARGS[*]}"
 if [ -z "$FEATURE_DESCRIPTION" ]; then
-    echo "Usage: $0 [--json] <feature_description>" >&2
+    echo "Usage: $0 [--json] [--short-name <name>] <feature_description>" >&2
     exit 1
 fi
 
@@ -67,9 +101,84 @@ fi
 NEXT=$((HIGHEST + 1))
 FEATURE_NUM=$(printf "%03d" "$NEXT")
 
-BRANCH_NAME=$(echo "$FEATURE_DESCRIPTION" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/-\+/-/g' | sed 's/^-//' | sed 's/-$//')
-WORDS=$(echo "$BRANCH_NAME" | tr '-' '\n' | grep -v '^$' | head -3 | tr '\n' '-' | sed 's/-$//')
-BRANCH_NAME="${FEATURE_NUM}-${WORDS}"
+# Function to generate branch name with stop word filtering and length filtering
+generate_branch_name() {
+    local description="$1"
+    
+    # Common stop words to filter out
+    local stop_words="^(i|a|an|the|to|for|of|in|on|at|by|with|from|is|are|was|were|be|been|being|have|has|had|do|does|did|will|would|should|could|can|may|might|must|shall|this|that|these|those|my|your|our|their|want|need|add|get|set)$"
+    
+    # Convert to lowercase and split into words
+    local clean_name=$(echo "$description" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/ /g')
+    
+    # Filter words: remove stop words and words shorter than 3 chars (unless they're uppercase acronyms in original)
+    local meaningful_words=()
+    for word in $clean_name; do
+        # Skip empty words
+        [ -z "$word" ] && continue
+        
+        # Keep words that are NOT stop words AND (length >= 3 OR are potential acronyms)
+        if ! echo "$word" | grep -qiE "$stop_words"; then
+            if [ ${#word} -ge 3 ]; then
+                meaningful_words+=("$word")
+            elif echo "$description" | grep -q "\b${word^^}\b"; then
+                # Keep short words if they appear as uppercase in original (likely acronyms)
+                meaningful_words+=("$word")
+            fi
+        fi
+    done
+    
+    # If we have meaningful words, use first 3-4 of them
+    if [ ${#meaningful_words[@]} -gt 0 ]; then
+        local max_words=3
+        if [ ${#meaningful_words[@]} -eq 4 ]; then max_words=4; fi
+        
+        local result=""
+        local count=0
+        for word in "${meaningful_words[@]}"; do
+            if [ $count -ge $max_words ]; then break; fi
+            if [ -n "$result" ]; then result="$result-"; fi
+            result="$result$word"
+            count=$((count + 1))
+        done
+        echo "$result"
+    else
+        # Fallback to original logic if no meaningful words found
+        echo "$description" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/-\+/-/g' | sed 's/^-//' | sed 's/-$//' | tr '-' '\n' | grep -v '^$' | head -3 | tr '\n' '-' | sed 's/-$//'
+    fi
+}
+
+# Generate branch name
+if [ -n "$SHORT_NAME" ]; then
+    # Use provided short name, just clean it up
+    BRANCH_SUFFIX=$(echo "$SHORT_NAME" | tr '[:upper:]' '[:lower:]' | sed 's/[^a-z0-9]/-/g' | sed 's/-\+/-/g' | sed 's/^-//' | sed 's/-$//')
+else
+    # Generate from description with smart filtering
+    BRANCH_SUFFIX=$(generate_branch_name "$FEATURE_DESCRIPTION")
+fi
+
+BRANCH_NAME="${FEATURE_NUM}-${BRANCH_SUFFIX}"
+
+# GitHub enforces a 244-byte limit on branch names
+# Validate and truncate if necessary
+MAX_BRANCH_LENGTH=244
+if [ ${#BRANCH_NAME} -gt $MAX_BRANCH_LENGTH ]; then
+    # Calculate how much we need to trim from suffix
+    # Account for: feature number (3) + hyphen (1) = 4 chars
+    MAX_SUFFIX_LENGTH=$((MAX_BRANCH_LENGTH - 4))
+    
+    # Truncate suffix at word boundary if possible
+    TRUNCATED_SUFFIX=$(echo "$BRANCH_SUFFIX" | cut -c1-$MAX_SUFFIX_LENGTH)
+    # Remove trailing hyphen if truncation created one
+    TRUNCATED_SUFFIX=$(echo "$TRUNCATED_SUFFIX" | sed 's/-$//')
+    
+    ORIGINAL_BRANCH_NAME="$BRANCH_NAME"
+    BRANCH_NAME="${FEATURE_NUM}-${TRUNCATED_SUFFIX}"
+    
+    >&2 echo "[specify] Warning: Branch name exceeded GitHub's 244-byte limit"
+    >&2 echo "[specify] Original: $ORIGINAL_BRANCH_NAME (${#ORIGINAL_BRANCH_NAME} bytes)"
+    >&2 echo "[specify] Truncated to: $BRANCH_NAME (${#BRANCH_NAME} bytes)"
+fi
 
 if [ "$HAS_GIT" = true ]; then
     git checkout -b "$BRANCH_NAME"
diff --git a/scripts/bash/setup-plan.sh b/scripts/bash/setup-plan.sh
index 654ba50..740a143 100644
--- a/scripts/bash/setup-plan.sh
+++ b/scripts/bash/setup-plan.sh
@@ -58,3 +58,4 @@ else
     echo "BRANCH: $CURRENT_BRANCH"
     echo "HAS_GIT: $HAS_GIT"
 fi
+
diff --git a/scripts/bash/update-agent-context.sh b/scripts/bash/update-agent-context.sh
index d3cc422..71d7e68 100644
--- a/scripts/bash/update-agent-context.sh
+++ b/scripts/bash/update-agent-context.sh
@@ -30,12 +30,12 @@
 #
 # 5. Multi-Agent Support
 #    - Handles agent-specific file paths and naming conventions
-#    - Supports: Claude, Gemini, Copilot, Cursor, Qwen, opencode, Codex, Windsurf
+#    - Supports: Claude, Gemini, Copilot, Cursor, Qwen, opencode, Codex, Windsurf, Kilo Code, Auggie CLI, or Amazon Q Developer CLI
 #    - Can update single agents or all existing agent files
 #    - Creates default Claude file if no agent files exist
 #
 # Usage: ./update-agent-context.sh [agent_type]
-# Agent types: claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf
+# Agent types: claude|gemini|copilot|cursor-agent|qwen|opencode|codex|windsurf|kilocode|auggie|q
 # Leave empty to update all existing agent files
 
 set -e
@@ -69,6 +69,8 @@ WINDSURF_FILE="$REPO_ROOT/.windsurf/rules/specify-rules.md"
 KILOCODE_FILE="$REPO_ROOT/.kilocode/rules/specify-rules.md"
 AUGGIE_FILE="$REPO_ROOT/.augment/rules/specify-rules.md"
 ROO_FILE="$REPO_ROOT/.roo/rules/specify-rules.md"
+CODEBUDDY_FILE="$REPO_ROOT/CODEBUDDY.md"
+Q_FILE="$REPO_ROOT/AGENTS.md"
 
 # Template file
 TEMPLATE_FILE="$REPO_ROOT/.specify/templates/agent-file-template.md"
@@ -248,7 +250,7 @@ get_commands_for_language() {
             echo "cargo test && cargo clippy"
             ;;
         *"JavaScript"*|*"TypeScript"*)
-            echo "npm test && npm run lint"
+            echo "npm test \\&\\& npm run lint"
             ;;
         *)
             echo "# Add commands for $lang"
@@ -556,7 +558,7 @@ update_specific_agent() {
         copilot)
             update_agent_file "$COPILOT_FILE" "GitHub Copilot"
             ;;
-        cursor)
+        cursor-agent)
             update_agent_file "$CURSOR_FILE" "Cursor IDE"
             ;;
         qwen)
@@ -580,9 +582,15 @@ update_specific_agent() {
         roo)
             update_agent_file "$ROO_FILE" "Roo Code"
             ;;
+        codebuddy)
+            update_agent_file "$CODEBUDDY_FILE" "CodeBuddy CLI"
+            ;;
+        q)
+            update_agent_file "$Q_FILE" "Amazon Q Developer CLI"
+            ;;
         *)
             log_error "Unknown agent type '$agent_type'"
-            log_error "Expected: claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo"
+            log_error "Expected: claude|gemini|copilot|cursor-agent|qwen|opencode|codex|windsurf|kilocode|auggie|roo|q"
             exit 1
             ;;
     esac
@@ -641,6 +649,16 @@ update_all_existing_agents() {
         update_agent_file "$ROO_FILE" "Roo Code"
         found_agent=true
     fi
+
+    if [[ -f "$CODEBUDDY_FILE" ]]; then
+        update_agent_file "$CODEBUDDY_FILE" "CodeBuddy CLI"
+        found_agent=true
+    fi
+
+    if [[ -f "$Q_FILE" ]]; then
+        update_agent_file "$Q_FILE" "Amazon Q Developer CLI"
+        found_agent=true
+    fi
     
     # If no agent files exist, create a default Claude file
     if [[ "$found_agent" == false ]]; then
@@ -665,7 +683,8 @@ print_summary() {
     fi
     
     echo
-    log_info "Usage: $0 [claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo]"
+
+    log_info "Usage: $0 [claude|gemini|copilot|cursor-agent|qwen|opencode|codex|windsurf|kilocode|auggie|codebuddy|q]"
 }
 
 #==============================================================================
@@ -717,3 +736,4 @@ main() {
 if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
     main "$@"
 fi
+
diff --git a/scripts/powershell/check-prerequisites.ps1 b/scripts/powershell/check-prerequisites.ps1
index d61c3b9..91667e9 100644
--- a/scripts/powershell/check-prerequisites.ps1
+++ b/scripts/powershell/check-prerequisites.ps1
@@ -88,20 +88,20 @@ if ($PathsOnly) {
 # Validate required directories and files
 if (-not (Test-Path $paths.FEATURE_DIR -PathType Container)) {
     Write-Output "ERROR: Feature directory not found: $($paths.FEATURE_DIR)"
-    Write-Output "Run /specify first to create the feature structure."
+    Write-Output "Run /speckit.specify first to create the feature structure."
     exit 1
 }
 
 if (-not (Test-Path $paths.IMPL_PLAN -PathType Leaf)) {
     Write-Output "ERROR: plan.md not found in $($paths.FEATURE_DIR)"
-    Write-Output "Run /plan first to create the implementation plan."
+    Write-Output "Run /speckit.plan first to create the implementation plan."
     exit 1
 }
 
 # Check for tasks.md if required
 if ($RequireTasks -and -not (Test-Path $paths.TASKS -PathType Leaf)) {
     Write-Output "ERROR: tasks.md not found in $($paths.FEATURE_DIR)"
-    Write-Output "Run /tasks first to create the task list."
+    Write-Output "Run /speckit.tasks first to create the task list."
     exit 1
 }
 
@@ -145,4 +145,4 @@ if ($Json) {
     if ($IncludeTasks) {
         Test-FileExists -Path $paths.TASKS -Description 'tasks.md' | Out-Null
     }
-}
\ No newline at end of file
+}
diff --git a/scripts/powershell/common.ps1 b/scripts/powershell/common.ps1
index c8e34b2..b0be273 100644
--- a/scripts/powershell/common.ps1
+++ b/scripts/powershell/common.ps1
@@ -134,3 +134,4 @@ function Test-DirHasFiles {
         return $false
     }
 }
+
diff --git a/scripts/powershell/create-new-feature.ps1 b/scripts/powershell/create-new-feature.ps1
index 0f1f591..83e286a 100644
--- a/scripts/powershell/create-new-feature.ps1
+++ b/scripts/powershell/create-new-feature.ps1
@@ -3,20 +3,39 @@
 [CmdletBinding()]
 param(
     [switch]$Json,
+    [string]$ShortName,
+    [switch]$Help,
     [Parameter(ValueFromRemainingArguments = $true)]
     [string[]]$FeatureDescription
 )
 $ErrorActionPreference = 'Stop'
 
+# Show help if requested
+if ($Help) {
+    Write-Host "Usage: ./create-new-feature.ps1 [-Json] [-ShortName <name>] <feature description>"
+    Write-Host ""
+    Write-Host "Options:"
+    Write-Host "  -Json               Output in JSON format"
+    Write-Host "  -ShortName <name>   Provide a custom short name (2-4 words) for the branch"
+    Write-Host "  -Help               Show this help message"
+    Write-Host ""
+    Write-Host "Examples:"
+    Write-Host "  ./create-new-feature.ps1 'Add user authentication system' -ShortName 'user-auth'"
+    Write-Host "  ./create-new-feature.ps1 'Implement OAuth2 integration for API'"
+    exit 0
+}
+
+# Check if feature description provided
 if (-not $FeatureDescription -or $FeatureDescription.Count -eq 0) {
-    Write-Error "Usage: ./create-new-feature.ps1 [-Json] <feature description>"
+    Write-Error "Usage: ./create-new-feature.ps1 [-Json] [-ShortName <name>] <feature description>"
     exit 1
 }
+
 $featureDesc = ($FeatureDescription -join ' ').Trim()
 
 # Resolve repository root. Prefer git information when available, but fall back
 # to searching for repository markers so the workflow still functions in repositories that
-# were initialised with --no-git.
+# were initialized with --no-git.
 function Find-RepositoryRoot {
     param(
         [string]$StartDir,
@@ -72,9 +91,82 @@ if (Test-Path $specsDir) {
 $next = $highest + 1
 $featureNum = ('{0:000}' -f $next)
 
-$branchName = $featureDesc.ToLower() -replace '[^a-z0-9]', '-' -replace '-{2,}', '-' -replace '^-', '' -replace '-$', ''
-$words = ($branchName -split '-') | Where-Object { $_ } | Select-Object -First 3
-$branchName = "$featureNum-$([string]::Join('-', $words))"
+# Function to generate branch name with stop word filtering and length filtering
+function Get-BranchName {
+    param([string]$Description)
+    
+    # Common stop words to filter out
+    $stopWords = @(
+        'i', 'a', 'an', 'the', 'to', 'for', 'of', 'in', 'on', 'at', 'by', 'with', 'from',
+        'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had',
+        'do', 'does', 'did', 'will', 'would', 'should', 'could', 'can', 'may', 'might', 'must', 'shall',
+        'this', 'that', 'these', 'those', 'my', 'your', 'our', 'their',
+        'want', 'need', 'add', 'get', 'set'
+    )
+    
+    # Convert to lowercase and extract words (alphanumeric only)
+    $cleanName = $Description.ToLower() -replace '[^a-z0-9\s]', ' '
+    $words = $cleanName -split '\s+' | Where-Object { $_ }
+    
+    # Filter words: remove stop words and words shorter than 3 chars (unless they're uppercase acronyms in original)
+    $meaningfulWords = @()
+    foreach ($word in $words) {
+        # Skip stop words
+        if ($stopWords -contains $word) { continue }
+        
+        # Keep words that are length >= 3 OR appear as uppercase in original (likely acronyms)
+        if ($word.Length -ge 3) {
+            $meaningfulWords += $word
+        } elseif ($Description -match "\b$($word.ToUpper())\b") {
+            # Keep short words if they appear as uppercase in original (likely acronyms)
+            $meaningfulWords += $word
+        }
+    }
+    
+    # If we have meaningful words, use first 3-4 of them
+    if ($meaningfulWords.Count -gt 0) {
+        $maxWords = if ($meaningfulWords.Count -eq 4) { 4 } else { 3 }
+        $result = ($meaningfulWords | Select-Object -First $maxWords) -join '-'
+        return $result
+    } else {
+        # Fallback to original logic if no meaningful words found
+        $result = $Description.ToLower() -replace '[^a-z0-9]', '-' -replace '-{2,}', '-' -replace '^-', '' -replace '-$', ''
+        $fallbackWords = ($result -split '-') | Where-Object { $_ } | Select-Object -First 3
+        return [string]::Join('-', $fallbackWords)
+    }
+}
+
+# Generate branch name
+if ($ShortName) {
+    # Use provided short name, just clean it up
+    $branchSuffix = $ShortName.ToLower() -replace '[^a-z0-9]', '-' -replace '-{2,}', '-' -replace '^-', '' -replace '-$', ''
+} else {
+    # Generate from description with smart filtering
+    $branchSuffix = Get-BranchName -Description $featureDesc
+}
+
+$branchName = "$featureNum-$branchSuffix"
+
+# GitHub enforces a 244-byte limit on branch names
+# Validate and truncate if necessary
+$maxBranchLength = 244
+if ($branchName.Length -gt $maxBranchLength) {
+    # Calculate how much we need to trim from suffix
+    # Account for: feature number (3) + hyphen (1) = 4 chars
+    $maxSuffixLength = $maxBranchLength - 4
+    
+    # Truncate suffix
+    $truncatedSuffix = $branchSuffix.Substring(0, [Math]::Min($branchSuffix.Length, $maxSuffixLength))
+    # Remove trailing hyphen if truncation created one
+    $truncatedSuffix = $truncatedSuffix -replace '-$', ''
+    
+    $originalBranchName = $branchName
+    $branchName = "$featureNum-$truncatedSuffix"
+    
+    Write-Warning "[specify] Branch name exceeded GitHub's 244-byte limit"
+    Write-Warning "[specify] Original: $originalBranchName ($($originalBranchName.Length) bytes)"
+    Write-Warning "[specify] Truncated to: $branchName ($($branchName.Length) bytes)"
+}
 
 if ($hasGit) {
     try {
@@ -115,3 +207,4 @@ if ($Json) {
     Write-Output "HAS_GIT: $hasGit"
     Write-Output "SPECIFY_FEATURE environment variable set to: $branchName"
 }
+
diff --git a/scripts/powershell/setup-plan.ps1 b/scripts/powershell/setup-plan.ps1
index d0ed582..db6e9f2 100644
--- a/scripts/powershell/setup-plan.ps1
+++ b/scripts/powershell/setup-plan.ps1
@@ -59,3 +59,4 @@ if ($Json) {
     Write-Output "BRANCH: $($paths.CURRENT_BRANCH)"
     Write-Output "HAS_GIT: $($paths.HAS_GIT)"
 }
+
diff --git a/scripts/powershell/update-agent-context.ps1 b/scripts/powershell/update-agent-context.ps1
index 8f4830a..2fb4abe 100644
--- a/scripts/powershell/update-agent-context.ps1
+++ b/scripts/powershell/update-agent-context.ps1
@@ -9,7 +9,7 @@ Mirrors the behavior of scripts/bash/update-agent-context.sh:
  2. Plan Data Extraction
  3. Agent File Management (create from template or update existing)
  4. Content Generation (technology stack, recent changes, timestamp)
- 5. Multi-Agent Support (claude, gemini, copilot, cursor, qwen, opencode, codex, windsurf)
+ 5. Multi-Agent Support (claude, gemini, copilot, cursor-agent, qwen, opencode, codex, windsurf, kilocode, auggie, roo, q)
 
 .PARAMETER AgentType
 Optional agent key to update a single agent. If omitted, updates all existing agent files (creating a default Claude file if none exist).
@@ -25,7 +25,7 @@ Relies on common helper functions in common.ps1
 #>
 param(
     [Parameter(Position=0)]
-    [ValidateSet('claude','gemini','copilot','cursor','qwen','opencode','codex','windsurf','kilocode','auggie','roo')]
+    [ValidateSet('claude','gemini','copilot','cursor-agent','qwen','opencode','codex','windsurf','kilocode','auggie','roo','codebuddy','q')]
     [string]$AgentType
 )
 
@@ -54,6 +54,8 @@ $WINDSURF_FILE = Join-Path $REPO_ROOT '.windsurf/rules/specify-rules.md'
 $KILOCODE_FILE = Join-Path $REPO_ROOT '.kilocode/rules/specify-rules.md'
 $AUGGIE_FILE   = Join-Path $REPO_ROOT '.augment/rules/specify-rules.md'
 $ROO_FILE      = Join-Path $REPO_ROOT '.roo/rules/specify-rules.md'
+$CODEBUDDY_FILE = Join-Path $REPO_ROOT 'CODEBUDDY.md'
+$Q_FILE        = Join-Path $REPO_ROOT 'AGENTS.md'
 
 $TEMPLATE_FILE = Join-Path $REPO_ROOT '.specify/templates/agent-file-template.md'
 
@@ -124,7 +126,7 @@ function Extract-PlanField {
     if (-not (Test-Path $PlanFile)) { return '' }
     # Lines like **Language/Version**: Python 3.12
     $regex = "^\*\*$([Regex]::Escape($FieldPattern))\*\*: (.+)$"
-    Get-Content -LiteralPath $PlanFile | ForEach-Object {
+    Get-Content -LiteralPath $PlanFile -Encoding utf8 | ForEach-Object {
         if ($_ -match $regex) { 
             $val = $Matches[1].Trim()
             if ($val -notin @('NEEDS CLARIFICATION','N/A')) { return $val }
@@ -215,7 +217,7 @@ function New-AgentFile {
     $escaped_framework = $NEW_FRAMEWORK
     $escaped_branch = $CURRENT_BRANCH
 
-    $content = Get-Content -LiteralPath $temp -Raw
+    $content = Get-Content -LiteralPath $temp -Raw -Encoding utf8
     $content = $content -replace '\[PROJECT NAME\]',$ProjectName
     $content = $content -replace '\[DATE\]',$Date.ToString('yyyy-MM-dd')
     
@@ -253,7 +255,7 @@ function New-AgentFile {
 
     $parent = Split-Path -Parent $TargetFile
     if (-not (Test-Path $parent)) { New-Item -ItemType Directory -Path $parent | Out-Null }
-    Set-Content -LiteralPath $TargetFile -Value $content -NoNewline
+    Set-Content -LiteralPath $TargetFile -Value $content -NoNewline -Encoding utf8
     Remove-Item $temp -Force
     return $true
 }
@@ -285,7 +287,7 @@ function Update-ExistingAgentFile {
     if ($techStack) { $newChangeEntry = "- ${CURRENT_BRANCH}: Added ${techStack}" }
     elseif ($NEW_DB -and $NEW_DB -notin @('N/A','NEEDS CLARIFICATION')) { $newChangeEntry = "- ${CURRENT_BRANCH}: Added ${NEW_DB}" }
 
-    $lines = Get-Content -LiteralPath $TargetFile
+    $lines = Get-Content -LiteralPath $TargetFile -Encoding utf8
     $output = New-Object System.Collections.Generic.List[string]
     $inTech = $false; $inChanges = $false; $techAdded = $false; $changeAdded = $false; $existingChanges = 0
 
@@ -327,7 +329,7 @@ function Update-ExistingAgentFile {
         $newTechEntries | ForEach-Object { $output.Add($_) }
     }
 
-    Set-Content -LiteralPath $TargetFile -Value ($output -join [Environment]::NewLine)
+    Set-Content -LiteralPath $TargetFile -Value ($output -join [Environment]::NewLine) -Encoding utf8
     return $true
 }
 
@@ -368,7 +370,7 @@ function Update-SpecificAgent {
         'claude'   { Update-AgentFile -TargetFile $CLAUDE_FILE   -AgentName 'Claude Code' }
         'gemini'   { Update-AgentFile -TargetFile $GEMINI_FILE   -AgentName 'Gemini CLI' }
         'copilot'  { Update-AgentFile -TargetFile $COPILOT_FILE  -AgentName 'GitHub Copilot' }
-        'cursor'   { Update-AgentFile -TargetFile $CURSOR_FILE   -AgentName 'Cursor IDE' }
+        'cursor-agent' { Update-AgentFile -TargetFile $CURSOR_FILE   -AgentName 'Cursor IDE' }
         'qwen'     { Update-AgentFile -TargetFile $QWEN_FILE     -AgentName 'Qwen Code' }
         'opencode' { Update-AgentFile -TargetFile $AGENTS_FILE   -AgentName 'opencode' }
         'codex'    { Update-AgentFile -TargetFile $AGENTS_FILE   -AgentName 'Codex CLI' }
@@ -376,7 +378,9 @@ function Update-SpecificAgent {
         'kilocode' { Update-AgentFile -TargetFile $KILOCODE_FILE -AgentName 'Kilo Code' }
         'auggie'   { Update-AgentFile -TargetFile $AUGGIE_FILE   -AgentName 'Auggie CLI' }
         'roo'      { Update-AgentFile -TargetFile $ROO_FILE      -AgentName 'Roo Code' }
-        default { Write-Err "Unknown agent type '$Type'"; Write-Err 'Expected: claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo'; return $false }
+        'codebuddy' { Update-AgentFile -TargetFile $CODEBUDDY_FILE -AgentName 'CodeBuddy CLI' }
+        'q'        { Update-AgentFile -TargetFile $Q_FILE        -AgentName 'Amazon Q Developer CLI' }
+        default { Write-Err "Unknown agent type '$Type'"; Write-Err 'Expected: claude|gemini|copilot|cursor-agent|qwen|opencode|codex|windsurf|kilocode|auggie|roo|codebuddy|q'; return $false }
     }
 }
 
@@ -393,6 +397,8 @@ function Update-AllExistingAgents {
     if (Test-Path $KILOCODE_FILE) { if (-not (Update-AgentFile -TargetFile $KILOCODE_FILE -AgentName 'Kilo Code')) { $ok = $false }; $found = $true }
     if (Test-Path $AUGGIE_FILE)   { if (-not (Update-AgentFile -TargetFile $AUGGIE_FILE   -AgentName 'Auggie CLI')) { $ok = $false }; $found = $true }
     if (Test-Path $ROO_FILE)      { if (-not (Update-AgentFile -TargetFile $ROO_FILE      -AgentName 'Roo Code')) { $ok = $false }; $found = $true }
+    if (Test-Path $CODEBUDDY_FILE) { if (-not (Update-AgentFile -TargetFile $CODEBUDDY_FILE -AgentName 'CodeBuddy CLI')) { $ok = $false }; $found = $true }
+    if (Test-Path $Q_FILE)        { if (-not (Update-AgentFile -TargetFile $Q_FILE        -AgentName 'Amazon Q Developer CLI')) { $ok = $false }; $found = $true }
     if (-not $found) {
         Write-Info 'No existing agent files found, creating default Claude file...'
         if (-not (Update-AgentFile -TargetFile $CLAUDE_FILE -AgentName 'Claude Code')) { $ok = $false }
@@ -407,7 +413,7 @@ function Print-Summary {
     if ($NEW_FRAMEWORK) { Write-Host "  - Added framework: $NEW_FRAMEWORK" }
     if ($NEW_DB -and $NEW_DB -ne 'N/A') { Write-Host "  - Added database: $NEW_DB" }
     Write-Host ''
-    Write-Info 'Usage: ./update-agent-context.ps1 [-AgentType claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo]'
+    Write-Info 'Usage: ./update-agent-context.ps1 [-AgentType claude|gemini|copilot|cursor-agent|qwen|opencode|codex|windsurf|kilocode|auggie|roo|codebuddy|q]'
 }
 
 function Main {
@@ -428,3 +434,4 @@ function Main {
 }
 
 Main
+
diff --git a/spec-driven.md b/spec-driven.md
index a932c2e..13edc9e 100644
--- a/spec-driven.md
+++ b/spec-driven.md
@@ -74,7 +74,7 @@ The key is treating specifications as the source of truth, with code as the gene
 
 The SDD methodology is significantly enhanced through three powerful commands that automate the specification → planning → tasking workflow:
 
-### The `/specify` Command
+### The `/speckit.specify` Command
 
 This command transforms a simple feature description (the user-prompt) into a complete, structured specification with automatic repository management:
 
@@ -83,7 +83,7 @@ This command transforms a simple feature description (the user-prompt) into a co
 3. **Template-Based Generation**: Copies and customizes the feature specification template with your requirements
 4. **Directory Structure**: Creates the proper `specs/[branch-name]/` structure for all related documents
 
-### The `/plan` Command
+### The `/speckit.plan` Command
 
 Once a feature specification exists, this command creates a comprehensive implementation plan:
 
@@ -93,7 +93,7 @@ Once a feature specification exists, this command creates a comprehensive implem
 4. **Detailed Documentation**: Generates supporting documents for data models, API contracts, and test scenarios
 5. **Quickstart Validation**: Produces a quickstart guide capturing key validation scenarios
 
-### The `/tasks` Command
+### The `/speckit.tasks` Command
 
 After a plan is created, this command analyzes the plan and related design documents to generate an executable task list:
 
@@ -121,7 +121,7 @@ Total: ~12 hours of documentation work
 
 ```bash
 # Step 1: Create the feature specification (5 minutes)
-/specify Real-time chat system with message history and user presence
+/speckit.specify Real-time chat system with message history and user presence
 
 # This automatically:
 # - Creates branch "003-chat-system"
@@ -129,10 +129,10 @@ Total: ~12 hours of documentation work
 # - Populates it with structured requirements
 
 # Step 2: Generate implementation plan (5 minutes)
-/plan WebSocket for real-time messaging, PostgreSQL for history, Redis for presence
+/speckit.plan WebSocket for real-time messaging, PostgreSQL for history, Redis for presence
 
 # Step 3: Generate executable tasks (5 minutes)
-/tasks
+/speckit.tasks
 
 # This automatically creates:
 # - specs/003-chat-system/plan.md
@@ -401,3 +401,4 @@ By embedding these principles into the specification and planning process, SDD e
 This isn't about replacing developers or automating creativity. It's about amplifying human capability by automating mechanical translation. It's about creating a tight feedback loop where specifications, research, and code evolve together, each iteration bringing deeper understanding and better alignment between intent and implementation.
 
 Software development needs better tools for maintaining alignment between intent and implementation. SDD provides the methodology for achieving this alignment through executable specifications that generate code rather than merely guiding it.
+
diff --git a/src/specify_cli/__init__.py b/src/specify_cli/__init__.py
index 83d2fdf..ae9c75f 100644
--- a/src/specify_cli/__init__.py
+++ b/src/specify_cli/__init__.py
@@ -14,11 +14,13 @@ Specify CLI - Setup tool for Specify projects
 
 Usage:
     uvx specify-cli.py init <project-name>
+    uvx specify-cli.py init .
     uvx specify-cli.py init --here
 
 Or install globally:
     uv tool install --from specify-cli.py specify-cli
     specify init <project-name>
+    specify init .
     specify init --here
 """
 
@@ -62,27 +64,92 @@ def _github_auth_headers(cli_token: str | None = None) -> dict:
     token = _github_token(cli_token)
     return {"Authorization": f"Bearer {token}"} if token else {}
 
-# Constants
-AI_CHOICES = {
-    "copilot": "GitHub Copilot",
-    "claude": "Claude Code",
-    "gemini": "Gemini CLI",
-    "cursor": "Cursor",
-    "qwen": "Qwen Code",
-    "opencode": "opencode",
-    "codex": "Codex CLI",
-    "windsurf": "Windsurf",
-    "kilocode": "Kilo Code",
-    "auggie": "Auggie CLI",
-    "roo": "Roo Code",
+# Agent configuration with name, folder, install URL, and CLI tool requirement
+AGENT_CONFIG = {
+    "copilot": {
+        "name": "GitHub Copilot",
+        "folder": ".github/",
+        "install_url": None,  # IDE-based, no CLI check needed
+        "requires_cli": False,
+    },
+    "claude": {
+        "name": "Claude Code",
+        "folder": ".claude/",
+        "install_url": "https://docs.anthropic.com/en/docs/claude-code/setup",
+        "requires_cli": True,
+    },
+    "gemini": {
+        "name": "Gemini CLI",
+        "folder": ".gemini/",
+        "install_url": "https://github.com/google-gemini/gemini-cli",
+        "requires_cli": True,
+    },
+    "cursor-agent": {
+        "name": "Cursor",
+        "folder": ".cursor/",
+        "install_url": None,  # IDE-based
+        "requires_cli": False,
+    },
+    "qwen": {
+        "name": "Qwen Code",
+        "folder": ".qwen/",
+        "install_url": "https://github.com/QwenLM/qwen-code",
+        "requires_cli": True,
+    },
+    "opencode": {
+        "name": "opencode",
+        "folder": ".opencode/",
+        "install_url": "https://opencode.ai",
+        "requires_cli": True,
+    },
+    "codex": {
+        "name": "Codex CLI",
+        "folder": ".codex/",
+        "install_url": "https://github.com/openai/codex",
+        "requires_cli": True,
+    },
+    "windsurf": {
+        "name": "Windsurf",
+        "folder": ".windsurf/",
+        "install_url": None,  # IDE-based
+        "requires_cli": False,
+    },
+    "kilocode": {
+        "name": "Kilo Code",
+        "folder": ".kilocode/",
+        "install_url": None,  # IDE-based
+        "requires_cli": False,
+    },
+    "auggie": {
+        "name": "Auggie CLI",
+        "folder": ".augment/",
+        "install_url": "https://docs.augmentcode.com/cli/setup-auggie/install-auggie-cli",
+        "requires_cli": True,
+    },
+    "codebuddy": {
+        "name": "CodeBuddy",
+        "folder": ".codebuddy/",
+        "install_url": "https://www.codebuddy.ai/cli",
+        "requires_cli": True,
+    },
+    "roo": {
+        "name": "Roo Code",
+        "folder": ".roo/",
+        "install_url": None,  # IDE-based
+        "requires_cli": False,
+    },
+    "q": {
+        "name": "Amazon Q Developer CLI",
+        "folder": ".amazonq/",
+        "install_url": "https://aws.amazon.com/developer/learning/q-developer-cli/",
+        "requires_cli": True,
+    },
 }
-# Add script type choices
+
 SCRIPT_TYPE_CHOICES = {"sh": "POSIX Shell (bash/zsh)", "ps": "PowerShell"}
 
-# Claude CLI local installation path after migrate-installer
 CLAUDE_LOCAL_PATH = Path.home() / ".claude" / "local" / "claude"
 
-# ASCII Art Banner
 BANNER = """
 ███████╗██████╗ ███████╗ ██████╗██╗███████╗██╗   ██╗
 ██╔════╝██╔══██╗██╔════╝██╔════╝██║██╔════╝╚██╗ ██╔╝
@@ -131,7 +198,7 @@ class StepTracker:
                     s["detail"] = detail
                 self._maybe_refresh()
                 return
-        # If not present, add it
+
         self.steps.append({"key": key, "label": key, "status": status, "detail": detail})
         self._maybe_refresh()
 
@@ -148,7 +215,6 @@ class StepTracker:
             label = step["label"]
             detail_text = step["detail"].strip() if step["detail"] else ""
 
-            # Circles (unchanged styling)
             status = step["status"]
             if status == "done":
                 symbol = "[green]●[/green]"
@@ -179,40 +245,26 @@ class StepTracker:
             tree.add(line)
         return tree
 
-
-
-MINI_BANNER = """
-╔═╗╔═╗╔═╗╔═╗╦╔═╗╦ ╦
-╚═╗╠═╝║╣ ║  ║╠╣ ╚╦╝
-╚═╝╩  ╚═╝╚═╝╩╚   ╩ 
-"""
-
 def get_key():
     """Get a single keypress in a cross-platform way using readchar."""
     key = readchar.readkey()
-    
-    # Arrow keys
-    if key == readchar.key.UP:
+
+    if key == readchar.key.UP or key == readchar.key.CTRL_P:
         return 'up'
-    if key == readchar.key.DOWN:
+    if key == readchar.key.DOWN or key == readchar.key.CTRL_N:
         return 'down'
-    
-    # Enter/Return
+
     if key == readchar.key.ENTER:
         return 'enter'
-    
-    # Escape
+
     if key == readchar.key.ESC:
         return 'escape'
-        
-    # Ctrl+C
+
     if key == readchar.key.CTRL_C:
         raise KeyboardInterrupt
 
     return key
 
-
-
 def select_with_arrows(options: dict, prompt_text: str = "Select an option", default_key: str = None) -> str:
     """
     Interactive selection using arrow keys with Rich Live display.
@@ -230,7 +282,7 @@ def select_with_arrows(options: dict, prompt_text: str = "Select an option", def
         selected_index = option_keys.index(default_key)
     else:
         selected_index = 0
-    
+
     selected_key = None
 
     def create_selection_panel():
@@ -238,23 +290,23 @@ def select_with_arrows(options: dict, prompt_text: str = "Select an option", def
         table = Table.grid(padding=(0, 2))
         table.add_column(style="cyan", justify="left", width=3)
         table.add_column(style="white", justify="left")
-        
+
         for i, key in enumerate(option_keys):
             if i == selected_index:
                 table.add_row("▶", f"[cyan]{key}[/cyan] [dim]({options[key]})[/dim]")
             else:
                 table.add_row(" ", f"[cyan]{key}[/cyan] [dim]({options[key]})[/dim]")
-        
+
         table.add_row("", "")
         table.add_row("", "[dim]Use ↑/↓ to navigate, Enter to select, Esc to cancel[/dim]")
-        
+
         return Panel(
             table,
             title=f"[bold]{prompt_text}[/bold]",
             border_style="cyan",
             padding=(1, 2)
         )
-    
+
     console.print()
 
     def run_selection_loop():
@@ -273,7 +325,7 @@ def select_with_arrows(options: dict, prompt_text: str = "Select an option", def
                     elif key == 'escape':
                         console.print("\n[yellow]Selection cancelled[/yellow]")
                         raise typer.Exit(1)
-                    
+
                     live.update(create_selection_panel(), refresh=True)
 
                 except KeyboardInterrupt:
@@ -286,17 +338,13 @@ def select_with_arrows(options: dict, prompt_text: str = "Select an option", def
         console.print("\n[red]Selection failed.[/red]")
         raise typer.Exit(1)
 
-    # Suppress explicit selection print; tracker / later logic will report consolidated status
     return selected_key
 
-
-
 console = Console()
 
-
 class BannerGroup(TyperGroup):
     """Custom group that shows banner before help."""
-    
+
     def format_help(self, ctx, formatter):
         # Show banner before help
         show_banner()
@@ -311,34 +359,28 @@ app = typer.Typer(
     cls=BannerGroup,
 )
 
-
 def show_banner():
     """Display the ASCII art banner."""
-    # Create gradient effect with different colors
     banner_lines = BANNER.strip().split('\n')
     colors = ["bright_blue", "blue", "cyan", "bright_cyan", "white", "bright_white"]
-    
+
     styled_banner = Text()
     for i, line in enumerate(banner_lines):
         color = colors[i % len(colors)]
         styled_banner.append(line + "\n", style=color)
-    
+
     console.print(Align.center(styled_banner))
     console.print(Align.center(Text(TAGLINE, style="italic bright_yellow")))
     console.print()
 
-
 @app.callback()
 def callback(ctx: typer.Context):
     """Show banner when no subcommand is provided."""
-    # Show banner only when no subcommand and no help flag
-    # (help is handled by BannerGroup)
     if ctx.invoked_subcommand is None and "--help" not in sys.argv and "-h" not in sys.argv:
         show_banner()
         console.print(Align.center("[dim]Run 'specify --help' for usage information[/dim]"))
         console.print()
 
-
 def run_command(cmd: list[str], check_return: bool = True, capture: bool = False, shell: bool = False) -> Optional[str]:
     """Run a shell command and optionally capture output."""
     try:
@@ -357,20 +399,16 @@ def run_command(cmd: list[str], check_return: bool = True, capture: bool = False
             raise
         return None
 
-
-def check_tool_for_tracker(tool: str, tracker: StepTracker) -> bool:
-    """Check if a tool is installed and update tracker."""
-    if shutil.which(tool):
-        tracker.complete(tool, "available")
-        return True
-    else:
-        tracker.error(tool, "not found")
-        return False
-
-
-def check_tool(tool: str, install_hint: str) -> bool:
-    """Check if a tool is installed."""
+def check_tool(tool: str, tracker: StepTracker = None) -> bool:
+    """Check if a tool is installed. Optionally update tracker.
     
+    Args:
+        tool: Name of the tool to check
+        tracker: Optional StepTracker to update with results
+        
+    Returns:
+        True if tool is found, False otherwise
+    """
     # Special handling for Claude CLI after `claude migrate-installer`
     # See: https://github.com/github/spec-kit/issues/123
     # The migrate-installer command REMOVES the original executable from PATH
@@ -378,13 +416,19 @@ def check_tool(tool: str, install_hint: str) -> bool:
     # This path should be prioritized over other claude executables in PATH
     if tool == "claude":
         if CLAUDE_LOCAL_PATH.exists() and CLAUDE_LOCAL_PATH.is_file():
+            if tracker:
+                tracker.complete(tool, "available")
             return True
     
-    if shutil.which(tool):
-        return True
-    else:
-        return False
-
+    found = shutil.which(tool) is not None
+    
+    if tracker:
+        if found:
+            tracker.complete(tool, "available")
+        else:
+            tracker.error(tool, "not found")
+    
+    return found
 
 def is_git_repo(path: Path = None) -> bool:
     """Check if the specified path is inside a git repository."""
@@ -406,41 +450,118 @@ def is_git_repo(path: Path = None) -> bool:
     except (subprocess.CalledProcessError, FileNotFoundError):
         return False
 
-
-def init_git_repo(project_path: Path, quiet: bool = False) -> bool:
+def init_git_repo(project_path: Path, quiet: bool = False) -> Tuple[bool, Optional[str]]:
     """Initialize a git repository in the specified path.
-    quiet: if True suppress console output (tracker handles status)
+    
+    Args:
+        project_path: Path to initialize git repository in
+        quiet: if True suppress console output (tracker handles status)
+    
+    Returns:
+        Tuple of (success: bool, error_message: Optional[str])
     """
     try:
         original_cwd = Path.cwd()
         os.chdir(project_path)
         if not quiet:
             console.print("[cyan]Initializing git repository...[/cyan]")
-        subprocess.run(["git", "init"], check=True, capture_output=True)
-        subprocess.run(["git", "add", "."], check=True, capture_output=True)
-        subprocess.run(["git", "commit", "-m", "Initial commit from Specify template"], check=True, capture_output=True)
+        subprocess.run(["git", "init"], check=True, capture_output=True, text=True)
+        subprocess.run(["git", "add", "."], check=True, capture_output=True, text=True)
+        subprocess.run(["git", "commit", "-m", "Initial commit from Specify template"], check=True, capture_output=True, text=True)
         if not quiet:
             console.print("[green]✓[/green] Git repository initialized")
-        return True
-        
+        return True, None
+
     except subprocess.CalledProcessError as e:
+        error_msg = f"Command: {' '.join(e.cmd)}\nExit code: {e.returncode}"
+        if e.stderr:
+            error_msg += f"\nError: {e.stderr.strip()}"
+        elif e.stdout:
+            error_msg += f"\nOutput: {e.stdout.strip()}"
+        
         if not quiet:
             console.print(f"[red]Error initializing git repository:[/red] {e}")
-        return False
+        return False, error_msg
     finally:
         os.chdir(original_cwd)
 
+def handle_vscode_settings(sub_item, dest_file, rel_path, verbose=False, tracker=None) -> None:
+    """Handle merging or copying of .vscode/settings.json files."""
+    def log(message, color="green"):
+        if verbose and not tracker:
+            console.print(f"[{color}]{message}[/] {rel_path}")
+
+    try:
+        with open(sub_item, 'r', encoding='utf-8') as f:
+            new_settings = json.load(f)
+
+        if dest_file.exists():
+            merged = merge_json_files(dest_file, new_settings, verbose=verbose and not tracker)
+            with open(dest_file, 'w', encoding='utf-8') as f:
+                json.dump(merged, f, indent=4)
+                f.write('\n')
+            log("Merged:", "green")
+        else:
+            shutil.copy2(sub_item, dest_file)
+            log("Copied (no existing settings.json):", "blue")
+
+    except Exception as e:
+        log(f"Warning: Could not merge, copying instead: {e}", "yellow")
+        shutil.copy2(sub_item, dest_file)
+
+def merge_json_files(existing_path: Path, new_content: dict, verbose: bool = False) -> dict:
+    """Merge new JSON content into existing JSON file.
+
+    Performs a deep merge where:
+    - New keys are added
+    - Existing keys are preserved unless overwritten by new content
+    - Nested dictionaries are merged recursively
+    - Lists and other values are replaced (not merged)
+
+    Args:
+        existing_path: Path to existing JSON file
+        new_content: New JSON content to merge in
+        verbose: Whether to print merge details
+
+    Returns:
+        Merged JSON content as dict
+    """
+    try:
+        with open(existing_path, 'r', encoding='utf-8') as f:
+            existing_content = json.load(f)
+    except (FileNotFoundError, json.JSONDecodeError):
+        # If file doesn't exist or is invalid, just use new content
+        return new_content
+
+    def deep_merge(base: dict, update: dict) -> dict:
+        """Recursively merge update dict into base dict."""
+        result = base.copy()
+        for key, value in update.items():
+            if key in result and isinstance(result[key], dict) and isinstance(value, dict):
+                # Recursively merge nested dictionaries
+                result[key] = deep_merge(result[key], value)
+            else:
+                # Add new key or replace existing value
+                result[key] = value
+        return result
+
+    merged = deep_merge(existing_content, new_content)
+
+    if verbose:
+        console.print(f"[cyan]Merged JSON file:[/cyan] {existing_path.name}")
+
+    return merged
 
 def download_template_from_github(ai_assistant: str, download_dir: Path, *, script_type: str = "sh", verbose: bool = True, show_progress: bool = True, client: httpx.Client = None, debug: bool = False, github_token: str = None) -> Tuple[Path, dict]:
     repo_owner = "github"
     repo_name = "spec-kit"
     if client is None:
         client = httpx.Client(verify=ssl_context)
-    
+
     if verbose:
         console.print("[cyan]Fetching latest release information...[/cyan]")
     api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/releases/latest"
-    
+
     try:
         response = client.get(
             api_url,
@@ -462,8 +583,7 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
         console.print(f"[red]Error fetching release information[/red]")
         console.print(Panel(str(e), title="Fetch Error", border_style="red"))
         raise typer.Exit(1)
-    
-    # Find the template asset for the specified AI assistant
+
     assets = release_data.get("assets", [])
     pattern = f"spec-kit-template-{ai_assistant}-{script_type}"
     matching_assets = [
@@ -482,7 +602,7 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
     download_url = asset["browser_download_url"]
     filename = asset["name"]
     file_size = asset["size"]
-    
+
     if verbose:
         console.print(f"[cyan]Found template:[/cyan] {filename}")
         console.print(f"[cyan]Size:[/cyan] {file_size:,} bytes")
@@ -491,7 +611,7 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
     zip_path = download_dir / filename
     if verbose:
         console.print(f"[cyan]Downloading template...[/cyan]")
-    
+
     try:
         with client.stream(
             "GET",
@@ -542,14 +662,12 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
     }
     return zip_path, metadata
 
-
 def download_and_extract_template(project_path: Path, ai_assistant: str, script_type: str, is_current_dir: bool = False, *, verbose: bool = True, tracker: StepTracker | None = None, client: httpx.Client = None, debug: bool = False, github_token: str = None) -> Path:
     """Download the latest release and extract it to create a new project.
     Returns project_path. Uses tracker if provided (with keys: fetch, download, extract, cleanup)
     """
     current_dir = Path.cwd()
-    
-    # Step: fetch + download combined
+
     if tracker:
         tracker.start("fetch", "contacting GitHub API")
     try:
@@ -574,42 +692,37 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
             if verbose:
                 console.print(f"[red]Error downloading template:[/red] {e}")
         raise
-    
+
     if tracker:
         tracker.add("extract", "Extract template")
         tracker.start("extract")
     elif verbose:
         console.print("Extracting template...")
-    
+
     try:
-        # Create project directory only if not using current directory
         if not is_current_dir:
             project_path.mkdir(parents=True)
-        
+
         with zipfile.ZipFile(zip_path, 'r') as zip_ref:
-            # List all files in the ZIP for debugging
             zip_contents = zip_ref.namelist()
             if tracker:
                 tracker.start("zip-list")
                 tracker.complete("zip-list", f"{len(zip_contents)} entries")
             elif verbose:
                 console.print(f"[cyan]ZIP contains {len(zip_contents)} items[/cyan]")
-            
-            # For current directory, extract to a temp location first
+
             if is_current_dir:
                 with tempfile.TemporaryDirectory() as temp_dir:
                     temp_path = Path(temp_dir)
                     zip_ref.extractall(temp_path)
-                    
-                    # Check what was extracted
+
                     extracted_items = list(temp_path.iterdir())
                     if tracker:
                         tracker.start("extracted-summary")
                         tracker.complete("extracted-summary", f"temp {len(extracted_items)} items")
                     elif verbose:
                         console.print(f"[cyan]Extracted {len(extracted_items)} items to temp location[/cyan]")
-                    
-                    # Handle GitHub-style ZIP with a single root directory
+
                     source_dir = temp_path
                     if len(extracted_items) == 1 and extracted_items[0].is_dir():
                         source_dir = extracted_items[0]
@@ -618,21 +731,23 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
                             tracker.complete("flatten")
                         elif verbose:
                             console.print(f"[cyan]Found nested directory structure[/cyan]")
-                    
-                    # Copy contents to current directory
+
                     for item in source_dir.iterdir():
                         dest_path = project_path / item.name
                         if item.is_dir():
                             if dest_path.exists():
                                 if verbose and not tracker:
                                     console.print(f"[yellow]Merging directory:[/yellow] {item.name}")
-                                # Recursively copy directory contents
                                 for sub_item in item.rglob('*'):
                                     if sub_item.is_file():
                                         rel_path = sub_item.relative_to(item)
                                         dest_file = dest_path / rel_path
                                         dest_file.parent.mkdir(parents=True, exist_ok=True)
-                                        shutil.copy2(sub_item, dest_file)
+                                        # Special handling for .vscode/settings.json - merge instead of overwrite
+                                        if dest_file.name == "settings.json" and dest_file.parent.name == ".vscode":
+                                            handle_vscode_settings(sub_item, dest_file, rel_path, verbose, tracker)
+                                        else:
+                                            shutil.copy2(sub_item, dest_file)
                             else:
                                 shutil.copytree(item, dest_path)
                         else:
@@ -642,10 +757,8 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
                     if verbose and not tracker:
                         console.print(f"[cyan]Template files merged into current directory[/cyan]")
             else:
-                # Extract directly to project directory (original behavior)
                 zip_ref.extractall(project_path)
-                
-                # Check what was extracted
+
                 extracted_items = list(project_path.iterdir())
                 if tracker:
                     tracker.start("extracted-summary")
@@ -654,24 +767,22 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
                     console.print(f"[cyan]Extracted {len(extracted_items)} items to {project_path}:[/cyan]")
                     for item in extracted_items:
                         console.print(f"  - {item.name} ({'dir' if item.is_dir() else 'file'})")
-                
-                # Handle GitHub-style ZIP with a single root directory
+
                 if len(extracted_items) == 1 and extracted_items[0].is_dir():
-                    # Move contents up one level
                     nested_dir = extracted_items[0]
                     temp_move_dir = project_path.parent / f"{project_path.name}_temp"
-                    # Move the nested directory contents to temp location
+
                     shutil.move(str(nested_dir), str(temp_move_dir))
-                    # Remove the now-empty project directory
+
                     project_path.rmdir()
-                    # Rename temp directory to project directory
+
                     shutil.move(str(temp_move_dir), str(project_path))
                     if tracker:
                         tracker.add("flatten", "Flatten nested directory")
                         tracker.complete("flatten")
                     elif verbose:
                         console.print(f"[cyan]Flattened nested directory structure[/cyan]")
-                    
+
     except Exception as e:
         if tracker:
             tracker.error("extract", str(e))
@@ -680,7 +791,7 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
                 console.print(f"[red]Error extracting template:[/red] {e}")
                 if debug:
                     console.print(Panel(str(e), title="Extraction Error", border_style="red"))
-        # Clean up project directory if created and not current directory
+
         if not is_current_dir and project_path.exists():
             shutil.rmtree(project_path)
         raise typer.Exit(1)
@@ -690,14 +801,14 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
     finally:
         if tracker:
             tracker.add("cleanup", "Remove temporary archive")
-        # Clean up downloaded ZIP file
+
         if zip_path.exists():
             zip_path.unlink()
             if tracker:
                 tracker.complete("cleanup")
             elif verbose:
                 console.print(f"Cleaned up: {zip_path.name}")
-    
+
     return project_path
 
 
@@ -747,8 +858,8 @@ def ensure_executable_scripts(project_path: Path, tracker: StepTracker | None =
 
 @app.command()
 def init(
-    project_name: str = typer.Argument(None, help="Name for your new project directory (optional if using --here)"),
-    ai_assistant: str = typer.Option(None, "--ai", help="AI assistant to use: claude, gemini, copilot, cursor, qwen, opencode, codex, windsurf, kilocode, or auggie"),
+    project_name: str = typer.Argument(None, help="Name for your new project directory (optional if using --here, or use '.' for current directory)"),
+    ai_assistant: str = typer.Option(None, "--ai", help="AI assistant to use: claude, gemini, copilot, cursor-agent, qwen, opencode, codex, windsurf, kilocode, auggie, codebuddy, or q"),
     script_type: str = typer.Option(None, "--script", help="Script type to use: sh or ps"),
     ignore_agent_tools: bool = typer.Option(False, "--ignore-agent-tools", help="Skip checks for AI agent tools like Claude Code"),
     no_git: bool = typer.Option(False, "--no-git", help="Skip git repository initialization"),
@@ -763,7 +874,7 @@ def init(
     
     This command will:
     1. Check that required tools are installed (git is optional)
-    2. Let you choose your AI assistant (Claude Code, Gemini CLI, GitHub Copilot, Cursor, Qwen Code, opencode, Codex CLI, Windsurf, Kilo Code, or Auggie CLI)
+    2. Let you choose your AI assistant
     3. Download the appropriate template from GitHub
     4. Extract the template to a new project directory or current directory
     5. Initialize a fresh git repository (if not --no-git and no existing repo)
@@ -772,38 +883,35 @@ def init(
     Examples:
         specify init my-project
         specify init my-project --ai claude
-        specify init my-project --ai gemini
         specify init my-project --ai copilot --no-git
-        specify init my-project --ai cursor
-        specify init my-project --ai qwen
-        specify init my-project --ai opencode
-        specify init my-project --ai codex
-        specify init my-project --ai windsurf
-        specify init my-project --ai auggie
         specify init --ignore-agent-tools my-project
-        specify init --here --ai claude
+        specify init . --ai claude         # Initialize in current directory
+        specify init .                     # Initialize in current directory (interactive AI selection)
+        specify init --here --ai claude    # Alternative syntax for current directory
         specify init --here --ai codex
+        specify init --here --ai codebuddy
         specify init --here
         specify init --here --force  # Skip confirmation when current directory not empty
     """
-    # Show banner first
+
     show_banner()
-    
-    # Validate arguments
+
+    if project_name == ".":
+        here = True
+        project_name = None  # Clear project_name to use existing validation logic
+
     if here and project_name:
         console.print("[red]Error:[/red] Cannot specify both project name and --here flag")
         raise typer.Exit(1)
-    
+
     if not here and not project_name:
-        console.print("[red]Error:[/red] Must specify either a project name or use --here flag")
+        console.print("[red]Error:[/red] Must specify either a project name, use '.' for current directory, or use --here flag")
         raise typer.Exit(1)
-    
-    # Determine project directory
+
     if here:
         project_name = Path.cwd().name
         project_path = Path.cwd()
-        
-        # Check if current directory has any files
+
         existing_items = list(project_path.iterdir())
         if existing_items:
             console.print(f"[yellow]Warning:[/yellow] Current directory is not empty ({len(existing_items)} items)")
@@ -811,14 +919,12 @@ def init(
             if force:
                 console.print("[cyan]--force supplied: skipping confirmation and proceeding with merge[/cyan]")
             else:
-                # Ask for confirmation
                 response = typer.confirm("Do you want to continue?")
                 if not response:
                     console.print("[yellow]Operation cancelled[/yellow]")
                     raise typer.Exit(0)
     else:
         project_path = Path(project_name).resolve()
-        # Check if project directory already exists
         if project_path.exists():
             error_panel = Panel(
                 f"Directory '[cyan]{project_name}[/cyan]' already exists\n"
@@ -830,113 +936,79 @@ def init(
             console.print()
             console.print(error_panel)
             raise typer.Exit(1)
-    
-    # Create formatted setup info with column alignment
+
     current_dir = Path.cwd()
-    
+
     setup_lines = [
         "[cyan]Specify Project Setup[/cyan]",
         "",
         f"{'Project':<15} [green]{project_path.name}[/green]",
         f"{'Working Path':<15} [dim]{current_dir}[/dim]",
     ]
-    
-    # Add target path only if different from working dir
+
     if not here:
         setup_lines.append(f"{'Target Path':<15} [dim]{project_path}[/dim]")
-    
+
     console.print(Panel("\n".join(setup_lines), border_style="cyan", padding=(1, 2)))
-    
-    # Check git only if we might need it (not --no-git)
-    # Only set to True if the user wants it and the tool is available
+
     should_init_git = False
     if not no_git:
-        should_init_git = check_tool("git", "https://git-scm.com/downloads")
+        should_init_git = check_tool("git")
         if not should_init_git:
             console.print("[yellow]Git not found - will skip repository initialization[/yellow]")
 
-    # AI assistant selection
     if ai_assistant:
-        if ai_assistant not in AI_CHOICES:
-            console.print(f"[red]Error:[/red] Invalid AI assistant '{ai_assistant}'. Choose from: {', '.join(AI_CHOICES.keys())}")
+        if ai_assistant not in AGENT_CONFIG:
+            console.print(f"[red]Error:[/red] Invalid AI assistant '{ai_assistant}'. Choose from: {', '.join(AGENT_CONFIG.keys())}")
             raise typer.Exit(1)
         selected_ai = ai_assistant
     else:
-        # Use arrow-key selection interface
+        # Create options dict for selection (agent_key: display_name)
+        ai_choices = {key: config["name"] for key, config in AGENT_CONFIG.items()}
         selected_ai = select_with_arrows(
-            AI_CHOICES, 
+            ai_choices, 
             "Choose your AI assistant:", 
             "copilot"
         )
-    
-    # Check agent tools unless ignored
+
     if not ignore_agent_tools:
-        agent_tool_missing = False
-        install_url = ""
-        if selected_ai == "claude":
-            if not check_tool("claude", "https://docs.anthropic.com/en/docs/claude-code/setup"):
-                install_url = "https://docs.anthropic.com/en/docs/claude-code/setup"
-                agent_tool_missing = True
-        elif selected_ai == "gemini":
-            if not check_tool("gemini", "https://github.com/google-gemini/gemini-cli"):
-                install_url = "https://github.com/google-gemini/gemini-cli"
-                agent_tool_missing = True
-        elif selected_ai == "qwen":
-            if not check_tool("qwen", "https://github.com/QwenLM/qwen-code"):
-                install_url = "https://github.com/QwenLM/qwen-code"
-                agent_tool_missing = True
-        elif selected_ai == "opencode":
-            if not check_tool("opencode", "https://opencode.ai"):
-                install_url = "https://opencode.ai"
-                agent_tool_missing = True
-        elif selected_ai == "codex":
-            if not check_tool("codex", "https://github.com/openai/codex"):
-                install_url = "https://github.com/openai/codex"
-                agent_tool_missing = True
-        elif selected_ai == "auggie":
-            if not check_tool("auggie", "https://docs.augmentcode.com/cli/setup-auggie/install-auggie-cli"):
-                install_url = "https://docs.augmentcode.com/cli/setup-auggie/install-auggie-cli"
-                agent_tool_missing = True
-        # GitHub Copilot and Cursor checks are not needed as they're typically available in supported IDEs
-
-        if agent_tool_missing:
-            error_panel = Panel(
-                f"[cyan]{selected_ai}[/cyan] not found\n"
-                f"Install with: [cyan]{install_url}[/cyan]\n"
-                f"{AI_CHOICES[selected_ai]} is required to continue with this project type.\n\n"
-                "Tip: Use [cyan]--ignore-agent-tools[/cyan] to skip this check",
-                title="[red]Agent Detection Error[/red]",
-                border_style="red",
-                padding=(1, 2)
-            )
-            console.print()
-            console.print(error_panel)
-            raise typer.Exit(1)
-    
-    # Determine script type (explicit, interactive, or OS default)
+        agent_config = AGENT_CONFIG.get(selected_ai)
+        if agent_config and agent_config["requires_cli"]:
+            install_url = agent_config["install_url"]
+            if not check_tool(selected_ai):
+                error_panel = Panel(
+                    f"[cyan]{selected_ai}[/cyan] not found\n"
+                    f"Install from: [cyan]{install_url}[/cyan]\n"
+                    f"{agent_config['name']} is required to continue with this project type.\n\n"
+                    "Tip: Use [cyan]--ignore-agent-tools[/cyan] to skip this check",
+                    title="[red]Agent Detection Error[/red]",
+                    border_style="red",
+                    padding=(1, 2)
+                )
+                console.print()
+                console.print(error_panel)
+                raise typer.Exit(1)
+
     if script_type:
         if script_type not in SCRIPT_TYPE_CHOICES:
             console.print(f"[red]Error:[/red] Invalid script type '{script_type}'. Choose from: {', '.join(SCRIPT_TYPE_CHOICES.keys())}")
             raise typer.Exit(1)
         selected_script = script_type
     else:
-        # Auto-detect default
         default_script = "ps" if os.name == "nt" else "sh"
-        # Provide interactive selection similar to AI if stdin is a TTY
+
         if sys.stdin.isatty():
             selected_script = select_with_arrows(SCRIPT_TYPE_CHOICES, "Choose script type (or press Enter)", default_script)
         else:
             selected_script = default_script
-    
+
     console.print(f"[cyan]Selected AI assistant:[/cyan] {selected_ai}")
     console.print(f"[cyan]Selected script type:[/cyan] {selected_script}")
-    
-    # Download and set up project
-    # New tree-based progress (no emojis); include earlier substeps
+
     tracker = StepTracker("Initialize Specify Project")
-    # Flag to allow suppressing legacy headings
+
     sys._specify_tracker_active = True
-    # Pre steps recorded as completed before live rendering
+
     tracker.add("precheck", "Check required tools")
     tracker.complete("precheck", "ok")
     tracker.add("ai-select", "Select AI assistant")
@@ -956,30 +1028,31 @@ def init(
     ]:
         tracker.add(key, label)
 
-    # Use transient so live tree is replaced by the final static render (avoids duplicate output)
+    # Track git error message outside Live context so it persists
+    git_error_message = None
+
     with Live(tracker.render(), console=console, refresh_per_second=8, transient=True) as live:
         tracker.attach_refresh(lambda: live.update(tracker.render()))
         try:
-            # Create a httpx client with verify based on skip_tls
             verify = not skip_tls
             local_ssl_context = ssl_context if verify else False
             local_client = httpx.Client(verify=local_ssl_context)
 
             download_and_extract_template(project_path, selected_ai, selected_script, here, verbose=False, tracker=tracker, client=local_client, debug=debug, github_token=github_token)
 
-            # Ensure scripts are executable (POSIX)
             ensure_executable_scripts(project_path, tracker=tracker)
 
-            # Git step
             if not no_git:
                 tracker.start("git")
                 if is_git_repo(project_path):
                     tracker.complete("git", "existing repo detected")
                 elif should_init_git:
-                    if init_git_repo(project_path, quiet=True):
+                    success, error_msg = init_git_repo(project_path, quiet=True)
+                    if success:
                         tracker.complete("git", "initialized")
                     else:
                         tracker.error("git", "init failed")
+                        git_error_message = error_msg
                 else:
                     tracker.skip("git", "git not available")
             else:
@@ -1002,30 +1075,32 @@ def init(
                 shutil.rmtree(project_path)
             raise typer.Exit(1)
         finally:
-            # Force final render
             pass
 
-    # Final static tree (ensures finished state visible after Live context ends)
     console.print(tracker.render())
     console.print("\n[bold green]Project ready.[/bold green]")
     
+    # Show git error details if initialization failed
+    if git_error_message:
+        console.print()
+        git_error_panel = Panel(
+            f"[yellow]Warning:[/yellow] Git repository initialization failed\n\n"
+            f"{git_error_message}\n\n"
+            f"[dim]You can initialize git manually later with:[/dim]\n"
+            f"[cyan]cd {project_path if not here else '.'}[/cyan]\n"
+            f"[cyan]git init[/cyan]\n"
+            f"[cyan]git add .[/cyan]\n"
+            f"[cyan]git commit -m \"Initial commit\"[/cyan]",
+            title="[red]Git Initialization Failed[/red]",
+            border_style="red",
+            padding=(1, 2)
+        )
+        console.print(git_error_panel)
+
     # Agent folder security notice
-    agent_folder_map = {
-        "claude": ".claude/",
-        "gemini": ".gemini/",
-        "cursor": ".cursor/",
-        "qwen": ".qwen/",
-        "opencode": ".opencode/",
-        "codex": ".codex/",
-        "windsurf": ".windsurf/",
-        "kilocode": ".kilocode/",
-        "auggie": ".augment/",
-        "copilot": ".github/",
-        "roo": ".roo/"
-    }
-    
-    if selected_ai in agent_folder_map:
-        agent_folder = agent_folder_map[selected_ai]
+    agent_config = AGENT_CONFIG.get(selected_ai)
+    if agent_config:
+        agent_folder = agent_config["folder"]
         security_notice = Panel(
             f"Some agents may store credentials, auth tokens, or other identifying and private artifacts in the agent folder within your project.\n"
             f"Consider adding [cyan]{agent_folder}[/cyan] (or parts of it) to [cyan].gitignore[/cyan] to prevent accidental credential leakage.",
@@ -1035,8 +1110,7 @@ def init(
         )
         console.print()
         console.print(security_notice)
-    
-    # Boxed "Next steps" section
+
     steps_lines = []
     if not here:
         steps_lines.append(f"1. Go to the project folder: [cyan]cd {project_name}[/cyan]")
@@ -1058,28 +1132,27 @@ def init(
         step_num += 1
 
     steps_lines.append(f"{step_num}. Start using slash commands with your AI agent:")
-    steps_lines.append("   2.1 [cyan]/constitution[/] - Establish project principles")
-    steps_lines.append("   2.2 [cyan]/specify[/] - Create specifications")
-    steps_lines.append("   2.3 [cyan]/clarify[/] - Clarify and de-risk specification (run before [cyan]/plan[/cyan])")
-    steps_lines.append("   2.4 [cyan]/plan[/] - Create implementation plans")
-    steps_lines.append("   2.5 [cyan]/tasks[/] - Generate actionable tasks")
-    steps_lines.append("   2.6 [cyan]/analyze[/] - Validate alignment & surface inconsistencies (read-only)")
-    steps_lines.append("   2.7 [cyan]/implement[/] - Execute implementation")
+
+    steps_lines.append("   2.1 [cyan]/speckit.constitution[/] - Establish project principles")
+    steps_lines.append("   2.2 [cyan]/speckit.specify[/] - Create baseline specification")
+    steps_lines.append("   2.3 [cyan]/speckit.plan[/] - Create implementation plan")
+    steps_lines.append("   2.4 [cyan]/speckit.tasks[/] - Generate actionable tasks")
+    steps_lines.append("   2.5 [cyan]/speckit.implement[/] - Execute implementation")
 
     steps_panel = Panel("\n".join(steps_lines), title="Next Steps", border_style="cyan", padding=(1,2))
     console.print()
     console.print(steps_panel)
 
-    if selected_ai == "codex":
-        warning_text = """[bold yellow]Important Note:[/bold yellow]
-
-Custom prompts do not yet support arguments in Codex. You may need to manually specify additional project instructions directly in prompt files located in [cyan].codex/prompts/[/cyan].
-
-For more information, see: [cyan]https://github.com/openai/codex/issues/2890[/cyan]"""
-        
-        warning_panel = Panel(warning_text, title="Slash Commands in Codex", border_style="yellow", padding=(1,2))
-        console.print()
-        console.print(warning_panel)
+    enhancement_lines = [
+        "Optional commands that you can use for your specs [bright_black](improve quality & confidence)[/bright_black]",
+        "",
+        f"○ [cyan]/speckit.clarify[/] [bright_black](optional)[/bright_black] - Ask structured questions to de-risk ambiguous areas before planning (run before [cyan]/speckit.plan[/] if used)",
+        f"○ [cyan]/speckit.analyze[/] [bright_black](optional)[/bright_black] - Cross-artifact consistency & alignment report (after [cyan]/speckit.tasks[/], before [cyan]/speckit.implement[/])",
+        f"○ [cyan]/speckit.checklist[/] [bright_black](optional)[/bright_black] - Generate quality checklists to validate requirements completeness, clarity, and consistency (after [cyan]/speckit.plan[/])"
+    ]
+    enhancements_panel = Panel("\n".join(enhancement_lines), title="Enhancement Commands", border_style="cyan", padding=(1,2))
+    console.print()
+    console.print(enhancements_panel)
 
 @app.command()
 def check():
@@ -1088,32 +1161,30 @@ def check():
     console.print("[bold]Checking for installed tools...[/bold]\n")
 
     tracker = StepTracker("Check Available Tools")
-    
+
     tracker.add("git", "Git version control")
-    tracker.add("claude", "Claude Code CLI")
-    tracker.add("gemini", "Gemini CLI")
-    tracker.add("qwen", "Qwen Code CLI")
+    git_ok = check_tool("git", tracker=tracker)
+
+    agent_results = {}
+    for agent_key, agent_config in AGENT_CONFIG.items():
+        agent_name = agent_config["name"]
+        requires_cli = agent_config["requires_cli"]
+
+        tracker.add(agent_key, agent_name)
+
+        if requires_cli:
+            agent_results[agent_key] = check_tool(agent_key, tracker=tracker)
+        else:
+            # IDE-based agent - skip CLI check and mark as optional
+            tracker.skip(agent_key, "IDE-based, no CLI check")
+            agent_results[agent_key] = False  # Don't count IDE agents as "found"
+
+    # Check VS Code variants (not in agent config)
     tracker.add("code", "Visual Studio Code")
+    code_ok = check_tool("code", tracker=tracker)
+
     tracker.add("code-insiders", "Visual Studio Code Insiders")
-    tracker.add("cursor-agent", "Cursor IDE agent")
-    tracker.add("windsurf", "Windsurf IDE")
-    tracker.add("kilocode", "Kilo Code IDE")
-    tracker.add("opencode", "opencode")
-    tracker.add("codex", "Codex CLI")
-    tracker.add("auggie", "Auggie CLI")
-    
-    git_ok = check_tool_for_tracker("git", tracker)
-    claude_ok = check_tool_for_tracker("claude", tracker)  
-    gemini_ok = check_tool_for_tracker("gemini", tracker)
-    qwen_ok = check_tool_for_tracker("qwen", tracker)
-    code_ok = check_tool_for_tracker("code", tracker)
-    code_insiders_ok = check_tool_for_tracker("code-insiders", tracker)
-    cursor_ok = check_tool_for_tracker("cursor-agent", tracker)
-    windsurf_ok = check_tool_for_tracker("windsurf", tracker)
-    kilocode_ok = check_tool_for_tracker("kilocode", tracker)
-    opencode_ok = check_tool_for_tracker("opencode", tracker)
-    codex_ok = check_tool_for_tracker("codex", tracker)
-    auggie_ok = check_tool_for_tracker("auggie", tracker)
+    code_insiders_ok = check_tool("code-insiders", tracker=tracker)
 
     console.print(tracker.render())
 
@@ -1121,13 +1192,13 @@ def check():
 
     if not git_ok:
         console.print("[dim]Tip: Install git for repository management[/dim]")
-    if not (claude_ok or gemini_ok or cursor_ok or qwen_ok or windsurf_ok or kilocode_ok or opencode_ok or codex_ok or auggie_ok):
-        console.print("[dim]Tip: Install an AI assistant for the best experience[/dim]")
 
+    if not any(agent_results.values()):
+        console.print("[dim]Tip: Install an AI assistant for the best experience[/dim]")
 
 def main():
     app()
 
-
 if __name__ == "__main__":
     main()
+
diff --git a/templates/agent-file-template.md b/templates/agent-file-template.md
index 2301e0e..f734997 100644
--- a/templates/agent-file-template.md
+++ b/templates/agent-file-template.md
@@ -20,4 +20,4 @@ Auto-generated from all feature plans. Last updated: [DATE]
 [LAST 3 FEATURES AND WHAT THEY ADDED]
 
 <!-- MANUAL ADDITIONS START -->
-<!-- MANUAL ADDITIONS END -->
\ No newline at end of file
+<!-- MANUAL ADDITIONS END -->
diff --git a/templates/checklist-template.md b/templates/checklist-template.md
new file mode 100644
index 0000000..1c8b11a
--- /dev/null
+++ b/templates/checklist-template.md
@@ -0,0 +1,41 @@
+# [CHECKLIST TYPE] Checklist: [FEATURE NAME]
+
+**Purpose**: [Brief description of what this checklist covers]
+**Created**: [DATE]
+**Feature**: [Link to spec.md or relevant documentation]
+
+**Note**: This checklist is generated by the `/speckit.checklist` command based on feature context and requirements.
+
+<!-- 
+  ============================================================================
+  IMPORTANT: The checklist items below are SAMPLE ITEMS for illustration only.
+  
+  The /speckit.checklist command MUST replace these with actual items based on:
+  - User's specific checklist request
+  - Feature requirements from spec.md
+  - Technical context from plan.md
+  - Implementation details from tasks.md
+  
+  DO NOT keep these sample items in the generated checklist file.
+  ============================================================================
+-->
+
+## [Category 1]
+
+- [ ] CHK001 First checklist item with clear action
+- [ ] CHK002 Second checklist item
+- [ ] CHK003 Third checklist item
+
+## [Category 2]
+
+- [ ] CHK004 Another category item
+- [ ] CHK005 Item with specific criteria
+- [ ] CHK006 Final item in this category
+
+## Notes
+
+- Check items off as completed: `[x]`
+- Add comments or findings inline
+- Link to relevant resources or documentation
+- Items are numbered sequentially for easy reference
+
diff --git a/templates/commands/analyze.md b/templates/commands/analyze.md
index c07d550..82957e5 100644
--- a/templates/commands/analyze.md
+++ b/templates/commands/analyze.md
@@ -5,100 +5,184 @@ scripts:
   ps: scripts/powershell/check-prerequisites.ps1 -Json -RequireTasks -IncludeTasks
 ---
 
-The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Goal
+
+Identify inconsistencies, duplications, ambiguities, and underspecified items across the three core artifacts (`spec.md`, `plan.md`, `tasks.md`) before implementation. This command MUST run only after `/tasks` has successfully produced a complete `tasks.md`.
+
+## Operating Constraints
+
+**STRICTLY READ-ONLY**: Do **not** modify any files. Output a structured analysis report. Offer an optional remediation plan (user must explicitly approve before any follow-up editing commands would be invoked manually).
+
+**Constitution Authority**: The project constitution (`/memory/constitution.md`) is **non-negotiable** within this analysis scope. Constitution conflicts are automatically CRITICAL and require adjustment of the spec, plan, or tasks—not dilution, reinterpretation, or silent ignoring of the principle. If a principle itself needs to change, that must occur in a separate, explicit constitution update outside `/analyze`.
+
+## Execution Steps
+
+### 1. Initialize Analysis Context
+
+Run `{SCRIPT}` once from repo root and parse JSON for FEATURE_DIR and AVAILABLE_DOCS. Derive absolute paths:
+
+- SPEC = FEATURE_DIR/spec.md
+- PLAN = FEATURE_DIR/plan.md
+- TASKS = FEATURE_DIR/tasks.md
+
+Abort with an error message if any required file is missing (instruct the user to run missing prerequisite command).
+For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").
+
+### 2. Load Artifacts (Progressive Disclosure)
+
+Load only the minimal necessary context from each artifact:
+
+**From spec.md:**
+
+- Overview/Context
+- Functional Requirements
+- Non-Functional Requirements
+- User Stories
+- Edge Cases (if present)
+
+**From plan.md:**
+
+- Architecture/stack choices
+- Data Model references
+- Phases
+- Technical constraints
+
+**From tasks.md:**
+
+- Task IDs
+- Descriptions
+- Phase grouping
+- Parallel markers [P]
+- Referenced file paths
+
+**From constitution:**
+
+- Load `/memory/constitution.md` for principle validation
+
+### 3. Build Semantic Models
+
+Create internal representations (do not include raw artifacts in output):
+
+- **Requirements inventory**: Each functional + non-functional requirement with a stable key (derive slug based on imperative phrase; e.g., "User can upload file" → `user-can-upload-file`)
+- **User story/action inventory**: Discrete user actions with acceptance criteria
+- **Task coverage mapping**: Map each task to one or more requirements or stories (inference by keyword / explicit reference patterns like IDs or key phrases)
+- **Constitution rule set**: Extract principle names and MUST/SHOULD normative statements
+
+### 4. Detection Passes (Token-Efficient Analysis)
+
+Focus on high-signal findings. Limit to 50 findings total; aggregate remainder in overflow summary.
+
+#### A. Duplication Detection
+
+- Identify near-duplicate requirements
+- Mark lower-quality phrasing for consolidation
+
+#### B. Ambiguity Detection
+
+- Flag vague adjectives (fast, scalable, secure, intuitive, robust) lacking measurable criteria
+- Flag unresolved placeholders (TODO, TKTK, ???, `<placeholder>`, etc.)
+
+#### C. Underspecification
+
+- Requirements with verbs but missing object or measurable outcome
+- User stories missing acceptance criteria alignment
+- Tasks referencing files or components not defined in spec/plan
+
+#### D. Constitution Alignment
+
+- Any requirement or plan element conflicting with a MUST principle
+- Missing mandated sections or quality gates from constitution
+
+#### E. Coverage Gaps
+
+- Requirements with zero associated tasks
+- Tasks with no mapped requirement/story
+- Non-functional requirements not reflected in tasks (e.g., performance, security)
+
+#### F. Inconsistency
+
+- Terminology drift (same concept named differently across files)
+- Data entities referenced in plan but absent in spec (or vice versa)
+- Task ordering contradictions (e.g., integration tasks before foundational setup tasks without dependency note)
+- Conflicting requirements (e.g., one requires Next.js while other specifies Vue)
+
+### 5. Severity Assignment
+
+Use this heuristic to prioritize findings:
+
+- **CRITICAL**: Violates constitution MUST, missing core spec artifact, or requirement with zero coverage that blocks baseline functionality
+- **HIGH**: Duplicate or conflicting requirement, ambiguous security/performance attribute, untestable acceptance criterion
+- **MEDIUM**: Terminology drift, missing non-functional task coverage, underspecified edge case
+- **LOW**: Style/wording improvements, minor redundancy not affecting execution order
+
+### 6. Produce Compact Analysis Report
+
+Output a Markdown report (no file writes) with the following structure:
+
+## Specification Analysis Report
+
+| ID | Category | Severity | Location(s) | Summary | Recommendation |
+|----|----------|----------|-------------|---------|----------------|
+| A1 | Duplication | HIGH | spec.md:L120-134 | Two similar requirements ... | Merge phrasing; keep clearer version |
+
+(Add one row per finding; generate stable IDs prefixed by category initial.)
+
+**Coverage Summary Table:**
+
+| Requirement Key | Has Task? | Task IDs | Notes |
+|-----------------|-----------|----------|-------|
+
+**Constitution Alignment Issues:** (if any)
+
+**Unmapped Tasks:** (if any)
+
+**Metrics:**
+
+- Total Requirements
+- Total Tasks
+- Coverage % (requirements with >=1 task)
+- Ambiguity Count
+- Duplication Count
+- Critical Issues Count
+
+### 7. Provide Next Actions
+
+At end of report, output a concise Next Actions block:
+
+- If CRITICAL issues exist: Recommend resolving before `/implement`
+- If only LOW/MEDIUM: User may proceed, but provide improvement suggestions
+- Provide explicit command suggestions: e.g., "Run /specify with refinement", "Run /plan to adjust architecture", "Manually edit tasks.md to add coverage for 'performance-metrics'"
+
+### 8. Offer Remediation
+
+Ask the user: "Would you like me to suggest concrete remediation edits for the top N issues?" (Do NOT apply them automatically.)
+
+## Operating Principles
+
+### Context Efficiency
+
+- **Minimal high-signal tokens**: Focus on actionable findings, not exhaustive documentation
+- **Progressive disclosure**: Load artifacts incrementally; don't dump all content into analysis
+- **Token-efficient output**: Limit findings table to 50 rows; summarize overflow
+- **Deterministic results**: Rerunning without changes should produce consistent IDs and counts
+
+### Analysis Guidelines
+
+- **NEVER modify files** (this is read-only analysis)
+- **NEVER hallucinate missing sections** (if absent, report them accurately)
+- **Prioritize constitution violations** (these are always CRITICAL)
+- **Use examples over exhaustive rules** (cite specific instances, not generic patterns)
+- **Report zero issues gracefully** (emit success report with coverage statistics)
+
+## Context
+
+{ARGS}
 
-Goal: Identify inconsistencies, duplications, ambiguities, and underspecified items across the three core artifacts (`spec.md`, `plan.md`, `tasks.md`) before implementation. This command MUST run only after `/tasks` has successfully produced a complete `tasks.md`.
-
-STRICTLY READ-ONLY: Do **not** modify any files. Output a structured analysis report. Offer an optional remediation plan (user must explicitly approve before any follow-up editing commands would be invoked manually).
-
-Constitution Authority: The project constitution (`/memory/constitution.md`) is **non-negotiable** within this analysis scope. Constitution conflicts are automatically CRITICAL and require adjustment of the spec, plan, or tasks—not dilution, reinterpretation, or silent ignoring of the principle. If a principle itself needs to change, that must occur in a separate, explicit constitution update outside `/analyze`.
-
-Execution steps:
-
-1. Run `{SCRIPT}` once from repo root and parse JSON for FEATURE_DIR and AVAILABLE_DOCS. Derive absolute paths:
-   - SPEC = FEATURE_DIR/spec.md
-   - PLAN = FEATURE_DIR/plan.md
-   - TASKS = FEATURE_DIR/tasks.md
-   Abort with an error message if any required file is missing (instruct the user to run missing prerequisite command).
-
-2. Load artifacts:
-   - Parse spec.md sections: Overview/Context, Functional Requirements, Non-Functional Requirements, User Stories, Edge Cases (if present).
-   - Parse plan.md: Architecture/stack choices, Data Model references, Phases, Technical constraints.
-   - Parse tasks.md: Task IDs, descriptions, phase grouping, parallel markers [P], referenced file paths.
-   - Load constitution `/memory/constitution.md` for principle validation.
-
-3. Build internal semantic models:
-   - Requirements inventory: Each functional + non-functional requirement with a stable key (derive slug based on imperative phrase; e.g., "User can upload file" -> `user-can-upload-file`).
-   - User story/action inventory.
-   - Task coverage mapping: Map each task to one or more requirements or stories (inference by keyword / explicit reference patterns like IDs or key phrases).
-   - Constitution rule set: Extract principle names and any MUST/SHOULD normative statements.
-
-4. Detection passes:
-   A. Duplication detection:
-      - Identify near-duplicate requirements. Mark lower-quality phrasing for consolidation.
-   B. Ambiguity detection:
-      - Flag vague adjectives (fast, scalable, secure, intuitive, robust) lacking measurable criteria.
-      - Flag unresolved placeholders (TODO, TKTK, ???, <placeholder>, etc.).
-   C. Underspecification:
-      - Requirements with verbs but missing object or measurable outcome.
-      - User stories missing acceptance criteria alignment.
-      - Tasks referencing files or components not defined in spec/plan.
-   D. Constitution alignment:
-      - Any requirement or plan element conflicting with a MUST principle.
-      - Missing mandated sections or quality gates from constitution.
-   E. Coverage gaps:
-      - Requirements with zero associated tasks.
-      - Tasks with no mapped requirement/story.
-      - Non-functional requirements not reflected in tasks (e.g., performance, security).
-   F. Inconsistency:
-      - Terminology drift (same concept named differently across files).
-      - Data entities referenced in plan but absent in spec (or vice versa).
-      - Task ordering contradictions (e.g., integration tasks before foundational setup tasks without dependency note).
-      - Conflicting requirements (e.g., one requires to use Next.js while other says to use Vue as the framework).
-
-5. Severity assignment heuristic:
-   - CRITICAL: Violates constitution MUST, missing core spec artifact, or requirement with zero coverage that blocks baseline functionality.
-   - HIGH: Duplicate or conflicting requirement, ambiguous security/performance attribute, untestable acceptance criterion.
-   - MEDIUM: Terminology drift, missing non-functional task coverage, underspecified edge case.
-   - LOW: Style/wording improvements, minor redundancy not affecting execution order.
-
-6. Produce a Markdown report (no file writes) with sections:
-
-   ### Specification Analysis Report
-   | ID | Category | Severity | Location(s) | Summary | Recommendation |
-   |----|----------|----------|-------------|---------|----------------|
-   | A1 | Duplication | HIGH | spec.md:L120-134 | Two similar requirements ... | Merge phrasing; keep clearer version |
-   (Add one row per finding; generate stable IDs prefixed by category initial.)
-
-   Additional subsections:
-   - Coverage Summary Table:
-     | Requirement Key | Has Task? | Task IDs | Notes |
-   - Constitution Alignment Issues (if any)
-   - Unmapped Tasks (if any)
-   - Metrics:
-     * Total Requirements
-     * Total Tasks
-     * Coverage % (requirements with >=1 task)
-     * Ambiguity Count
-     * Duplication Count
-     * Critical Issues Count
-
-7. At end of report, output a concise Next Actions block:
-   - If CRITICAL issues exist: Recommend resolving before `/implement`.
-   - If only LOW/MEDIUM: User may proceed, but provide improvement suggestions.
-   - Provide explicit command suggestions: e.g., "Run /specify with refinement", "Run /plan to adjust architecture", "Manually edit tasks.md to add coverage for 'performance-metrics'".
-
-8. Ask the user: "Would you like me to suggest concrete remediation edits for the top N issues?" (Do NOT apply them automatically.)
-
-Behavior rules:
-- NEVER modify files.
-- NEVER hallucinate missing sections—if absent, report them.
-- KEEP findings deterministic: if rerun without changes, produce consistent IDs and counts.
-- LIMIT total findings in the main table to 50; aggregate remainder in a summarized overflow note.
-- If zero issues found, emit a success report with coverage statistics and proceed recommendation.
-
-Context: {ARGS}
diff --git a/templates/commands/checklist.md b/templates/commands/checklist.md
new file mode 100644
index 0000000..0900e33
--- /dev/null
+++ b/templates/commands/checklist.md
@@ -0,0 +1,291 @@
+---
+description: Generate a custom checklist for the current feature based on user requirements.
+scripts:
+  sh: scripts/bash/check-prerequisites.sh --json
+  ps: scripts/powershell/check-prerequisites.ps1 -Json
+---
+
+## Checklist Purpose: "Unit Tests for English"
+
+**CRITICAL CONCEPT**: Checklists are **UNIT TESTS FOR REQUIREMENTS WRITING** - they validate the quality, clarity, and completeness of requirements in a given domain.
+
+**NOT for verification/testing**:
+- ❌ NOT "Verify the button clicks correctly"
+- ❌ NOT "Test error handling works"
+- ❌ NOT "Confirm the API returns 200"
+- ❌ NOT checking if code/implementation matches the spec
+
+**FOR requirements quality validation**:
+- ✅ "Are visual hierarchy requirements defined for all card types?" (completeness)
+- ✅ "Is 'prominent display' quantified with specific sizing/positioning?" (clarity)
+- ✅ "Are hover state requirements consistent across all interactive elements?" (consistency)
+- ✅ "Are accessibility requirements defined for keyboard navigation?" (coverage)
+- ✅ "Does the spec define what happens when logo image fails to load?" (edge cases)
+
+**Metaphor**: If your spec is code written in English, the checklist is its unit test suite. You're testing whether the requirements are well-written, complete, unambiguous, and ready for implementation - NOT whether the implementation works.
+
+## User Input
+
+```text
+$ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Execution Steps
+
+1. **Setup**: Run `{SCRIPT}` from repo root and parse JSON for FEATURE_DIR and AVAILABLE_DOCS list.
+   - All file paths must be absolute.
+   - For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").
+
+2. **Clarify intent (dynamic)**: Derive up to THREE initial contextual clarifying questions (no pre-baked catalog). They MUST:
+   - Be generated from the user's phrasing + extracted signals from spec/plan/tasks
+   - Only ask about information that materially changes checklist content
+   - Be skipped individually if already unambiguous in `$ARGUMENTS`
+   - Prefer precision over breadth
+
+   Generation algorithm:
+   1. Extract signals: feature domain keywords (e.g., auth, latency, UX, API), risk indicators ("critical", "must", "compliance"), stakeholder hints ("QA", "review", "security team"), and explicit deliverables ("a11y", "rollback", "contracts").
+   2. Cluster signals into candidate focus areas (max 4) ranked by relevance.
+   3. Identify probable audience & timing (author, reviewer, QA, release) if not explicit.
+   4. Detect missing dimensions: scope breadth, depth/rigor, risk emphasis, exclusion boundaries, measurable acceptance criteria.
+   5. Formulate questions chosen from these archetypes:
+      - Scope refinement (e.g., "Should this include integration touchpoints with X and Y or stay limited to local module correctness?")
+      - Risk prioritization (e.g., "Which of these potential risk areas should receive mandatory gating checks?")
+      - Depth calibration (e.g., "Is this a lightweight pre-commit sanity list or a formal release gate?")
+      - Audience framing (e.g., "Will this be used by the author only or peers during PR review?")
+      - Boundary exclusion (e.g., "Should we explicitly exclude performance tuning items this round?")
+      - Scenario class gap (e.g., "No recovery flows detected—are rollback / partial failure paths in scope?")
+
+   Question formatting rules:
+   - If presenting options, generate a compact table with columns: Option | Candidate | Why It Matters
+   - Limit to A–E options maximum; omit table if a free-form answer is clearer
+   - Never ask the user to restate what they already said
+   - Avoid speculative categories (no hallucination). If uncertain, ask explicitly: "Confirm whether X belongs in scope."
+
+   Defaults when interaction impossible:
+   - Depth: Standard
+   - Audience: Reviewer (PR) if code-related; Author otherwise
+   - Focus: Top 2 relevance clusters
+
+   Output the questions (label Q1/Q2/Q3). After answers: if ≥2 scenario classes (Alternate / Exception / Recovery / Non-Functional domain) remain unclear, you MAY ask up to TWO more targeted follow‑ups (Q4/Q5) with a one-line justification each (e.g., "Unresolved recovery path risk"). Do not exceed five total questions. Skip escalation if user explicitly declines more.
+
+3. **Understand user request**: Combine `$ARGUMENTS` + clarifying answers:
+   - Derive checklist theme (e.g., security, review, deploy, ux)
+   - Consolidate explicit must-have items mentioned by user
+   - Map focus selections to category scaffolding
+   - Infer any missing context from spec/plan/tasks (do NOT hallucinate)
+
+4. **Load feature context**: Read from FEATURE_DIR:
+   - spec.md: Feature requirements and scope
+   - plan.md (if exists): Technical details, dependencies
+   - tasks.md (if exists): Implementation tasks
+   
+   **Context Loading Strategy**:
+   - Load only necessary portions relevant to active focus areas (avoid full-file dumping)
+   - Prefer summarizing long sections into concise scenario/requirement bullets
+   - Use progressive disclosure: add follow-on retrieval only if gaps detected
+   - If source docs are large, generate interim summary items instead of embedding raw text
+
+5. **Generate checklist** - Create "Unit Tests for Requirements":
+   - Create `FEATURE_DIR/checklists/` directory if it doesn't exist
+   - Generate unique checklist filename:
+     - Use short, descriptive name based on domain (e.g., `ux.md`, `api.md`, `security.md`)
+     - Format: `[domain].md` 
+     - If file exists, append to existing file
+   - Number items sequentially starting from CHK001
+   - Each `/speckit.checklist` run creates a NEW file (never overwrites existing checklists)
+
+   **CORE PRINCIPLE - Test the Requirements, Not the Implementation**:
+   Every checklist item MUST evaluate the REQUIREMENTS THEMSELVES for:
+   - **Completeness**: Are all necessary requirements present?
+   - **Clarity**: Are requirements unambiguous and specific?
+   - **Consistency**: Do requirements align with each other?
+   - **Measurability**: Can requirements be objectively verified?
+   - **Coverage**: Are all scenarios/edge cases addressed?
+   
+   **Category Structure** - Group items by requirement quality dimensions:
+   - **Requirement Completeness** (Are all necessary requirements documented?)
+   - **Requirement Clarity** (Are requirements specific and unambiguous?)
+   - **Requirement Consistency** (Do requirements align without conflicts?)
+   - **Acceptance Criteria Quality** (Are success criteria measurable?)
+   - **Scenario Coverage** (Are all flows/cases addressed?)
+   - **Edge Case Coverage** (Are boundary conditions defined?)
+   - **Non-Functional Requirements** (Performance, Security, Accessibility, etc. - are they specified?)
+   - **Dependencies & Assumptions** (Are they documented and validated?)
+   - **Ambiguities & Conflicts** (What needs clarification?)
+   
+   **HOW TO WRITE CHECKLIST ITEMS - "Unit Tests for English"**:
+   
+   ❌ **WRONG** (Testing implementation):
+   - "Verify landing page displays 3 episode cards"
+   - "Test hover states work on desktop"
+   - "Confirm logo click navigates home"
+   
+   ✅ **CORRECT** (Testing requirements quality):
+   - "Are the exact number and layout of featured episodes specified?" [Completeness]
+   - "Is 'prominent display' quantified with specific sizing/positioning?" [Clarity]
+   - "Are hover state requirements consistent across all interactive elements?" [Consistency]
+   - "Are keyboard navigation requirements defined for all interactive UI?" [Coverage]
+   - "Is the fallback behavior specified when logo image fails to load?" [Edge Cases]
+   - "Are loading states defined for asynchronous episode data?" [Completeness]
+   - "Does the spec define visual hierarchy for competing UI elements?" [Clarity]
+   
+   **ITEM STRUCTURE**:
+   Each item should follow this pattern:
+   - Question format asking about requirement quality
+   - Focus on what's WRITTEN (or not written) in the spec/plan
+   - Include quality dimension in brackets [Completeness/Clarity/Consistency/etc.]
+   - Reference spec section `[Spec §X.Y]` when checking existing requirements
+   - Use `[Gap]` marker when checking for missing requirements
+   
+   **EXAMPLES BY QUALITY DIMENSION**:
+   
+   Completeness:
+   - "Are error handling requirements defined for all API failure modes? [Gap]"
+   - "Are accessibility requirements specified for all interactive elements? [Completeness]"
+   - "Are mobile breakpoint requirements defined for responsive layouts? [Gap]"
+   
+   Clarity:
+   - "Is 'fast loading' quantified with specific timing thresholds? [Clarity, Spec §NFR-2]"
+   - "Are 'related episodes' selection criteria explicitly defined? [Clarity, Spec §FR-5]"
+   - "Is 'prominent' defined with measurable visual properties? [Ambiguity, Spec §FR-4]"
+   
+   Consistency:
+   - "Do navigation requirements align across all pages? [Consistency, Spec §FR-10]"
+   - "Are card component requirements consistent between landing and detail pages? [Consistency]"
+   
+   Coverage:
+   - "Are requirements defined for zero-state scenarios (no episodes)? [Coverage, Edge Case]"
+   - "Are concurrent user interaction scenarios addressed? [Coverage, Gap]"
+   - "Are requirements specified for partial data loading failures? [Coverage, Exception Flow]"
+   
+   Measurability:
+   - "Are visual hierarchy requirements measurable/testable? [Acceptance Criteria, Spec §FR-1]"
+   - "Can 'balanced visual weight' be objectively verified? [Measurability, Spec §FR-2]"
+
+   **Scenario Classification & Coverage** (Requirements Quality Focus):
+   - Check if requirements exist for: Primary, Alternate, Exception/Error, Recovery, Non-Functional scenarios
+   - For each scenario class, ask: "Are [scenario type] requirements complete, clear, and consistent?"
+   - If scenario class missing: "Are [scenario type] requirements intentionally excluded or missing? [Gap]"
+   - Include resilience/rollback when state mutation occurs: "Are rollback requirements defined for migration failures? [Gap]"
+
+   **Traceability Requirements**:
+   - MINIMUM: ≥80% of items MUST include at least one traceability reference
+   - Each item should reference: spec section `[Spec §X.Y]`, or use markers: `[Gap]`, `[Ambiguity]`, `[Conflict]`, `[Assumption]`
+   - If no ID system exists: "Is a requirement & acceptance criteria ID scheme established? [Traceability]"
+
+   **Surface & Resolve Issues** (Requirements Quality Problems):
+   Ask questions about the requirements themselves:
+   - Ambiguities: "Is the term 'fast' quantified with specific metrics? [Ambiguity, Spec §NFR-1]"
+   - Conflicts: "Do navigation requirements conflict between §FR-10 and §FR-10a? [Conflict]"
+   - Assumptions: "Is the assumption of 'always available podcast API' validated? [Assumption]"
+   - Dependencies: "Are external podcast API requirements documented? [Dependency, Gap]"
+   - Missing definitions: "Is 'visual hierarchy' defined with measurable criteria? [Gap]"
+
+   **Content Consolidation**:
+   - Soft cap: If raw candidate items > 40, prioritize by risk/impact
+   - Merge near-duplicates checking the same requirement aspect
+   - If >5 low-impact edge cases, create one item: "Are edge cases X, Y, Z addressed in requirements? [Coverage]"
+
+   **🚫 ABSOLUTELY PROHIBITED** - These make it an implementation test, not a requirements test:
+   - ❌ Any item starting with "Verify", "Test", "Confirm", "Check" + implementation behavior
+   - ❌ References to code execution, user actions, system behavior
+   - ❌ "Displays correctly", "works properly", "functions as expected"
+   - ❌ "Click", "navigate", "render", "load", "execute"
+   - ❌ Test cases, test plans, QA procedures
+   - ❌ Implementation details (frameworks, APIs, algorithms)
+   
+   **✅ REQUIRED PATTERNS** - These test requirements quality:
+   - ✅ "Are [requirement type] defined/specified/documented for [scenario]?"
+   - ✅ "Is [vague term] quantified/clarified with specific criteria?"
+   - ✅ "Are requirements consistent between [section A] and [section B]?"
+   - ✅ "Can [requirement] be objectively measured/verified?"
+   - ✅ "Are [edge cases/scenarios] addressed in requirements?"
+   - ✅ "Does the spec define [missing aspect]?"
+
+6. **Structure Reference**: Generate the checklist following the canonical template in `templates/checklist-template.md` for title, meta section, category headings, and ID formatting. If template is unavailable, use: H1 title, purpose/created meta lines, `##` category sections containing `- [ ] CHK### <requirement item>` lines with globally incrementing IDs starting at CHK001.
+
+7. **Report**: Output full path to created checklist, item count, and remind user that each run creates a new file. Summarize:
+   - Focus areas selected
+   - Depth level
+   - Actor/timing
+   - Any explicit user-specified must-have items incorporated
+
+**Important**: Each `/speckit.checklist` command invocation creates a checklist file using short, descriptive names unless file already exists. This allows:
+
+- Multiple checklists of different types (e.g., `ux.md`, `test.md`, `security.md`)
+- Simple, memorable filenames that indicate checklist purpose
+- Easy identification and navigation in the `checklists/` folder
+
+To avoid clutter, use descriptive types and clean up obsolete checklists when done.
+
+## Example Checklist Types & Sample Items
+
+**UX Requirements Quality:** `ux.md`
+
+Sample items (testing the requirements, NOT the implementation):
+- "Are visual hierarchy requirements defined with measurable criteria? [Clarity, Spec §FR-1]"
+- "Is the number and positioning of UI elements explicitly specified? [Completeness, Spec §FR-1]"
+- "Are interaction state requirements (hover, focus, active) consistently defined? [Consistency]"
+- "Are accessibility requirements specified for all interactive elements? [Coverage, Gap]"
+- "Is fallback behavior defined when images fail to load? [Edge Case, Gap]"
+- "Can 'prominent display' be objectively measured? [Measurability, Spec §FR-4]"
+
+**API Requirements Quality:** `api.md`
+
+Sample items:
+- "Are error response formats specified for all failure scenarios? [Completeness]"
+- "Are rate limiting requirements quantified with specific thresholds? [Clarity]"
+- "Are authentication requirements consistent across all endpoints? [Consistency]"
+- "Are retry/timeout requirements defined for external dependencies? [Coverage, Gap]"
+- "Is versioning strategy documented in requirements? [Gap]"
+
+**Performance Requirements Quality:** `performance.md`
+
+Sample items:
+- "Are performance requirements quantified with specific metrics? [Clarity]"
+- "Are performance targets defined for all critical user journeys? [Coverage]"
+- "Are performance requirements under different load conditions specified? [Completeness]"
+- "Can performance requirements be objectively measured? [Measurability]"
+- "Are degradation requirements defined for high-load scenarios? [Edge Case, Gap]"
+
+**Security Requirements Quality:** `security.md`
+
+Sample items:
+- "Are authentication requirements specified for all protected resources? [Coverage]"
+- "Are data protection requirements defined for sensitive information? [Completeness]"
+- "Is the threat model documented and requirements aligned to it? [Traceability]"
+- "Are security requirements consistent with compliance obligations? [Consistency]"
+- "Are security failure/breach response requirements defined? [Gap, Exception Flow]"
+
+## Anti-Examples: What NOT To Do
+
+**❌ WRONG - These test implementation, not requirements:**
+
+```markdown
+- [ ] CHK001 - Verify landing page displays 3 episode cards [Spec §FR-001]
+- [ ] CHK002 - Test hover states work correctly on desktop [Spec §FR-003]
+- [ ] CHK003 - Confirm logo click navigates to home page [Spec §FR-010]
+- [ ] CHK004 - Check that related episodes section shows 3-5 items [Spec §FR-005]
+```
+
+**✅ CORRECT - These test requirements quality:**
+
+```markdown
+- [ ] CHK001 - Are the number and layout of featured episodes explicitly specified? [Completeness, Spec §FR-001]
+- [ ] CHK002 - Are hover state requirements consistently defined for all interactive elements? [Consistency, Spec §FR-003]
+- [ ] CHK003 - Are navigation requirements clear for all clickable brand elements? [Clarity, Spec §FR-010]
+- [ ] CHK004 - Is the selection criteria for related episodes documented? [Gap, Spec §FR-005]
+- [ ] CHK005 - Are loading state requirements defined for asynchronous episode data? [Gap]
+- [ ] CHK006 - Can "visual hierarchy" requirements be objectively measured? [Measurability, Spec §FR-001]
+```
+
+**Key Differences:**
+- Wrong: Tests if the system works correctly
+- Correct: Tests if the requirements are written correctly
+- Wrong: Verification of behavior
+- Correct: Validation of requirement quality
+- Wrong: "Does it do X?" 
+- Correct: "Is X clearly specified?"
+
diff --git a/templates/commands/clarify.md b/templates/commands/clarify.md
index e3f4a79..65f2536 100644
--- a/templates/commands/clarify.md
+++ b/templates/commands/clarify.md
@@ -5,15 +5,19 @@ scripts:
    ps: scripts/powershell/check-prerequisites.ps1 -Json -PathsOnly
 ---
 
-The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Outline
 
 Goal: Detect and reduce ambiguity or missing decision points in the active feature specification and record the clarifications directly in the spec file.
 
-Note: This clarification workflow is expected to run (and be completed) BEFORE invoking `/plan`. If the user explicitly states they are skipping clarification (e.g., exploratory spike), you may proceed, but must warn that downstream rework risk increases.
+Note: This clarification workflow is expected to run (and be completed) BEFORE invoking `/speckit.plan`. If the user explicitly states they are skipping clarification (e.g., exploratory spike), you may proceed, but must warn that downstream rework risk increases.
 
 Execution steps:
 
@@ -21,7 +25,8 @@ Execution steps:
    - `FEATURE_DIR`
    - `FEATURE_SPEC`
    - (Optionally capture `IMPL_PLAN`, `TASKS` for future chained flows.)
-   - If JSON parsing fails, abort and instruct user to re-run `/specify` or verify feature branch environment.
+   - If JSON parsing fails, abort and instruct user to re-run `/speckit.specify` or verify feature branch environment.
+   - For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").
 
 2. Load the current spec file. Perform a structured ambiguity & coverage scan using this taxonomy. For each category, mark status: Clear / Partial / Missing. Produce an internal coverage map used for prioritization (do not output raw map unless no questions will be asked).
 
@@ -80,7 +85,7 @@ Execution steps:
    - Information is better deferred to planning phase (note internally)
 
 3. Generate (internally) a prioritized queue of candidate clarification questions (maximum 5). Do NOT output them all at once. Apply these constraints:
-    - Maximum of 5 total questions across the whole session.
+    - Maximum of 10 total questions across the whole session.
     - Each question must be answerable with EITHER:
        * A short multiple‑choice selection (2–5 distinct, mutually exclusive options), OR
        * A one-word / short‑phrase answer (explicitly constrain: "Answer in <=5 words").
@@ -92,7 +97,15 @@ Execution steps:
 
 4. Sequential questioning loop (interactive):
     - Present EXACTLY ONE question at a time.
-    - For multiple‑choice questions render options as a Markdown table:
+    - For multiple‑choice questions:
+       * **Analyze all options** and determine the **most suitable option** based on:
+          - Best practices for the project type
+          - Common patterns in similar implementations
+          - Risk reduction (security, performance, maintainability)
+          - Alignment with any explicit project goals or constraints visible in the spec
+       * Present your **recommended option prominently** at the top with clear reasoning (1-2 sentences explaining why this is the best choice).
+       * Format as: `**Recommended:** Option [X] - <reasoning>`
+       * Then render all options as a Markdown table:
 
        | Option | Description |
        |--------|-------------|
@@ -101,9 +114,14 @@ Execution steps:
        | C | <Option C description> | (add D/E as needed up to 5)
        | Short | Provide a different short answer (<=5 words) | (Include only if free-form alternative is appropriate)
 
-    - For short‑answer style (no meaningful discrete options), output a single line after the question: `Format: Short answer (<=5 words)`.
+       * After the table, add: `You can reply with the option letter (e.g., "A"), accept the recommendation by saying "yes" or "recommended", or provide your own short answer.`
+    - For short‑answer style (no meaningful discrete options):
+       * Provide your **suggested answer** based on best practices and context.
+       * Format as: `**Suggested:** <your proposed answer> - <brief reasoning>`
+       * Then output: `Format: Short answer (<=5 words). You can accept the suggestion by saying "yes" or "suggested", or provide your own answer.`
     - After the user answers:
-       * Validate the answer maps to one option or fits the <=5 word constraint.
+       * If the user replies with "yes", "recommended", or "suggested", use your previously stated recommendation/suggestion as the answer.
+       * Otherwise, validate the answer maps to one option or fits the <=5 word constraint.
        * If ambiguous, ask for a quick disambiguation (count still belongs to same question; do not advance).
        * Once satisfactory, record it in working memory (do not yet write to disk) and move to the next queued question.
     - Stop asking further questions when:
@@ -146,12 +164,12 @@ Execution steps:
    - Path to updated spec.
    - Sections touched (list names).
    - Coverage summary table listing each taxonomy category with Status: Resolved (was Partial/Missing and addressed), Deferred (exceeds question quota or better suited for planning), Clear (already sufficient), Outstanding (still Partial/Missing but low impact).
-   - If any Outstanding or Deferred remain, recommend whether to proceed to `/plan` or run `/clarify` again later post-plan.
+   - If any Outstanding or Deferred remain, recommend whether to proceed to `/speckit.plan` or run `/speckit.clarify` again later post-plan.
    - Suggested next command.
 
 Behavior rules:
 - If no meaningful ambiguities found (or all potential questions would be low-impact), respond: "No critical ambiguities detected worth formal clarification." and suggest proceeding.
-- If spec file missing, instruct user to run `/specify` first (do not create a new spec here).
+- If spec file missing, instruct user to run `/speckit.specify` first (do not create a new spec here).
 - Never exceed 5 total asked questions (clarification retries for a single question do not count as new questions).
 - Avoid speculative tech stack questions unless the absence blocks functional clarity.
 - Respect user early termination signals ("stop", "done", "proceed").
@@ -159,3 +177,4 @@ Behavior rules:
  - If quota reached with unresolved high-impact categories remaining, explicitly flag them under Deferred with rationale.
 
 Context for prioritization: {ARGS}
+
diff --git a/templates/commands/constitution.md b/templates/commands/constitution.md
index 605e936..dc07934 100644
--- a/templates/commands/constitution.md
+++ b/templates/commands/constitution.md
@@ -2,11 +2,15 @@
 description: Create or update the project constitution from interactive or provided principle inputs, ensuring all dependent templates stay in sync.
 ---
 
-The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Outline
 
 You are updating the project constitution at `/memory/constitution.md`. This file is a TEMPLATE containing placeholder tokens in square brackets (e.g. `[PROJECT_NAME]`, `[PRINCIPLE_1_NAME]`). Your job is to (a) collect/derive concrete values, (b) fill the template precisely, and (c) propagate any amendments across dependent artifacts.
 
@@ -71,3 +75,4 @@ If the user supplies partial updates (e.g., only one principle revision), still
 If critical info missing (e.g., ratification date truly unknown), insert `TODO(<FIELD_NAME>): explanation` and include in the Sync Impact Report under deferred items.
 
 Do not create a new template; always operate on the existing `/memory/constitution.md` file.
+
diff --git a/templates/commands/implement.md b/templates/commands/implement.md
index ff2f1b6..c4e7c17 100644
--- a/templates/commands/implement.md
+++ b/templates/commands/implement.md
@@ -5,15 +5,48 @@ scripts:
   ps: scripts/powershell/check-prerequisites.ps1 -Json -RequireTasks -IncludeTasks
 ---
 
-The user input can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Outline
+
+1. Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").
 
-1. Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute.
+2. **Check checklists status** (if FEATURE_DIR/checklists/ exists):
+   - Scan all checklist files in the checklists/ directory
+   - For each checklist, count:
+     * Total items: All lines matching `- [ ]` or `- [X]` or `- [x]`
+     * Completed items: Lines matching `- [X]` or `- [x]`
+     * Incomplete items: Lines matching `- [ ]`
+   - Create a status table:
+     ```
+     | Checklist | Total | Completed | Incomplete | Status |
+     |-----------|-------|-----------|------------|--------|
+     | ux.md     | 12    | 12        | 0          | ✓ PASS |
+     | test.md   | 8     | 5         | 3          | ✗ FAIL |
+     | security.md | 6   | 6         | 0          | ✓ PASS |
+     ```
+   - Calculate overall status:
+     * **PASS**: All checklists have 0 incomplete items
+     * **FAIL**: One or more checklists have incomplete items
+   
+   - **If any checklist is incomplete**:
+     * Display the table with incomplete item counts
+     * **STOP** and ask: "Some checklists are incomplete. Do you want to proceed with implementation anyway? (yes/no)"
+     * Wait for user response before continuing
+     * If user says "no" or "wait" or "stop", halt execution
+     * If user says "yes" or "proceed" or "continue", proceed to step 3
+   
+   - **If all checklists are complete**:
+     * Display the table showing all checklists passed
+     * Automatically proceed to step 3
 
-2. Load and analyze the implementation context:
+3. Load and analyze the implementation context:
    - **REQUIRED**: Read tasks.md for the complete task list and execution plan
    - **REQUIRED**: Read plan.md for tech stack, architecture, and file structure
    - **IF EXISTS**: Read data-model.md for entities and relationships
@@ -21,27 +54,66 @@ $ARGUMENTS
    - **IF EXISTS**: Read research.md for technical decisions and constraints
    - **IF EXISTS**: Read quickstart.md for integration scenarios
 
-3. Parse tasks.md structure and extract:
+4. **Project Setup Verification**:
+   - **REQUIRED**: Create/verify ignore files based on actual project setup:
+   
+   **Detection & Creation Logic**:
+   - Check if the following command succeeds to determine if the repository is a git repo (create/verify .gitignore if so):
+
+     ```sh
+     git rev-parse --git-dir 2>/dev/null
+     ```
+   - Check if Dockerfile* exists or Docker in plan.md → create/verify .dockerignore
+   - Check if .eslintrc* or eslint.config.* exists → create/verify .eslintignore
+   - Check if .prettierrc* exists → create/verify .prettierignore
+   - Check if .npmrc or package.json exists → create/verify .npmignore (if publishing)
+   - Check if terraform files (*.tf) exist → create/verify .terraformignore
+   - Check if .helmignore needed (helm charts present) → create/verify .helmignore
+   
+   **If ignore file already exists**: Verify it contains essential patterns, append missing critical patterns only
+   **If ignore file missing**: Create with full pattern set for detected technology
+   
+   **Common Patterns by Technology** (from plan.md tech stack):
+   - **Node.js/JavaScript**: `node_modules/`, `dist/`, `build/`, `*.log`, `.env*`
+   - **Python**: `__pycache__/`, `*.pyc`, `.venv/`, `venv/`, `dist/`, `*.egg-info/`
+   - **Java**: `target/`, `*.class`, `*.jar`, `.gradle/`, `build/`
+   - **C#/.NET**: `bin/`, `obj/`, `*.user`, `*.suo`, `packages/`
+   - **Go**: `*.exe`, `*.test`, `vendor/`, `*.out`
+   - **Ruby**: `.bundle/`, `log/`, `tmp/`, `*.gem`, `vendor/bundle/`
+   - **PHP**: `vendor/`, `*.log`, `*.cache`, `*.env`
+   - **Rust**: `target/`, `debug/`, `release/`, `*.rs.bk`, `*.rlib`, `*.prof*`, `.idea/`, `*.log`, `.env*`
+   - **Kotlin**: `build/`, `out/`, `.gradle/`, `.idea/`, `*.class`, `*.jar`, `*.iml`, `*.log`, `.env*`
+   - **C++**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.so`, `*.a`, `*.exe`, `*.dll`, `.idea/`, `*.log`, `.env*`
+   - **C**: `build/`, `bin/`, `obj/`, `out/`, `*.o`, `*.a`, `*.so`, `*.exe`, `Makefile`, `config.log`, `.idea/`, `*.log`, `.env*`
+   - **Universal**: `.DS_Store`, `Thumbs.db`, `*.tmp`, `*.swp`, `.vscode/`, `.idea/`
+   
+   **Tool-Specific Patterns**:
+   - **Docker**: `node_modules/`, `.git/`, `Dockerfile*`, `.dockerignore`, `*.log*`, `.env*`, `coverage/`
+   - **ESLint**: `node_modules/`, `dist/`, `build/`, `coverage/`, `*.min.js`
+   - **Prettier**: `node_modules/`, `dist/`, `build/`, `coverage/`, `package-lock.json`, `yarn.lock`, `pnpm-lock.yaml`
+   - **Terraform**: `.terraform/`, `*.tfstate*`, `*.tfvars`, `.terraform.lock.hcl`
+
+5. Parse tasks.md structure and extract:
    - **Task phases**: Setup, Tests, Core, Integration, Polish
    - **Task dependencies**: Sequential vs parallel execution rules
    - **Task details**: ID, description, file paths, parallel markers [P]
    - **Execution flow**: Order and dependency requirements
 
-4. Execute implementation following the task plan:
+6. Execute implementation following the task plan:
    - **Phase-by-phase execution**: Complete each phase before moving to the next
    - **Respect dependencies**: Run sequential tasks in order, parallel tasks [P] can run together  
    - **Follow TDD approach**: Execute test tasks before their corresponding implementation tasks
    - **File-based coordination**: Tasks affecting the same files must run sequentially
    - **Validation checkpoints**: Verify each phase completion before proceeding
 
-5. Implementation execution rules:
+7. Implementation execution rules:
    - **Setup first**: Initialize project structure, dependencies, configuration
    - **Tests before code**: If you need to write tests for contracts, entities, and integration scenarios
    - **Core development**: Implement models, services, CLI commands, endpoints
    - **Integration work**: Database connections, middleware, logging, external services
    - **Polish and validation**: Unit tests, performance optimization, documentation
 
-6. Progress tracking and error handling:
+8. Progress tracking and error handling:
    - Report progress after each completed task
    - Halt execution if any non-parallel task fails
    - For parallel tasks [P], continue with successful tasks, report failed ones
@@ -49,11 +121,12 @@ $ARGUMENTS
    - Suggest next steps if implementation cannot proceed
    - **IMPORTANT** For completed tasks, make sure to mark the task off as [X] in the tasks file.
 
-7. Completion validation:
+9. Completion validation:
    - Verify all required tasks are completed
    - Check that implemented features match the original specification
    - Validate that tests pass and coverage meets requirements
    - Confirm the implementation follows the technical plan
    - Report final status with summary of completed work
 
-Note: This command assumes a complete task breakdown exists in tasks.md. If tasks are incomplete or missing, suggest running `/tasks` first to regenerate the task list.
\ No newline at end of file
+Note: This command assumes a complete task breakdown exists in tasks.md. If tasks are incomplete or missing, suggest running `/tasks` first to regenerate the task list.
+
diff --git a/templates/commands/plan.md b/templates/commands/plan.md
index 32522c2..2891e22 100644
--- a/templates/commands/plan.md
+++ b/templates/commands/plan.md
@@ -3,44 +3,85 @@ description: Execute the implementation planning workflow using the plan templat
 scripts:
   sh: scripts/bash/setup-plan.sh --json
   ps: scripts/powershell/setup-plan.ps1 -Json
+agent_scripts:
+  sh: scripts/bash/update-agent-context.sh __AGENT__
+  ps: scripts/powershell/update-agent-context.ps1 -AgentType __AGENT__
 ---
 
-The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Outline
+
+1. **Setup**: Run `{SCRIPT}` from repo root and parse JSON for FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, BRANCH. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").
+
+2. **Load context**: Read FEATURE_SPEC and `/memory/constitution.md`. Load IMPL_PLAN template (already copied).
+
+3. **Execute plan workflow**: Follow the structure in IMPL_PLAN template to:
+   - Fill Technical Context (mark unknowns as "NEEDS CLARIFICATION")
+   - Fill Constitution Check section from constitution
+   - Evaluate gates (ERROR if violations unjustified)
+   - Phase 0: Generate research.md (resolve all NEEDS CLARIFICATION)
+   - Phase 1: Generate data-model.md, contracts/, quickstart.md
+   - Phase 1: Update agent context by running the agent script
+   - Re-evaluate Constitution Check post-design
+
+4. **Stop and report**: Command ends after Phase 2 planning. Report branch, IMPL_PLAN path, and generated artifacts.
+
+## Phases
+
+### Phase 0: Outline & Research
+
+1. **Extract unknowns from Technical Context** above:
+   - For each NEEDS CLARIFICATION → research task
+   - For each dependency → best practices task
+   - For each integration → patterns task
+
+2. **Generate and dispatch research agents**:
+   ```
+   For each unknown in Technical Context:
+     Task: "Research {unknown} for {feature context}"
+   For each technology choice:
+     Task: "Find best practices for {tech} in {domain}"
+   ```
+
+3. **Consolidate findings** in `research.md` using format:
+   - Decision: [what was chosen]
+   - Rationale: [why chosen]
+   - Alternatives considered: [what else evaluated]
+
+**Output**: research.md with all NEEDS CLARIFICATION resolved
+
+### Phase 1: Design & Contracts
+
+**Prerequisites:** `research.md` complete
+
+1. **Extract entities from feature spec** → `data-model.md`:
+   - Entity name, fields, relationships
+   - Validation rules from requirements
+   - State transitions if applicable
+
+2. **Generate API contracts** from functional requirements:
+   - For each user action → endpoint
+   - Use standard REST/GraphQL patterns
+   - Output OpenAPI/GraphQL schema to `/contracts/`
+
+3. **Agent context update**:
+   - Run `{AGENT_SCRIPT}`
+   - These scripts detect which AI agent is in use
+   - Update the appropriate agent-specific context file
+   - Add only new technology from current plan
+   - Preserve manual additions between markers
+
+**Output**: data-model.md, /contracts/*, quickstart.md, agent-specific file
+
+## Key rules
+
+- Use absolute paths
+- ERROR on gate failures or unresolved clarifications
 
-Given the implementation details provided as an argument, do this:
-
-1. Run `{SCRIPT}` from the repo root and parse JSON for FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, BRANCH. All future file paths must be absolute.
-   - BEFORE proceeding, inspect FEATURE_SPEC for a `## Clarifications` section with at least one `Session` subheading. If missing or clearly ambiguous areas remain (vague adjectives, unresolved critical choices), PAUSE and instruct the user to run `/clarify` first to reduce rework. Only continue if: (a) Clarifications exist OR (b) an explicit user override is provided (e.g., "proceed without clarification"). Do not attempt to fabricate clarifications yourself.
-2. Read and analyze the feature specification to understand:
-   - The feature requirements and user stories
-   - Functional and non-functional requirements
-   - Success criteria and acceptance criteria
-   - Any technical constraints or dependencies mentioned
-
-3. Read the constitution at `/memory/constitution.md` to understand constitutional requirements.
-
-4. Execute the implementation plan template:
-   - Load `/templates/plan-template.md` (already copied to IMPL_PLAN path)
-   - Set Input path to FEATURE_SPEC
-   - Run the Execution Flow (main) function steps 1-9
-   - The template is self-contained and executable
-   - Follow error handling and gate checks as specified
-   - Let the template guide artifact generation in $SPECS_DIR:
-     * Phase 0 generates research.md
-     * Phase 1 generates data-model.md, contracts/, quickstart.md
-     * Phase 2 generates tasks.md
-   - Incorporate user-provided details from arguments into Technical Context: {ARGS}
-   - Update Progress Tracking as you complete each phase
-
-5. Verify execution completed:
-   - Check Progress Tracking shows all phases complete
-   - Ensure all required artifacts were generated
-   - Confirm no ERROR states in execution
-
-6. Report results with branch name, file paths, and generated artifacts.
-
-Use absolute paths with the repository root for all file operations to avoid path issues.
diff --git a/templates/commands/specify.md b/templates/commands/specify.md
index 652c86a..a75ad28 100644
--- a/templates/commands/specify.md
+++ b/templates/commands/specify.md
@@ -5,20 +5,229 @@ scripts:
   ps: scripts/powershell/create-new-feature.ps1 -Json "{ARGS}"
 ---
 
-The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
 
-The text the user typed after `/specify` in the triggering message **is** the feature description. Assume you always have it available in this conversation even if `{ARGS}` appears literally below. Do not ask the user to repeat it unless they provided an empty command.
+## Outline
+
+The text the user typed after `/speckit.specify` in the triggering message **is** the feature description. Assume you always have it available in this conversation even if `{ARGS}` appears literally below. Do not ask the user to repeat it unless they provided an empty command.
 
 Given that feature description, do this:
 
-1. Run the script `{SCRIPT}` from repo root and parse its JSON output for BRANCH_NAME and SPEC_FILE. All file paths must be absolute.
-  **IMPORTANT** You must only ever run this script once. The JSON is provided in the terminal as output - always refer to it to get the actual content you're looking for.
-2. Load `templates/spec-template.md` to understand required sections.
-3. Write the specification to SPEC_FILE using the template structure, replacing placeholders with concrete details derived from the feature description (arguments) while preserving section order and headings.
-4. Report completion with branch name, spec file path, and readiness for the next phase.
+1. **Generate a concise short name** (2-4 words) for the branch:
+   - Analyze the feature description and extract the most meaningful keywords
+   - Create a 2-4 word short name that captures the essence of the feature
+   - Use action-noun format when possible (e.g., "add-user-auth", "fix-payment-bug")
+   - Preserve technical terms and acronyms (OAuth2, API, JWT, etc.)
+   - Keep it concise but descriptive enough to understand the feature at a glance
+   - Examples:
+     - "I want to add user authentication" → "user-auth"
+     - "Implement OAuth2 integration for the API" → "oauth2-api-integration"
+     - "Create a dashboard for analytics" → "analytics-dashboard"
+     - "Fix payment processing timeout bug" → "fix-payment-timeout"
+
+2. Run the script `{SCRIPT}` from repo root **with the short-name argument** and parse its JSON output for BRANCH_NAME and SPEC_FILE. All file paths must be absolute.
+
+   **IMPORTANT**:
+
+   - Append the short-name argument to the `{SCRIPT}` command with the 2-4 word short name you created in step 1
+   - Bash: `--short-name "your-generated-short-name"`
+   - PowerShell: `-ShortName "your-generated-short-name"`
+   - For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot")
+   - You must only ever run this script once
+   - The JSON is provided in the terminal as output - always refer to it to get the actual content you're looking for
+
+3. Load `templates/spec-template.md` to understand required sections.
+
+4. Follow this execution flow:
+
+    1. Parse user description from Input
+       If empty: ERROR "No feature description provided"
+    2. Extract key concepts from description
+       Identify: actors, actions, data, constraints
+    3. For unclear aspects:
+       - Make informed guesses based on context and industry standards
+       - Only mark with [NEEDS CLARIFICATION: specific question] if:
+         - The choice significantly impacts feature scope or user experience
+         - Multiple reasonable interpretations exist with different implications
+         - No reasonable default exists
+       - **LIMIT: Maximum 3 [NEEDS CLARIFICATION] markers total**
+       - Prioritize clarifications by impact: scope > security/privacy > user experience > technical details
+    4. Fill User Scenarios & Testing section
+       If no clear user flow: ERROR "Cannot determine user scenarios"
+    5. Generate Functional Requirements
+       Each requirement must be testable
+       Use reasonable defaults for unspecified details (document assumptions in Assumptions section)
+    6. Define Success Criteria
+       Create measurable, technology-agnostic outcomes
+       Include both quantitative metrics (time, performance, volume) and qualitative measures (user satisfaction, task completion)
+       Each criterion must be verifiable without implementation details
+    7. Identify Key Entities (if data involved)
+    8. Return: SUCCESS (spec ready for planning)
+
+5. Write the specification to SPEC_FILE using the template structure, replacing placeholders with concrete details derived from the feature description (arguments) while preserving section order and headings.
+
+6. **Specification Quality Validation**: After writing the initial spec, validate it against quality criteria:
+
+   a. **Create Spec Quality Checklist**: Generate a checklist file at `FEATURE_DIR/checklists/requirements.md` using the checklist template structure with these validation items:
+   
+      ```markdown
+      # Specification Quality Checklist: [FEATURE NAME]
+      
+      **Purpose**: Validate specification completeness and quality before proceeding to planning
+      **Created**: [DATE]
+      **Feature**: [Link to spec.md]
+      
+      ## Content Quality
+      
+      - [ ] No implementation details (languages, frameworks, APIs)
+      - [ ] Focused on user value and business needs
+      - [ ] Written for non-technical stakeholders
+      - [ ] All mandatory sections completed
+      
+      ## Requirement Completeness
+      
+      - [ ] No [NEEDS CLARIFICATION] markers remain
+      - [ ] Requirements are testable and unambiguous
+      - [ ] Success criteria are measurable
+      - [ ] Success criteria are technology-agnostic (no implementation details)
+      - [ ] All acceptance scenarios are defined
+      - [ ] Edge cases are identified
+      - [ ] Scope is clearly bounded
+      - [ ] Dependencies and assumptions identified
+      
+      ## Feature Readiness
+      
+      - [ ] All functional requirements have clear acceptance criteria
+      - [ ] User scenarios cover primary flows
+      - [ ] Feature meets measurable outcomes defined in Success Criteria
+      - [ ] No implementation details leak into specification
+      
+      ## Notes
+      
+      - Items marked incomplete require spec updates before `/speckit.clarify` or `/speckit.plan`
+      ```
+   
+   b. **Run Validation Check**: Review the spec against each checklist item:
+      - For each item, determine if it passes or fails
+      - Document specific issues found (quote relevant spec sections)
+   
+   c. **Handle Validation Results**:
+      
+      - **If all items pass**: Mark checklist complete and proceed to step 6
+      
+      - **If items fail (excluding [NEEDS CLARIFICATION])**:
+        1. List the failing items and specific issues
+        2. Update the spec to address each issue
+        3. Re-run validation until all items pass (max 3 iterations)
+        4. If still failing after 3 iterations, document remaining issues in checklist notes and warn user
+      
+      - **If [NEEDS CLARIFICATION] markers remain**:
+        1. Extract all [NEEDS CLARIFICATION: ...] markers from the spec
+        2. **LIMIT CHECK**: If more than 3 markers exist, keep only the 3 most critical (by scope/security/UX impact) and make informed guesses for the rest
+        3. For each clarification needed (max 3), present options to user in this format:
+        
+           ```markdown
+           ## Question [N]: [Topic]
+           
+           **Context**: [Quote relevant spec section]
+           
+           **What we need to know**: [Specific question from NEEDS CLARIFICATION marker]
+           
+           **Suggested Answers**:
+           
+           | Option | Answer | Implications |
+           |--------|--------|--------------|
+           | A      | [First suggested answer] | [What this means for the feature] |
+           | B      | [Second suggested answer] | [What this means for the feature] |
+           | C      | [Third suggested answer] | [What this means for the feature] |
+           | Custom | Provide your own answer | [Explain how to provide custom input] |
+           
+           **Your choice**: _[Wait for user response]_
+           ```
+        
+        4. **CRITICAL - Table Formatting**: Ensure markdown tables are properly formatted:
+           - Use consistent spacing with pipes aligned
+           - Each cell should have spaces around content: `| Content |` not `|Content|`
+           - Header separator must have at least 3 dashes: `|--------|`
+           - Test that the table renders correctly in markdown preview
+        5. Number questions sequentially (Q1, Q2, Q3 - max 3 total)
+        6. Present all questions together before waiting for responses
+        7. Wait for user to respond with their choices for all questions (e.g., "Q1: A, Q2: Custom - [details], Q3: B")
+        8. Update the spec by replacing each [NEEDS CLARIFICATION] marker with the user's selected or provided answer
+        9. Re-run validation after all clarifications are resolved
+   
+   d. **Update Checklist**: After each validation iteration, update the checklist file with current pass/fail status
+
+7. Report completion with branch name, spec file path, checklist results, and readiness for the next phase (`/speckit.clarify` or `/speckit.plan`).
+
+**NOTE:** The script creates and checks out the new branch and initializes the spec file before writing.
+
+## General Guidelines
+
+## Quick Guidelines
+
+- Focus on **WHAT** users need and **WHY**.
+- Avoid HOW to implement (no tech stack, APIs, code structure).
+- Written for business stakeholders, not developers.
+- DO NOT create any checklists that are embedded in the spec. That will be a separate command.
+
+### Section Requirements
+
+- **Mandatory sections**: Must be completed for every feature
+- **Optional sections**: Include only when relevant to the feature
+- When a section doesn't apply, remove it entirely (don't leave as "N/A")
+
+### For AI Generation
+
+When creating this spec from a user prompt:
+
+1. **Make informed guesses**: Use context, industry standards, and common patterns to fill gaps
+2. **Document assumptions**: Record reasonable defaults in the Assumptions section
+3. **Limit clarifications**: Maximum 3 [NEEDS CLARIFICATION] markers - use only for critical decisions that:
+   - Significantly impact feature scope or user experience
+   - Have multiple reasonable interpretations with different implications
+   - Lack any reasonable default
+4. **Prioritize clarifications**: scope > security/privacy > user experience > technical details
+5. **Think like a tester**: Every vague requirement should fail the "testable and unambiguous" checklist item
+6. **Common areas needing clarification** (only if no reasonable default exists):
+   - Feature scope and boundaries (include/exclude specific use cases)
+   - User types and permissions (if multiple conflicting interpretations possible)
+   - Security/compliance requirements (when legally/financially significant)
+   
+**Examples of reasonable defaults** (don't ask about these):
+
+- Data retention: Industry-standard practices for the domain
+- Performance targets: Standard web/mobile app expectations unless specified
+- Error handling: User-friendly messages with appropriate fallbacks
+- Authentication method: Standard session-based or OAuth2 for web apps
+- Integration patterns: RESTful APIs unless specified otherwise
+
+### Success Criteria Guidelines
+
+Success criteria must be:
+
+1. **Measurable**: Include specific metrics (time, percentage, count, rate)
+2. **Technology-agnostic**: No mention of frameworks, languages, databases, or tools
+3. **User-focused**: Describe outcomes from user/business perspective, not system internals
+4. **Verifiable**: Can be tested/validated without knowing implementation details
+
+**Good examples**:
+
+- "Users can complete checkout in under 3 minutes"
+- "System supports 10,000 concurrent users"
+- "95% of searches return results in under 1 second"
+- "Task completion rate improves by 40%"
+
+**Bad examples** (implementation-focused):
+
+- "API response time is under 200ms" (too technical, use "Users see results instantly")
+- "Database can handle 1000 TPS" (implementation detail, use user-facing metric)
+- "React components render efficiently" (framework-specific)
+- "Redis cache hit rate above 80%" (technology-specific)
 
-Note: The script creates and checks out the new branch and initializes the spec file before writing.
diff --git a/templates/commands/tasks.md b/templates/commands/tasks.md
index eb0ef2b..9646400 100644
--- a/templates/commands/tasks.md
+++ b/templates/commands/tasks.md
@@ -5,61 +5,129 @@ scripts:
   ps: scripts/powershell/check-prerequisites.ps1 -Json
 ---
 
-The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-
-User input:
+## User Input
 
+```text
 $ARGUMENTS
+```
+
+You **MUST** consider the user input before proceeding (if not empty).
+
+## Outline
+
+1. **Setup**: Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute. For single quotes in args like "I'm Groot", use escape syntax: e.g 'I'\''m Groot' (or double-quote if possible: "I'm Groot").
+
+2. **Load design documents**: Read from FEATURE_DIR:
+   - **Required**: plan.md (tech stack, libraries, structure), spec.md (user stories with priorities)
+   - **Optional**: data-model.md (entities), contracts/ (API endpoints), research.md (decisions), quickstart.md (test scenarios)
+   - Note: Not all projects have all documents. Generate tasks based on what's available.
+
+3. **Execute task generation workflow**:
+   - Load plan.md and extract tech stack, libraries, project structure
+   - Load spec.md and extract user stories with their priorities (P1, P2, P3, etc.)
+   - If data-model.md exists: Extract entities and map to user stories
+   - If contracts/ exists: Map endpoints to user stories
+   - If research.md exists: Extract decisions for setup tasks
+   - Generate tasks organized by user story (see Task Generation Rules below)
+   - Generate dependency graph showing user story completion order
+   - Create parallel execution examples per user story
+   - Validate task completeness (each user story has all needed tasks, independently testable)
 
-1. Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute.
-2. Load and analyze available design documents:
-   - Always read plan.md for tech stack and libraries
-   - IF EXISTS: Read data-model.md for entities
-   - IF EXISTS: Read contracts/ for API endpoints
-   - IF EXISTS: Read research.md for technical decisions
-   - IF EXISTS: Read quickstart.md for test scenarios
-
-   Note: Not all projects have all documents. For example:
-   - CLI tools might not have contracts/
-   - Simple libraries might not need data-model.md
-   - Generate tasks based on what's available
-
-3. Generate tasks following the template:
-   - Use `/templates/tasks-template.md` as the base
-   - Replace example tasks with actual tasks based on:
-     * **Setup tasks**: Project init, dependencies, linting
-     * **Test tasks [P]**: One per contract, one per integration scenario
-     * **Core tasks**: One per entity, service, CLI command, endpoint
-     * **Integration tasks**: DB connections, middleware, logging
-     * **Polish tasks [P]**: Unit tests, performance, docs
-
-4. Task generation rules:
-   - Each contract file → contract test task marked [P]
-   - Each entity in data-model → model creation task marked [P]
-   - Each endpoint → implementation task (not parallel if shared files)
-   - Each user story → integration test marked [P]
-   - Different files = can be parallel [P]
-   - Same file = sequential (no [P])
-
-5. Order tasks by dependencies:
-   - Setup before everything
-   - Tests before implementation (TDD)
-   - Models before services
-   - Services before endpoints
-   - Core before integration
-   - Everything before polish
-
-6. Include parallel execution examples:
-   - Group [P] tasks that can run together
-   - Show actual Task agent commands
-
-7. Create FEATURE_DIR/tasks.md with:
-   - Correct feature name from implementation plan
-   - Numbered tasks (T001, T002, etc.)
+4. **Generate tasks.md**: Use `.specify/templates/tasks-template.md` as structure, fill with:
+   - Correct feature name from plan.md
+   - Phase 1: Setup tasks (project initialization)
+   - Phase 2: Foundational tasks (blocking prerequisites for all user stories)
+   - Phase 3+: One phase per user story (in priority order from spec.md)
+   - Each phase includes: story goal, independent test criteria, tests (if requested), implementation tasks
+   - Final Phase: Polish & cross-cutting concerns
+   - All tasks must follow the strict checklist format (see Task Generation Rules below)
    - Clear file paths for each task
-   - Dependency notes
-   - Parallel execution guidance
+   - Dependencies section showing story completion order
+   - Parallel execution examples per story
+   - Implementation strategy section (MVP first, incremental delivery)
+
+5. **Report**: Output path to generated tasks.md and summary:
+   - Total task count
+   - Task count per user story
+   - Parallel opportunities identified
+   - Independent test criteria for each story
+   - Suggested MVP scope (typically just User Story 1)
+   - Format validation: Confirm ALL tasks follow the checklist format (checkbox, ID, labels, file paths)
 
 Context for task generation: {ARGS}
 
 The tasks.md should be immediately executable - each task must be specific enough that an LLM can complete it without additional context.
+
+## Task Generation Rules
+
+**CRITICAL**: Tasks MUST be organized by user story to enable independent implementation and testing.
+
+**Tests are OPTIONAL**: Only generate test tasks if explicitly requested in the feature specification or if user requests TDD approach.
+
+### Checklist Format (REQUIRED)
+
+Every task MUST strictly follow this format:
+
+```text
+- [ ] [TaskID] [P?] [Story?] Description with file path
+```
+
+**Format Components**:
+
+1. **Checkbox**: ALWAYS start with `- [ ]` (markdown checkbox)
+2. **Task ID**: Sequential number (T001, T002, T003...) in execution order
+3. **[P] marker**: Include ONLY if task is parallelizable (different files, no dependencies on incomplete tasks)
+4. **[Story] label**: REQUIRED for user story phase tasks only
+   - Format: [US1], [US2], [US3], etc. (maps to user stories from spec.md)
+   - Setup phase: NO story label
+   - Foundational phase: NO story label  
+   - User Story phases: MUST have story label
+   - Polish phase: NO story label
+5. **Description**: Clear action with exact file path
+
+**Examples**:
+
+- ✅ CORRECT: `- [ ] T001 Create project structure per implementation plan`
+- ✅ CORRECT: `- [ ] T005 [P] Implement authentication middleware in src/middleware/auth.py`
+- ✅ CORRECT: `- [ ] T012 [P] [US1] Create User model in src/models/user.py`
+- ✅ CORRECT: `- [ ] T014 [US1] Implement UserService in src/services/user_service.py`
+- ❌ WRONG: `- [ ] Create User model` (missing ID and Story label)
+- ❌ WRONG: `T001 [US1] Create model` (missing checkbox)
+- ❌ WRONG: `- [ ] [US1] Create User model` (missing Task ID)
+- ❌ WRONG: `- [ ] T001 [US1] Create model` (missing file path)
+
+### Task Organization
+
+1. **From User Stories (spec.md)** - PRIMARY ORGANIZATION:
+   - Each user story (P1, P2, P3...) gets its own phase
+   - Map all related components to their story:
+     - Models needed for that story
+     - Services needed for that story
+     - Endpoints/UI needed for that story
+     - If tests requested: Tests specific to that story
+   - Mark story dependencies (most stories should be independent)
+   
+2. **From Contracts**:
+   - Map each contract/endpoint → to the user story it serves
+   - If tests requested: Each contract → contract test task [P] before implementation in that story's phase
+   
+3. **From Data Model**:
+   - Map each entity to the user story(ies) that need it
+   - If entity serves multiple stories: Put in earliest story or Setup phase
+   - Relationships → service layer tasks in appropriate story phase
+   
+4. **From Setup/Infrastructure**:
+   - Shared infrastructure → Setup phase (Phase 1)
+   - Foundational/blocking tasks → Foundational phase (Phase 2)
+   - Story-specific setup → within that story's phase
+
+### Phase Structure
+
+- **Phase 1**: Setup (project initialization)
+- **Phase 2**: Foundational (blocking prerequisites - MUST complete before user stories)
+- **Phase 3+**: User Stories in priority order (P1, P2, P3...)
+  - Within each story: Tests (if requested) → Models → Services → Endpoints → Integration
+  - Each phase should be a complete, independently testable increment
+- **Final Phase**: Polish & Cross-Cutting Concerns
+
+
diff --git a/templates/plan-template.md b/templates/plan-template.md
index e812b41..43460c3 100644
--- a/templates/plan-template.md
+++ b/templates/plan-template.md
@@ -1,45 +1,22 @@
----
-description: "Implementation plan template for feature development"
-scripts:
-  sh: scripts/bash/update-agent-context.sh __AGENT__
-  ps: scripts/powershell/update-agent-context.ps1 -AgentType __AGENT__
----
-
 # Implementation Plan: [FEATURE]
 
 **Branch**: `[###-feature-name]` | **Date**: [DATE] | **Spec**: [link]
 **Input**: Feature specification from `/specs/[###-feature-name]/spec.md`
 
-## Execution Flow (/plan command scope)
-```
-1. Load feature spec from Input path
-   → If not found: ERROR "No feature spec at {path}"
-2. Fill Technical Context (scan for NEEDS CLARIFICATION)
-   → Detect Project Type from context (web=frontend+backend, mobile=app+api)
-   → Set Structure Decision based on project type
-3. Fill the Constitution Check section based on the content of the constitution document.
-4. Evaluate Constitution Check section below
-   → If violations exist: Document in Complexity Tracking
-   → If no justification possible: ERROR "Simplify approach first"
-   → Update Progress Tracking: Initial Constitution Check
-5. Execute Phase 0 → research.md
-   → If NEEDS CLARIFICATION remain: ERROR "Resolve unknowns"
-6. Execute Phase 1 → contracts, data-model.md, quickstart.md, agent-specific template file (e.g., `CLAUDE.md` for Claude Code, `.github/copilot-instructions.md` for GitHub Copilot, `GEMINI.md` for Gemini CLI, `QWEN.md` for Qwen Code or `AGENTS.md` for opencode).
-7. Re-evaluate Constitution Check section
-   → If new violations: Refactor design, return to Phase 1
-   → Update Progress Tracking: Post-Design Constitution Check
-8. Plan Phase 2 → Describe task generation approach (DO NOT create tasks.md)
-9. STOP - Ready for /tasks command
-```
-
-**IMPORTANT**: The /plan command STOPS at step 7. Phases 2-4 are executed by other commands:
-- Phase 2: /tasks command creates tasks.md
-- Phase 3-4: Implementation execution (manual or via tools)
+**Note**: This template is filled in by the `/speckit.plan` command. See `.specify/templates/commands/plan.md` for the execution workflow.
 
 ## Summary
+
 [Extract from feature spec: primary requirement + technical approach from research]
 
 ## Technical Context
+
+<!--
+  ACTION REQUIRED: Replace the content in this section with the technical details
+  for the project. The structure here is presented in advisory capacity to guide
+  the iteration process.
+-->
+
 **Language/Version**: [e.g., Python 3.11, Swift 5.9, Rust 1.75 or NEEDS CLARIFICATION]  
 **Primary Dependencies**: [e.g., FastAPI, UIKit, LLVM or NEEDS CLARIFICATION]  
 **Storage**: [if applicable, e.g., PostgreSQL, CoreData, files or N/A]  
@@ -51,6 +28,7 @@ scripts:
 **Scale/Scope**: [domain-specific, e.g., 10k users, 1M LOC, 50 screens or NEEDS CLARIFICATION]
 
 ## Constitution Check
+
 *GATE: Must pass before Phase 0 research. Re-check after Phase 1 design.*
 
 [Gates determined based on constitution file]
@@ -58,19 +36,27 @@ scripts:
 ## Project Structure
 
 ### Documentation (this feature)
+
 ```
 specs/[###-feature]/
-├── plan.md              # This file (/plan command output)
-├── research.md          # Phase 0 output (/plan command)
-├── data-model.md        # Phase 1 output (/plan command)
-├── quickstart.md        # Phase 1 output (/plan command)
-├── contracts/           # Phase 1 output (/plan command)
-└── tasks.md             # Phase 2 output (/tasks command - NOT created by /plan)
+├── plan.md              # This file (/speckit.plan command output)
+├── research.md          # Phase 0 output (/speckit.plan command)
+├── data-model.md        # Phase 1 output (/speckit.plan command)
+├── quickstart.md        # Phase 1 output (/speckit.plan command)
+├── contracts/           # Phase 1 output (/speckit.plan command)
+└── tasks.md             # Phase 2 output (/speckit.tasks command - NOT created by /speckit.plan)
 ```
 
 ### Source Code (repository root)
+<!--
+  ACTION REQUIRED: Replace the placeholder tree below with the concrete layout
+  for this feature. Delete unused options and expand the chosen structure with
+  real paths (e.g., apps/admin, packages/something). The delivered plan must
+  not include Option labels.
+-->
+
 ```
-# Option 1: Single project (DEFAULT)
+# [REMOVE IF UNUSED] Option 1: Single project (DEFAULT)
 src/
 ├── models/
 ├── services/
@@ -82,7 +68,7 @@ tests/
 ├── integration/
 └── unit/
 
-# Option 2: Web application (when "frontend" + "backend" detected)
+# [REMOVE IF UNUSED] Option 2: Web application (when "frontend" + "backend" detected)
 backend/
 ├── src/
 │   ├── models/
@@ -97,98 +83,19 @@ frontend/
 │   └── services/
 └── tests/
 
-# Option 3: Mobile + API (when "iOS/Android" detected)
+# [REMOVE IF UNUSED] Option 3: Mobile + API (when "iOS/Android" detected)
 api/
 └── [same as backend above]
 
 ios/ or android/
-└── [platform-specific structure]
+└── [platform-specific structure: feature modules, UI flows, platform tests]
 ```
 
-**Structure Decision**: [DEFAULT to Option 1 unless Technical Context indicates web/mobile app]
-
-## Phase 0: Outline & Research
-1. **Extract unknowns from Technical Context** above:
-   - For each NEEDS CLARIFICATION → research task
-   - For each dependency → best practices task
-   - For each integration → patterns task
-
-2. **Generate and dispatch research agents**:
-   ```
-   For each unknown in Technical Context:
-     Task: "Research {unknown} for {feature context}"
-   For each technology choice:
-     Task: "Find best practices for {tech} in {domain}"
-   ```
-
-3. **Consolidate findings** in `research.md` using format:
-   - Decision: [what was chosen]
-   - Rationale: [why chosen]
-   - Alternatives considered: [what else evaluated]
-
-**Output**: research.md with all NEEDS CLARIFICATION resolved
-
-## Phase 1: Design & Contracts
-*Prerequisites: research.md complete*
-
-1. **Extract entities from feature spec** → `data-model.md`:
-   - Entity name, fields, relationships
-   - Validation rules from requirements
-   - State transitions if applicable
-
-2. **Generate API contracts** from functional requirements:
-   - For each user action → endpoint
-   - Use standard REST/GraphQL patterns
-   - Output OpenAPI/GraphQL schema to `/contracts/`
-
-3. **Generate contract tests** from contracts:
-   - One test file per endpoint
-   - Assert request/response schemas
-   - Tests must fail (no implementation yet)
-
-4. **Extract test scenarios** from user stories:
-   - Each story → integration test scenario
-   - Quickstart test = story validation steps
-
-5. **Update agent file incrementally** (O(1) operation):
-   - Run `{SCRIPT}`
-     **IMPORTANT**: Execute it exactly as specified above. Do not add or remove any arguments.
-   - If exists: Add only NEW tech from current plan
-   - Preserve manual additions between markers
-   - Update recent changes (keep last 3)
-   - Keep under 150 lines for token efficiency
-   - Output to repository root
-
-**Output**: data-model.md, /contracts/*, failing tests, quickstart.md, agent-specific file
-
-## Phase 2: Task Planning Approach
-*This section describes what the /tasks command will do - DO NOT execute during /plan*
-
-**Task Generation Strategy**:
-- Load `.specify/templates/tasks-template.md` as base
-- Generate tasks from Phase 1 design docs (contracts, data model, quickstart)
-- Each contract → contract test task [P]
-- Each entity → model creation task [P] 
-- Each user story → integration test task
-- Implementation tasks to make tests pass
-
-**Ordering Strategy**:
-- TDD order: Tests before implementation 
-- Dependency order: Models before services before UI
-- Mark [P] for parallel execution (independent files)
-
-**Estimated Output**: 25-30 numbered, ordered tasks in tasks.md
-
-**IMPORTANT**: This phase is executed by the /tasks command, NOT by /plan
-
-## Phase 3+: Future Implementation
-*These phases are beyond the scope of the /plan command*
-
-**Phase 3**: Task execution (/tasks command creates tasks.md)  
-**Phase 4**: Implementation (execute tasks.md following constitutional principles)  
-**Phase 5**: Validation (run tests, execute quickstart.md, performance validation)
+**Structure Decision**: [Document the selected structure and reference the real
+directories captured above]
 
 ## Complexity Tracking
+
 *Fill ONLY if Constitution Check has violations that must be justified*
 
 | Violation | Why Needed | Simpler Alternative Rejected Because |
@@ -196,23 +103,3 @@ ios/ or android/
 | [e.g., 4th project] | [current need] | [why 3 projects insufficient] |
 | [e.g., Repository pattern] | [specific problem] | [why direct DB access insufficient] |
 
-
-## Progress Tracking
-*This checklist is updated during execution flow*
-
-**Phase Status**:
-- [ ] Phase 0: Research complete (/plan command)
-- [ ] Phase 1: Design complete (/plan command)
-- [ ] Phase 2: Task planning complete (/plan command - describe approach only)
-- [ ] Phase 3: Tasks generated (/tasks command)
-- [ ] Phase 4: Implementation complete
-- [ ] Phase 5: Validation passed
-
-**Gate Status**:
-- [ ] Initial Constitution Check: PASS
-- [ ] Post-Design Constitution Check: PASS
-- [ ] All NEEDS CLARIFICATION resolved
-- [ ] Complexity deviations documented
-
----
-*Based on Constitution v2.1.1 - See `/memory/constitution.md`*
diff --git a/templates/spec-template.md b/templates/spec-template.md
index 7915e7d..9a83ac6 100644
--- a/templates/spec-template.md
+++ b/templates/spec-template.md
@@ -5,69 +5,85 @@
 **Status**: Draft  
 **Input**: User description: "$ARGUMENTS"
 
-## Execution Flow (main)
-```
-1. Parse user description from Input
-   → If empty: ERROR "No feature description provided"
-2. Extract key concepts from description
-   → Identify: actors, actions, data, constraints
-3. For each unclear aspect:
-   → Mark with [NEEDS CLARIFICATION: specific question]
-4. Fill User Scenarios & Testing section
-   → If no clear user flow: ERROR "Cannot determine user scenarios"
-5. Generate Functional Requirements
-   → Each requirement must be testable
-   → Mark ambiguous requirements
-6. Identify Key Entities (if data involved)
-7. Run Review Checklist
-   → If any [NEEDS CLARIFICATION]: WARN "Spec has uncertainties"
-   → If implementation details found: ERROR "Remove tech details"
-8. Return: SUCCESS (spec ready for planning)
-```
+## User Scenarios & Testing *(mandatory)*
+
+<!--
+  IMPORTANT: User stories should be PRIORITIZED as user journeys ordered by importance.
+  Each user story/journey must be INDEPENDENTLY TESTABLE - meaning if you implement just ONE of them,
+  you should still have a viable MVP (Minimum Viable Product) that delivers value.
+  
+  Assign priorities (P1, P2, P3, etc.) to each story, where P1 is the most critical.
+  Think of each story as a standalone slice of functionality that can be:
+  - Developed independently
+  - Tested independently
+  - Deployed independently
+  - Demonstrated to users independently
+-->
+
+### User Story 1 - [Brief Title] (Priority: P1)
+
+[Describe this user journey in plain language]
+
+**Why this priority**: [Explain the value and why it has this priority level]
+
+**Independent Test**: [Describe how this can be tested independently - e.g., "Can be fully tested by [specific action] and delivers [specific value]"]
+
+**Acceptance Scenarios**:
+
+1. **Given** [initial state], **When** [action], **Then** [expected outcome]
+2. **Given** [initial state], **When** [action], **Then** [expected outcome]
 
 ---
 
-## ⚡ Quick Guidelines
-- ✅ Focus on WHAT users need and WHY
-- ❌ Avoid HOW to implement (no tech stack, APIs, code structure)
-- 👥 Written for business stakeholders, not developers
-
-### Section Requirements
-- **Mandatory sections**: Must be completed for every feature
-- **Optional sections**: Include only when relevant to the feature
-- When a section doesn't apply, remove it entirely (don't leave as "N/A")
-
-### For AI Generation
-When creating this spec from a user prompt:
-1. **Mark all ambiguities**: Use [NEEDS CLARIFICATION: specific question] for any assumption you'd need to make
-2. **Don't guess**: If the prompt doesn't specify something (e.g., "login system" without auth method), mark it
-3. **Think like a tester**: Every vague requirement should fail the "testable and unambiguous" checklist item
-4. **Common underspecified areas**:
-   - User types and permissions
-   - Data retention/deletion policies  
-   - Performance targets and scale
-   - Error handling behaviors
-   - Integration requirements
-   - Security/compliance needs
+### User Story 2 - [Brief Title] (Priority: P2)
+
+[Describe this user journey in plain language]
+
+**Why this priority**: [Explain the value and why it has this priority level]
+
+**Independent Test**: [Describe how this can be tested independently]
+
+**Acceptance Scenarios**:
+
+1. **Given** [initial state], **When** [action], **Then** [expected outcome]
 
 ---
 
-## User Scenarios & Testing *(mandatory)*
+### User Story 3 - [Brief Title] (Priority: P3)
+
+[Describe this user journey in plain language]
 
-### Primary User Story
-[Describe the main user journey in plain language]
+**Why this priority**: [Explain the value and why it has this priority level]
+
+**Independent Test**: [Describe how this can be tested independently]
+
+**Acceptance Scenarios**:
 
-### Acceptance Scenarios
 1. **Given** [initial state], **When** [action], **Then** [expected outcome]
-2. **Given** [initial state], **When** [action], **Then** [expected outcome]
+
+---
+
+[Add more user stories as needed, each with an assigned priority]
 
 ### Edge Cases
+
+<!--
+  ACTION REQUIRED: The content in this section represents placeholders.
+  Fill them out with the right edge cases.
+-->
+
 - What happens when [boundary condition]?
 - How does system handle [error scenario]?
 
 ## Requirements *(mandatory)*
 
+<!--
+  ACTION REQUIRED: The content in this section represents placeholders.
+  Fill them out with the right functional requirements.
+-->
+
 ### Functional Requirements
+
 - **FR-001**: System MUST [specific capability, e.g., "allow users to create accounts"]
 - **FR-002**: System MUST [specific capability, e.g., "validate email addresses"]  
 - **FR-003**: Users MUST be able to [key interaction, e.g., "reset their password"]
@@ -75,42 +91,26 @@ When creating this spec from a user prompt:
 - **FR-005**: System MUST [behavior, e.g., "log all security events"]
 
 *Example of marking unclear requirements:*
+
 - **FR-006**: System MUST authenticate users via [NEEDS CLARIFICATION: auth method not specified - email/password, SSO, OAuth?]
 - **FR-007**: System MUST retain user data for [NEEDS CLARIFICATION: retention period not specified]
 
 ### Key Entities *(include if feature involves data)*
+
 - **[Entity 1]**: [What it represents, key attributes without implementation]
 - **[Entity 2]**: [What it represents, relationships to other entities]
 
----
+## Success Criteria *(mandatory)*
 
-## Review & Acceptance Checklist
-*GATE: Automated checks run during main() execution*
+<!--
+  ACTION REQUIRED: Define measurable success criteria.
+  These must be technology-agnostic and measurable.
+-->
 
-### Content Quality
-- [ ] No implementation details (languages, frameworks, APIs)
-- [ ] Focused on user value and business needs
-- [ ] Written for non-technical stakeholders
-- [ ] All mandatory sections completed
+### Measurable Outcomes
 
-### Requirement Completeness
-- [ ] No [NEEDS CLARIFICATION] markers remain
-- [ ] Requirements are testable and unambiguous  
-- [ ] Success criteria are measurable
-- [ ] Scope is clearly bounded
-- [ ] Dependencies and assumptions identified
+- **SC-001**: [Measurable metric, e.g., "Users can complete account creation in under 2 minutes"]
+- **SC-002**: [Measurable metric, e.g., "System handles 1000 concurrent users without degradation"]
+- **SC-003**: [User satisfaction metric, e.g., "90% of users successfully complete primary task on first attempt"]
+- **SC-004**: [Business metric, e.g., "Reduce support tickets related to [X] by 50%"]
 
----
-
-## Execution Status
-*Updated by main() during processing*
-
-- [ ] User description parsed
-- [ ] Key concepts extracted
-- [ ] Ambiguities marked
-- [ ] User scenarios defined
-- [ ] Requirements generated
-- [ ] Entities identified
-- [ ] Review checklist passed
-
----
diff --git a/templates/tasks-template.md b/templates/tasks-template.md
index b8a28fa..eea131f 100644
--- a/templates/tasks-template.md
+++ b/templates/tasks-template.md
@@ -1,39 +1,19 @@
+---
+description: "Task list template for feature implementation"
+---
+
 # Tasks: [FEATURE NAME]
 
 **Input**: Design documents from `/specs/[###-feature-name]/`
-**Prerequisites**: plan.md (required), research.md, data-model.md, contracts/
+**Prerequisites**: plan.md (required), spec.md (required for user stories), research.md, data-model.md, contracts/
 
-## Execution Flow (main)
-```
-1. Load plan.md from feature directory
-   → If not found: ERROR "No implementation plan found"
-   → Extract: tech stack, libraries, structure
-2. Load optional design documents:
-   → data-model.md: Extract entities → model tasks
-   → contracts/: Each file → contract test task
-   → research.md: Extract decisions → setup tasks
-3. Generate tasks by category:
-   → Setup: project init, dependencies, linting
-   → Tests: contract tests, integration tests
-   → Core: models, services, CLI commands
-   → Integration: DB, middleware, logging
-   → Polish: unit tests, performance, docs
-4. Apply task rules:
-   → Different files = mark [P] for parallel
-   → Same file = sequential (no [P])
-   → Tests before implementation (TDD)
-5. Number tasks sequentially (T001, T002...)
-6. Generate dependency graph
-7. Create parallel execution examples
-8. Validate task completeness:
-   → All contracts have tests?
-   → All entities have models?
-   → All endpoints implemented?
-9. Return: SUCCESS (tasks ready for execution)
-```
+**Tests**: The examples below include test tasks. Tests are OPTIONAL - only include them if explicitly requested in the feature specification.
 
-## Format: `[ID] [P?] Description`
+**Organization**: Tasks are grouped by user story to enable independent implementation and testing of each story.
+
+## Format: `[ID] [P?] [Story] Description`
 - **[P]**: Can run in parallel (different files, no dependencies)
+- **[Story]**: Which user story this task belongs to (e.g., US1, US2, US3)
 - Include exact file paths in descriptions
 
 ## Path Conventions
@@ -42,86 +22,230 @@
 - **Mobile**: `api/src/`, `ios/src/` or `android/src/`
 - Paths shown below assume single project - adjust based on plan.md structure
 
-## Phase 3.1: Setup
+<!-- 
+  ============================================================================
+  IMPORTANT: The tasks below are SAMPLE TASKS for illustration purposes only.
+  
+  The /speckit.tasks command MUST replace these with actual tasks based on:
+  - User stories from spec.md (with their priorities P1, P2, P3...)
+  - Feature requirements from plan.md
+  - Entities from data-model.md
+  - Endpoints from contracts/
+  
+  Tasks MUST be organized by user story so each story can be:
+  - Implemented independently
+  - Tested independently
+  - Delivered as an MVP increment
+  
+  DO NOT keep these sample tasks in the generated tasks.md file.
+  ============================================================================
+-->
+
+## Phase 1: Setup (Shared Infrastructure)
+
+**Purpose**: Project initialization and basic structure
+
 - [ ] T001 Create project structure per implementation plan
 - [ ] T002 Initialize [language] project with [framework] dependencies
 - [ ] T003 [P] Configure linting and formatting tools
 
-## Phase 3.2: Tests First (TDD) ⚠️ MUST COMPLETE BEFORE 3.3
-**CRITICAL: These tests MUST be written and MUST FAIL before ANY implementation**
-- [ ] T004 [P] Contract test POST /api/users in tests/contract/test_users_post.py
-- [ ] T005 [P] Contract test GET /api/users/{id} in tests/contract/test_users_get.py
-- [ ] T006 [P] Integration test user registration in tests/integration/test_registration.py
-- [ ] T007 [P] Integration test auth flow in tests/integration/test_auth.py
-
-## Phase 3.3: Core Implementation (ONLY after tests are failing)
-- [ ] T008 [P] User model in src/models/user.py
-- [ ] T009 [P] UserService CRUD in src/services/user_service.py
-- [ ] T010 [P] CLI --create-user in src/cli/user_commands.py
-- [ ] T011 POST /api/users endpoint
-- [ ] T012 GET /api/users/{id} endpoint
-- [ ] T013 Input validation
-- [ ] T014 Error handling and logging
-
-## Phase 3.4: Integration
-- [ ] T015 Connect UserService to DB
-- [ ] T016 Auth middleware
-- [ ] T017 Request/response logging
-- [ ] T018 CORS and security headers
-
-## Phase 3.5: Polish
-- [ ] T019 [P] Unit tests for validation in tests/unit/test_validation.py
-- [ ] T020 Performance tests (<200ms)
-- [ ] T021 [P] Update docs/api.md
-- [ ] T022 Remove duplication
-- [ ] T023 Run manual-testing.md
-
-## Dependencies
-- Tests (T004-T007) before implementation (T008-T014)
-- T008 blocks T009, T015
-- T016 blocks T018
-- Implementation before polish (T019-T023)
-
-## Parallel Example
-```
-# Launch T004-T007 together:
-Task: "Contract test POST /api/users in tests/contract/test_users_post.py"
-Task: "Contract test GET /api/users/{id} in tests/contract/test_users_get.py"
-Task: "Integration test registration in tests/integration/test_registration.py"
-Task: "Integration test auth in tests/integration/test_auth.py"
+---
+
+## Phase 2: Foundational (Blocking Prerequisites)
+
+**Purpose**: Core infrastructure that MUST be complete before ANY user story can be implemented
+
+**⚠️ CRITICAL**: No user story work can begin until this phase is complete
+
+Examples of foundational tasks (adjust based on your project):
+
+- [ ] T004 Setup database schema and migrations framework
+- [ ] T005 [P] Implement authentication/authorization framework
+- [ ] T006 [P] Setup API routing and middleware structure
+- [ ] T007 Create base models/entities that all stories depend on
+- [ ] T008 Configure error handling and logging infrastructure
+- [ ] T009 Setup environment configuration management
+
+**Checkpoint**: Foundation ready - user story implementation can now begin in parallel
+
+---
+
+## Phase 3: User Story 1 - [Title] (Priority: P1) 🎯 MVP
+
+**Goal**: [Brief description of what this story delivers]
+
+**Independent Test**: [How to verify this story works on its own]
+
+### Tests for User Story 1 (OPTIONAL - only if tests requested) ⚠️
+
+**NOTE: Write these tests FIRST, ensure they FAIL before implementation**
+
+- [ ] T010 [P] [US1] Contract test for [endpoint] in tests/contract/test_[name].py
+- [ ] T011 [P] [US1] Integration test for [user journey] in tests/integration/test_[name].py
+
+### Implementation for User Story 1
+
+- [ ] T012 [P] [US1] Create [Entity1] model in src/models/[entity1].py
+- [ ] T013 [P] [US1] Create [Entity2] model in src/models/[entity2].py
+- [ ] T014 [US1] Implement [Service] in src/services/[service].py (depends on T012, T013)
+- [ ] T015 [US1] Implement [endpoint/feature] in src/[location]/[file].py
+- [ ] T016 [US1] Add validation and error handling
+- [ ] T017 [US1] Add logging for user story 1 operations
+
+**Checkpoint**: At this point, User Story 1 should be fully functional and testable independently
+
+---
+
+## Phase 4: User Story 2 - [Title] (Priority: P2)
+
+**Goal**: [Brief description of what this story delivers]
+
+**Independent Test**: [How to verify this story works on its own]
+
+### Tests for User Story 2 (OPTIONAL - only if tests requested) ⚠️
+
+- [ ] T018 [P] [US2] Contract test for [endpoint] in tests/contract/test_[name].py
+- [ ] T019 [P] [US2] Integration test for [user journey] in tests/integration/test_[name].py
+
+### Implementation for User Story 2
+
+- [ ] T020 [P] [US2] Create [Entity] model in src/models/[entity].py
+- [ ] T021 [US2] Implement [Service] in src/services/[service].py
+- [ ] T022 [US2] Implement [endpoint/feature] in src/[location]/[file].py
+- [ ] T023 [US2] Integrate with User Story 1 components (if needed)
+
+**Checkpoint**: At this point, User Stories 1 AND 2 should both work independently
+
+---
+
+## Phase 5: User Story 3 - [Title] (Priority: P3)
+
+**Goal**: [Brief description of what this story delivers]
+
+**Independent Test**: [How to verify this story works on its own]
+
+### Tests for User Story 3 (OPTIONAL - only if tests requested) ⚠️
+
+- [ ] T024 [P] [US3] Contract test for [endpoint] in tests/contract/test_[name].py
+- [ ] T025 [P] [US3] Integration test for [user journey] in tests/integration/test_[name].py
+
+### Implementation for User Story 3
+
+- [ ] T026 [P] [US3] Create [Entity] model in src/models/[entity].py
+- [ ] T027 [US3] Implement [Service] in src/services/[service].py
+- [ ] T028 [US3] Implement [endpoint/feature] in src/[location]/[file].py
+
+**Checkpoint**: All user stories should now be independently functional
+
+---
+
+[Add more user story phases as needed, following the same pattern]
+
+---
+
+## Phase N: Polish & Cross-Cutting Concerns
+
+**Purpose**: Improvements that affect multiple user stories
+
+- [ ] TXXX [P] Documentation updates in docs/
+- [ ] TXXX Code cleanup and refactoring
+- [ ] TXXX Performance optimization across all stories
+- [ ] TXXX [P] Additional unit tests (if requested) in tests/unit/
+- [ ] TXXX Security hardening
+- [ ] TXXX Run quickstart.md validation
+
+---
+
+## Dependencies & Execution Order
+
+### Phase Dependencies
+
+- **Setup (Phase 1)**: No dependencies - can start immediately
+- **Foundational (Phase 2)**: Depends on Setup completion - BLOCKS all user stories
+- **User Stories (Phase 3+)**: All depend on Foundational phase completion
+  - User stories can then proceed in parallel (if staffed)
+  - Or sequentially in priority order (P1 → P2 → P3)
+- **Polish (Final Phase)**: Depends on all desired user stories being complete
+
+### User Story Dependencies
+
+- **User Story 1 (P1)**: Can start after Foundational (Phase 2) - No dependencies on other stories
+- **User Story 2 (P2)**: Can start after Foundational (Phase 2) - May integrate with US1 but should be independently testable
+- **User Story 3 (P3)**: Can start after Foundational (Phase 2) - May integrate with US1/US2 but should be independently testable
+
+### Within Each User Story
+
+- Tests (if included) MUST be written and FAIL before implementation
+- Models before services
+- Services before endpoints
+- Core implementation before integration
+- Story complete before moving to next priority
+
+### Parallel Opportunities
+
+- All Setup tasks marked [P] can run in parallel
+- All Foundational tasks marked [P] can run in parallel (within Phase 2)
+- Once Foundational phase completes, all user stories can start in parallel (if team capacity allows)
+- All tests for a user story marked [P] can run in parallel
+- Models within a story marked [P] can run in parallel
+- Different user stories can be worked on in parallel by different team members
+
+---
+
+## Parallel Example: User Story 1
+
+```bash
+# Launch all tests for User Story 1 together (if tests requested):
+Task: "Contract test for [endpoint] in tests/contract/test_[name].py"
+Task: "Integration test for [user journey] in tests/integration/test_[name].py"
+
+# Launch all models for User Story 1 together:
+Task: "Create [Entity1] model in src/models/[entity1].py"
+Task: "Create [Entity2] model in src/models/[entity2].py"
 ```
 
+---
+
+## Implementation Strategy
+
+### MVP First (User Story 1 Only)
+
+1. Complete Phase 1: Setup
+2. Complete Phase 2: Foundational (CRITICAL - blocks all stories)
+3. Complete Phase 3: User Story 1
+4. **STOP and VALIDATE**: Test User Story 1 independently
+5. Deploy/demo if ready
+
+### Incremental Delivery
+
+1. Complete Setup + Foundational → Foundation ready
+2. Add User Story 1 → Test independently → Deploy/Demo (MVP!)
+3. Add User Story 2 → Test independently → Deploy/Demo
+4. Add User Story 3 → Test independently → Deploy/Demo
+5. Each story adds value without breaking previous stories
+
+### Parallel Team Strategy
+
+With multiple developers:
+
+1. Team completes Setup + Foundational together
+2. Once Foundational is done:
+   - Developer A: User Story 1
+   - Developer B: User Story 2
+   - Developer C: User Story 3
+3. Stories complete and integrate independently
+
+---
+
 ## Notes
+
 - [P] tasks = different files, no dependencies
+- [Story] label maps task to specific user story for traceability
+- Each user story should be independently completable and testable
 - Verify tests fail before implementing
-- Commit after each task
-- Avoid: vague tasks, same file conflicts
-
-## Task Generation Rules
-*Applied during main() execution*
-
-1. **From Contracts**:
-   - Each contract file → contract test task [P]
-   - Each endpoint → implementation task
-   
-2. **From Data Model**:
-   - Each entity → model creation task [P]
-   - Relationships → service layer tasks
-   
-3. **From User Stories**:
-   - Each story → integration test [P]
-   - Quickstart scenarios → validation tasks
-
-4. **Ordering**:
-   - Setup → Tests → Models → Services → Endpoints → Polish
-   - Dependencies block parallel execution
-
-## Validation Checklist
-*GATE: Checked by main() before returning*
-
-- [ ] All contracts have corresponding tests
-- [ ] All entities have model tasks
-- [ ] All tests come before implementation
-- [ ] Parallel tasks truly independent
-- [ ] Each task specifies exact file path
-- [ ] No task modifies same file as another [P] task
\ No newline at end of file
+- Commit after each task or logical group
+- Stop at any checkpoint to validate story independently
+- Avoid: vague tasks, same file conflicts, cross-story dependencies that break independence
+
+
+
diff --git a/templates/vscode-settings.json b/templates/vscode-settings.json
new file mode 100644
index 0000000..d454aa6
--- /dev/null
+++ b/templates/vscode-settings.json
@@ -0,0 +1,14 @@
+{
+    "chat.promptFilesRecommendations": {
+        "speckit.constitution": true,
+        "speckit.specify": true,
+        "speckit.plan": true,
+        "speckit.tasks": true,
+        "speckit.implement": true
+    },
+    "chat.tools.terminal.autoApprove": {
+        ".specify/scripts/bash/": true,
+        ".specify/scripts/powershell/": true
+    }
+}
+
diff --git a/update-notes/update-notes-template.md b/update-notes/update-notes-template.md
deleted file mode 100644
index df9a925..0000000
--- a/update-notes/update-notes-template.md
+++ /dev/null
@@ -1,170 +0,0 @@
-# [项目名称] 更新说明 v[当前版本] → v[更新版本]
-
-## 版本信息
-- **当前版本**: v[当前版本] (commit: [当前CommitID])
-- **更新版本**: v[更新版本] (commit: [更新CommitID])
-- **更新日期**: [更新日期]
-
-## 更新概览
-
-本次更新是[项目名称]的一次[重大/重要/常规]版本升级，主要包含以下核心改进：
-
-### 🚀 核心功能增强
-- **[主要功能1]**: [功能描述和影响]
-- **[主要功能2]**: [功能描述和影响]
-- **[主要功能3]**: [功能描述和影响]
-- **[主要功能4]**: [功能描述和影响]
-
-### 📦 技术架构优化
-- **[技术改进1]**: [改进描述和效果]
-- **[技术改进2]**: [改进描述和效果]
-
-### 🔧 问题修复
-- **已知问题修复**: [修复的问题列表]
-- **性能优化**: [性能改进列表]
-
-## 主要更新内容
-
-### 🚀 核心功能增强
-
-#### 1. [功能模块1]
-
-**[新增/优化的功能]**:
-- **[功能点1]**: [详细描述，包含技术特点和用途]
-- **[功能点2]**: [详细描述，包含技术特点和用途]
-- **[功能点3]**: [详细描述，包含技术特点和用途]
-
-**技术实现**:
-- [技术实现细节1]
-- [技术实现细节2]
-- [技术实现细节3]
-
-#### 2. [功能模块2]
-
-**新增功能**:
-- **[功能名1]**: [功能描述，包含技术细节和使用场景]
-- **[功能名2]**: [功能描述，包含技术细节和使用场景]
-- **[功能名3]**: [功能描述，包含技术细节和使用场景]
-
-**优化现有功能**:
-- **[功能名1]**: [优化描述，包含改进点]
-- **[功能名2]**: [优化描述，包含改进点]
-
-#### 3. [功能模块3]
-
-**[功能描述]**:
-- **[特性1]**: [详细说明]
-- **[特性2]**: [详细说明]
-- **[特性3]**: [详细说明]
-
-### 🔧 技术改进
-
-#### 1. [技术模块1]
-
-**[技术改进描述]**:
-- **[改进点1]**: [详细说明]
-- **[改进点2]**: [详细说明]
-- **[改进点3]**: [详细说明]
-
-#### 2. [技术模块2]
-
-**[技术改进描述]**:
-- **[改进点1]**: [详细说明]
-- **[改进点2]**: [详细说明]
-
-**新增功能**:
-- **[功能1]**: [功能描述]
-- **[功能2]**: [功能描述]
-
-#### 3. [技术模块3]
-
-**[技术改进描述]**:
-- **[改进点1]**: [详细说明]
-- **[改进点2]**: [详细说明]
-
-### 📁 文件变更详情
-
-#### 新增文件
-- [文件路径1] - [文件描述]
-- [文件路径2] - [文件描述]
-- [文件路径3] - [文件描述]
-
-#### 删除文件
-- [文件路径1] ([删除原因])
-- [文件路径2] ([删除原因])
-
-#### 修改文件
-- [文件路径1]: [修改描述]
-- [文件路径2]: [修改描述]
-- [文件路径3]: [修改描述]
-
-### 🎯 用户体验改进
-
-#### 1. [改进类别1]
-- **[改进点1]**: [详细说明]
-- **[改进点2]**: [详细说明]
-- **[改进点3]**: [详细说明]
-
-#### 2. [改进类别2]
-- **[改进点1]**: [详细说明]
-- **[改进点2]**: [详细说明]
-
-#### 3. [改进类别3]
-- **[改进点1]**: [详细说明]
-- **[改进点2]**: [详细说明]
-
-### 🔒 安全性和稳定性
-
-#### 1. [安全类别1]
-- **[安全改进1]**: [详细说明]
-- **[安全改进2]**: [详细说明]
-
-#### 2. [安全类别2]
-- **[安全改进1]**: [详细说明]
-- **[安全改进2]**: [详细说明]
-
-## 破坏性变更
-
-### [变更类别1]
-- [变更描述1]
-- [变更描述2]
-
-### [变更类别2]
-- [变更描述1]
-- [变更描述2]
-
-## 兼容性说明
-
-### 向后兼容
-- [兼容性说明1]
-- [兼容性说明2]
-- [兼容性说明3]
-
-### 升级建议
-1. **[建议1]**: [详细说明]
-2. **[建议2]**: [详细说明]
-3. **[建议3]**: [详细说明]
-4. **[建议4]**: [详细说明]
-5. **[建议5]**: [详细说明]
-
-## 总结
-
-**核心记忆点**：
-- 🚀 **[关键特性1]**：[数字对比或关键描述]
-- ⚡ **[关键特性2]**：[关键功能描述]
-- 🔧 **[关键特性3]**：[技术改进描述]
-
-**关键改进**：[关键词1]、[关键词2]、[关键词3]、[关键词4]
-
-**升级建议**：[升级建议总结，兼容性说明]
-
----
-
-**更新统计**:
-- 新增文件: [数量]个
-- 删除文件: [数量]个  
-- 修改文件: [数量]个
-- 版本号: [当前版本] → [更新版本]
-- 主要改进: [主要改进关键词列表]
-
-*[项目总结性描述，突出更新价值和意义]*
diff --git a/update-notes/v0-v0.0.4+b18ef20-update-notes.md b/update-notes/v0-v0.0.4+b18ef20-update-notes.md
deleted file mode 100644
index e52c157..0000000
--- a/update-notes/v0-v0.0.4+b18ef20-update-notes.md
+++ /dev/null
@@ -1,197 +0,0 @@
-# Spec Kit 项目基准状态说明 v0.0.4
-
-## 版本信息
-- **当前版本**: v0.0.4 (commit: b18ef20)
-- **项目状态**: 基准版本，项目初始状态
-- **文档日期**: 2025-09-12
-
-## 项目概览
-
-Spec Kit 是一个基于规范驱动开发（Spec-Driven Development）的综合性工具包，旨在为开发团队提供结构化的软件开发方法。项目采用Python开发，支持多种AI编程助手，提供完整的开发工作流支持。
-
-### 🏗️ 核心架构
-
-**项目结构**:
-- **CLI工具**: 基于Typer框架的命令行界面，支持项目初始化和配置
-- **脚本系统**: 双平台脚本支持（Bash和PowerShell），提供跨平台兼容性
-- **模板系统**: 标准化的项目模板和命令模板，确保开发一致性
-- **AI代理集成**: 支持多种AI编程助手的集成和配置
-
-**技术栈**:
-- **Python 3.11+**: 核心开发语言
-- **Typer**: CLI框架，提供类型安全的命令行接口
-- **Rich**: 终端美化库，提供丰富的控制台输出
-- **HTTPX**: 异步HTTP客户端，支持代理和SOCKS连接
-- **Platformdirs**: 跨平台目录管理
-- **Truststore**: SSL证书管理
-
-### 🚀 核心功能
-
-#### 1. AI代理支持
-
-**当前支持的AI代理**:
-- **GitHub Copilot**: GitHub与OpenAI合作开发的AI编程助手，深度集成VS Code，提供智能代码补全和上下文感知，适合GitHub生态的协作开发
-- **Claude Code**: Anthropic开发的先进AI代码助手，基于Claude-3模型，擅长复杂逻辑推理和代码架构设计，适合大型企业级项目开发
-- **Gemini CLI**: Google开发的多模态AI编程工具，集成Gemini Pro模型，支持代码生成和自然语言交互，适合跨平台开发项目
-- **Cursor**: Cursor IDE的AI编程助手，基于GPT-4技术，提供智能代码编辑和重构功能，适合需要高效代码编辑的开发环境
-
-**技术实现**:
-- 每个代理都有独立的目录结构（如`.claude/commands/`、`.cursor/commands/`等）
-- 支持不同格式的命令文件（Markdown、TOML）
-- 统一的命令参数传递机制（`$ARGUMENTS`、`{{args}}`等）
-
-#### 2. 命令系统
-
-**核心命令**:
-- **specify命令**: 规范生成命令，基于用户输入创建详细的功能规范文档，支持交互式和命令行输入，使用create-new-feature.sh脚本进行项目初始化，适用于需求分析和规范制定场景
-- **plan命令**: 项目规划命令，基于功能规范生成详细的实施计划，支持依赖分析和任务分解，使用setup-plan.sh脚本进行计划生成，适用于项目规划和架构设计场景
-- **tasks命令**: 任务分解命令，将实施计划转换为可执行的任务列表，支持依赖排序和优先级管理，使用check-task-prerequisites.sh脚本进行前置条件检查，适用于任务管理和执行规划场景
-
-**技术特点**:
-- 支持JSON输出格式，便于其他工具集成
-- 统一的前置条件检查机制
-- 跨平台脚本支持（Bash和PowerShell）
-
-#### 3. 脚本系统
-
-**Bash脚本**:
-- **common.sh**: 通用函数库，提供跨脚本的公共功能
-- **create-new-feature.sh**: 新功能创建脚本，支持项目初始化和目录结构生成
-- **setup-plan.sh**: 计划设置脚本，生成项目实施计划
-- **check-task-prerequisites.sh**: 任务前置条件检查脚本
-- **get-feature-paths.sh**: 功能路径获取脚本
-- **update-agent-context.sh**: 代理上下文更新脚本
-
-**PowerShell脚本**:
-- **common.ps1**: PowerShell通用函数库
-- **create-new-feature.ps1**: PowerShell版本的新功能创建脚本
-- **setup-plan.ps1**: PowerShell版本的计划设置脚本
-- **check-task-prerequisites.ps1**: PowerShell版本的前置条件检查脚本
-- **get-feature-paths.ps1**: PowerShell版本的功能路径获取脚本
-- **update-agent-context.ps1**: PowerShell版本的代理上下文更新脚本
-
-#### 4. 模板系统
-
-**项目模板**:
-- **spec-template.md**: 功能规范模板，提供标准化的需求文档结构
-- **plan-template.md**: 实施计划模板，支持任务分解和依赖管理
-- **tasks-template.md**: 任务列表模板，提供可执行的任务格式
-- **agent-file-template.md**: AI代理文件模板，支持不同代理的配置
-
-**命令模板**:
-- **specify.md**: 规范生成命令模板
-- **plan.md**: 项目规划命令模板
-- **tasks.md**: 任务分解命令模板
-
-### 📁 项目结构
-
-```
-spec-kit/
-├── src/specify_cli/          # CLI核心代码
-├── scripts/                  # 脚本系统
-│   ├── bash/                # Bash脚本
-│   └── powershell/          # PowerShell脚本
-├── templates/               # 模板系统
-│   ├── commands/            # 命令模板
-│   ├── spec-template.md     # 规范模板
-│   ├── plan-template.md     # 计划模板
-│   └── tasks-template.md    # 任务模板
-├── docs/                    # 文档系统
-├── memory/                  # 项目记忆
-├── .github/workflows/       # CI/CD工作流
-└── pyproject.toml          # 项目配置
-```
-
-### 🔧 技术特性
-
-#### 1. 跨平台支持
-- **操作系统**: 支持Windows、macOS、Linux
-- **脚本语言**: 同时支持Bash和PowerShell
-- **Python版本**: 要求Python 3.11+
-
-#### 2. AI代理集成
-- **多代理支持**: 支持4种主流AI编程助手
-- **统一接口**: 标准化的命令格式和参数传递
-- **灵活配置**: 支持不同代理的特定配置需求
-
-#### 3. 开发工作流
-- **规范驱动**: 基于详细规范进行开发
-- **迭代优化**: 支持规范的持续改进
-- **质量管控**: 内置质量检查和验证机制
-
-#### 4. 扩展性
-- **模块化设计**: 松耦合的组件架构
-- **插件支持**: 支持自定义扩展
-- **模板系统**: 可定制的项目模板
-
-### 📚 文档系统
-
-**核心文档**:
-- **README.md**: 项目介绍和快速开始指南
-- **docs/**: 详细文档目录
-  - **quickstart.md**: 快速开始指南
-  - **local-development.md**: 本地开发指南
-  - **installation.md**: 安装说明
-- **CHANGELOG.md**: 版本更新日志
-- **CODE_OF_CONDUCT.md**: 行为准则
-
-**项目记忆**:
-- **constitution.md**: 项目宪法和开发规范
-- **constitution_update_checklist.md**: 宪法更新检查清单
-
-### 🚀 使用场景
-
-#### 1. 企业级项目开发
-- **大型团队协作**: 支持多开发者协作开发
-- **规范管理**: 统一的开发规范和流程
-- **质量保证**: 内置的质量检查机制
-
-#### 2. 快速原型开发
-- **快速启动**: 一键生成项目结构
-- **模板支持**: 标准化的项目模板
-- **AI辅助**: 智能化的开发建议
-
-#### 3. 教学和培训
-- **结构化学习**: 规范化的开发流程
-- **最佳实践**: 内置的开发最佳实践
-- **文档完善**: 详细的文档和示例
-
-### 🔮 项目优势
-
-#### 1. 技术优势
-- **现代化技术栈**: 基于最新的Python生态
-- **跨平台兼容**: 支持主流操作系统
-- **AI集成**: 深度集成多种AI编程助手
-
-#### 2. 开发优势
-- **规范驱动**: 确保开发质量和一致性
-- **工具链完整**: 从规划到实现的完整工具链
-- **易于扩展**: 模块化的架构设计
-
-#### 3. 团队优势
-- **协作友好**: 支持团队协作开发
-- **文档完善**: 详细的文档和指南
-- **社区支持**: 活跃的开源社区
-
-## 总结
-
-**项目定位**: Spec Kit是一个现代化的规范驱动开发工具包，为开发团队提供结构化的软件开发方法
-
-**核心价值**: 通过规范驱动开发，提高代码质量，加速开发效率，促进团队协作
-
-**技术特色**: 跨平台支持、AI代理集成、模块化架构、完整工具链
-
-**适用场景**: 企业级项目开发、快速原型开发、教学培训、团队协作
-
----
-
-**项目统计**:
-- 支持AI代理: 4个
-- 核心命令: 3个
-- 脚本文件: 12个（Bash + PowerShell）
-- 模板文件: 7个
-- 文档文件: 10+个
-- 版本号: v0.0.4
-- 主要特性: 规范驱动开发、AI代理集成、跨平台支持、模块化架构
-
-*Spec Kit为规范驱动开发提供了完整的工具链支持，是现代软件开发团队的重要工具。*
diff --git a/update-notes/v0.0.4+b18ef20-v0.0.17+f3d55cf-git-diff.txt b/update-notes/v0.0.4+b18ef20-v0.0.17+f3d55cf-git-diff.txt
deleted file mode 100644
index d66f447..0000000
--- a/update-notes/v0.0.4+b18ef20-v0.0.17+f3d55cf-git-diff.txt
+++ /dev/null
@@ -1,4811 +0,0 @@
-diff --git a/.github/workflows/release.yml b/.github/workflows/release.yml
-index bb29563..0bede83 100644
---- a/.github/workflows/release.yml
-+++ b/.github/workflows/release.yml
-@@ -25,33 +25,13 @@ jobs:
-       - name: Get latest tag
-         id: get_tag
-         run: |
--          # Get the latest tag, or use v0.0.0 if no tags exist
--          LATEST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "v0.0.0")
--          echo "latest_tag=$LATEST_TAG" >> $GITHUB_OUTPUT
--          
--          # Extract version number and increment
--          VERSION=$(echo $LATEST_TAG | sed 's/v//')
--          IFS='.' read -ra VERSION_PARTS <<< "$VERSION"
--          MAJOR=${VERSION_PARTS[0]:-0}
--          MINOR=${VERSION_PARTS[1]:-0}
--          PATCH=${VERSION_PARTS[2]:-0}
--          
--          # Increment patch version
--          PATCH=$((PATCH + 1))
--          NEW_VERSION="v$MAJOR.$MINOR.$PATCH"
--          
--          echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT
--          echo "New version will be: $NEW_VERSION"
-+          chmod +x .github/workflows/scripts/get-next-version.sh
-+          .github/workflows/scripts/get-next-version.sh
-       - name: Check if release already exists
-         id: check_release
-         run: |
--          if gh release view ${{ steps.get_tag.outputs.new_version }} >/dev/null 2>&1; then
--            echo "exists=true" >> $GITHUB_OUTPUT
--            echo "Release ${{ steps.get_tag.outputs.new_version }} already exists, skipping..."
--          else
--            echo "exists=false" >> $GITHUB_OUTPUT
--            echo "Release ${{ steps.get_tag.outputs.new_version }} does not exist, proceeding..."
--          fi
-+          chmod +x .github/workflows/scripts/check-release-exists.sh
-+          .github/workflows/scripts/check-release-exists.sh ${{ steps.get_tag.outputs.new_version }}
-         env:
-           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
-       - name: Create release package variants
-@@ -63,69 +43,17 @@ jobs:
-         if: steps.check_release.outputs.exists == 'false'
-         id: release_notes
-         run: |
--          # Get commits since last tag
--          LAST_TAG=${{ steps.get_tag.outputs.latest_tag }}
--          if [ "$LAST_TAG" = "v0.0.0" ]; then
--            # Check how many commits we have and use that as the limit
--            COMMIT_COUNT=$(git rev-list --count HEAD)
--            if [ "$COMMIT_COUNT" -gt 10 ]; then
--              COMMITS=$(git log --oneline --pretty=format:"- %s" HEAD~10..HEAD)
--            else
--              COMMITS=$(git log --oneline --pretty=format:"- %s" HEAD~$COMMIT_COUNT..HEAD 2>/dev/null || git log --oneline --pretty=format:"- %s")
--            fi
--          else
--            COMMITS=$(git log --oneline --pretty=format:"- %s" $LAST_TAG..HEAD)
--          fi
--          
--          # Create release notes
--          cat > release_notes.md << EOF
--          Template release ${{ steps.get_tag.outputs.new_version }}
--
--          Updated specification-driven development templates for GitHub Copilot, Claude Code, Gemini CLI, and Cursor.
--
--          Now includes per-script variants for POSIX shell (sh) and PowerShell (ps).
--
--          Download the template for your preferred AI assistant + script type:
--          - spec-kit-template-copilot-sh-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-copilot-ps-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-claude-sh-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-claude-ps-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-gemini-sh-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-gemini-ps-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-cursor-sh-${{ steps.get_tag.outputs.new_version }}.zip
--          - spec-kit-template-cursor-ps-${{ steps.get_tag.outputs.new_version }}.zip
--          EOF
--          
--          echo "Generated release notes:"
--          cat release_notes.md
-+          chmod +x .github/workflows/scripts/generate-release-notes.sh
-+          .github/workflows/scripts/generate-release-notes.sh ${{ steps.get_tag.outputs.new_version }} ${{ steps.get_tag.outputs.latest_tag }}
-       - name: Create GitHub Release
-         if: steps.check_release.outputs.exists == 'false'
-         run: |
--          # Remove 'v' prefix from version for release title
--          VERSION_NO_V=${{ steps.get_tag.outputs.new_version }}
--          VERSION_NO_V=${VERSION_NO_V#v}
--          
--          gh release create ${{ steps.get_tag.outputs.new_version }} \
--            spec-kit-template-copilot-sh-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-copilot-ps-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-claude-sh-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-claude-ps-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-gemini-sh-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-gemini-ps-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-cursor-sh-${{ steps.get_tag.outputs.new_version }}.zip \
--            spec-kit-template-cursor-ps-${{ steps.get_tag.outputs.new_version }}.zip \
--            --title "Spec Kit Templates - $VERSION_NO_V" \
--            --notes-file release_notes.md
-+          chmod +x .github/workflows/scripts/create-github-release.sh
-+          .github/workflows/scripts/create-github-release.sh ${{ steps.get_tag.outputs.new_version }}
-         env:
-           GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
-       - name: Update version in pyproject.toml (for release artifacts only)
-         if: steps.check_release.outputs.exists == 'false'
-         run: |
--          # Update version in pyproject.toml (remove 'v' prefix for Python versioning)
--          VERSION=${{ steps.get_tag.outputs.new_version }}
--          PYTHON_VERSION=${VERSION#v}
--          
--          if [ -f "pyproject.toml" ]; then
--            sed -i "s/version = \".*\"/version = \"$PYTHON_VERSION\"/" pyproject.toml
--            echo "Updated pyproject.toml version to $PYTHON_VERSION (for release artifacts only)"
--          fi
-+          chmod +x .github/workflows/scripts/update-version.sh
-+          .github/workflows/scripts/update-version.sh ${{ steps.get_tag.outputs.new_version }}
-diff --git a/.github/workflows/scripts/check-release-exists.sh b/.github/workflows/scripts/check-release-exists.sh
-new file mode 100644
-index 0000000..161bf20
---- /dev/null
-+++ b/.github/workflows/scripts/check-release-exists.sh
-@@ -0,0 +1,21 @@
-+#!/usr/bin/env bash
-+set -euo pipefail
-+
-+# check-release-exists.sh
-+# Check if a GitHub release already exists for the given version
-+# Usage: check-release-exists.sh <version>
-+
-+if [[ $# -ne 1 ]]; then
-+  echo "Usage: $0 <version>" >&2
-+  exit 1
-+fi
-+
-+VERSION="$1"
-+
-+if gh release view "$VERSION" >/dev/null 2>&1; then
-+  echo "exists=true" >> $GITHUB_OUTPUT
-+  echo "Release $VERSION already exists, skipping..."
-+else
-+  echo "exists=false" >> $GITHUB_OUTPUT
-+  echo "Release $VERSION does not exist, proceeding..."
-+fi
-\ No newline at end of file
-diff --git a/.github/workflows/scripts/create-github-release.sh b/.github/workflows/scripts/create-github-release.sh
-new file mode 100644
-index 0000000..0257520
---- /dev/null
-+++ b/.github/workflows/scripts/create-github-release.sh
-@@ -0,0 +1,42 @@
-+#!/usr/bin/env bash
-+set -euo pipefail
-+
-+# create-github-release.sh
-+# Create a GitHub release with all template zip files
-+# Usage: create-github-release.sh <version>
-+
-+if [[ $# -ne 1 ]]; then
-+  echo "Usage: $0 <version>" >&2
-+  exit 1
-+fi
-+
-+VERSION="$1"
-+
-+# Remove 'v' prefix from version for release title
-+VERSION_NO_V=${VERSION#v}
-+
-+gh release create "$VERSION" \
-+  .genreleases/spec-kit-template-copilot-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-copilot-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-claude-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-claude-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-gemini-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-gemini-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-cursor-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-cursor-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-opencode-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-opencode-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-qwen-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-qwen-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-windsurf-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-windsurf-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-codex-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-codex-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-kilocode-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-kilocode-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-auggie-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-auggie-ps-"$VERSION".zip \
-+  .genreleases/spec-kit-template-roo-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-roo-ps-"$VERSION".zip \
-+  --title "Spec Kit Templates - $VERSION_NO_V" \
-+  --notes-file release_notes.md
-\ No newline at end of file
-diff --git a/.github/workflows/scripts/create-release-packages.sh b/.github/workflows/scripts/create-release-packages.sh
-index 0ea28e0..1a12e55 100644
---- a/.github/workflows/scripts/create-release-packages.sh
-+++ b/.github/workflows/scripts/create-release-packages.sh
-@@ -6,7 +6,7 @@ set -euo pipefail
- # Usage: .github/workflows/scripts/create-release-packages.sh <version>
- #   Version argument should include leading 'v'.
- #   Optionally set AGENTS and/or SCRIPTS env vars to limit what gets built.
--#     AGENTS  : space or comma separated subset of: claude gemini copilot (default: all)
-+#     AGENTS  : space or comma separated subset of: claude gemini copilot cursor qwen opencode windsurf codex (default: all)
- #     SCRIPTS : space or comma separated subset of: sh ps (default: both)
- #   Examples:
- #     AGENTS=claude SCRIPTS=sh $0 v0.2.0
-@@ -25,7 +25,10 @@ fi
- 
- echo "Building release packages for $NEW_VERSION"
- 
--rm -rf sdd-package-base* sdd-*-package-* spec-kit-template-*-${NEW_VERSION}.zip || true
-+# Create and use .genreleases directory for all build artifacts
-+GENRELEASES_DIR=".genreleases"
-+mkdir -p "$GENRELEASES_DIR"
-+rm -rf "$GENRELEASES_DIR"/* || true
- 
- rewrite_paths() {
-   sed -E \
-@@ -82,7 +85,7 @@ generate_commands() {
- 
- build_variant() {
-   local agent=$1 script=$2
--  local base_dir="sdd-${agent}-package-${script}"
-+  local base_dir="$GENRELEASES_DIR/sdd-${agent}-package-${script}"
-   echo "Building $agent ($script) package..."
-   mkdir -p "$base_dir"
-   
-@@ -119,7 +122,6 @@ build_variant() {
-     if [[ -n $script_command ]]; then
-       # Always prefix with .specify/ for plan usage
-       script_command=".specify/$script_command"
--      tmp_file=$(mktemp)
-       # Replace {SCRIPT} placeholder with the script command and __AGENT__ with agent name
-       substituted=$(sed "s|{SCRIPT}|${script_command}|g" "$plan_tpl" | tr -d '\r' | sed "s|__AGENT__|${agent}|g")
-       # Strip YAML frontmatter from plan template output (keep body only)
-@@ -129,6 +131,11 @@ build_variant() {
-       echo "Warning: no plan-template script command found for $script in YAML frontmatter" >&2
-     fi
-   fi
-+  # NOTE: We substitute {ARGS} internally. Outward tokens differ intentionally:
-+  #   * Markdown/prompt (claude, copilot, cursor, opencode): $ARGUMENTS
-+  #   * TOML (gemini, qwen): {{args}}
-+  # This keeps formats readable without extra abstraction.
-+
-   case $agent in
-     claude)
-       mkdir -p "$base_dir/.claude/commands"
-@@ -143,26 +150,49 @@ build_variant() {
-     cursor)
-       mkdir -p "$base_dir/.cursor/commands"
-       generate_commands cursor md "\$ARGUMENTS" "$base_dir/.cursor/commands" "$script" ;;
-+    qwen)
-+      mkdir -p "$base_dir/.qwen/commands"
-+      generate_commands qwen toml "{{args}}" "$base_dir/.qwen/commands" "$script"
-+      [[ -f agent_templates/qwen/QWEN.md ]] && cp agent_templates/qwen/QWEN.md "$base_dir/QWEN.md" ;;
-+    opencode)
-+      mkdir -p "$base_dir/.opencode/command"
-+      generate_commands opencode md "\$ARGUMENTS" "$base_dir/.opencode/command" "$script" ;;
-+    windsurf)
-+      mkdir -p "$base_dir/.windsurf/workflows"
-+      generate_commands windsurf md "\$ARGUMENTS" "$base_dir/.windsurf/workflows" "$script" ;;
-+    codex)
-+      mkdir -p "$base_dir/.codex/prompts"
-+      generate_commands codex md "\$ARGUMENTS" "$base_dir/.codex/prompts" "$script" ;;
-+    kilocode)
-+      mkdir -p "$base_dir/.kilocode/workflows"
-+      generate_commands kilocode md "\$ARGUMENTS" "$base_dir/.kilocode/workflows" "$script" ;;
-+    auggie)
-+      mkdir -p "$base_dir/.augment/commands"
-+      generate_commands auggie md "\$ARGUMENTS" "$base_dir/.augment/commands" "$script" ;;
-+    roo)
-+      mkdir -p "$base_dir/.roo/commands"
-+      generate_commands roo md "\$ARGUMENTS" "$base_dir/.roo/commands" "$script" ;;
-   esac
-   ( cd "$base_dir" && zip -r "../spec-kit-template-${agent}-${script}-${NEW_VERSION}.zip" . )
--  echo "Created spec-kit-template-${agent}-${script}-${NEW_VERSION}.zip"
-+  echo "Created $GENRELEASES_DIR/spec-kit-template-${agent}-${script}-${NEW_VERSION}.zip"
- }
- 
- # Determine agent list
--ALL_AGENTS=(claude gemini copilot cursor)
-+ALL_AGENTS=(claude gemini copilot cursor qwen opencode windsurf codex kilocode auggie roo)
- ALL_SCRIPTS=(sh ps)
- 
-+
- norm_list() {
-   # convert comma+space separated -> space separated unique while preserving order of first occurrence
-   tr ',\n' '  ' | awk '{for(i=1;i<=NF;i++){if(!seen[$i]++){printf((out?" ":"") $i)}}}END{printf("\n")}'
- }
- 
- validate_subset() {
--  local type=$1; shift; local -n allowed=$1; shift; local items=($@)
-+  local type=$1; shift; local -n allowed=$1; shift; local items=("$@")
-   local ok=1
-   for it in "${items[@]}"; do
-     local found=0
--    for a in "${allowed[@]}"; do [[ $it == $a ]] && { found=1; break; }; done
-+    for a in "${allowed[@]}"; do [[ $it == "$a" ]] && { found=1; break; }; done
-     if [[ $found -eq 0 ]]; then
-       echo "Error: unknown $type '$it' (allowed: ${allowed[*]})" >&2
-       ok=0
-@@ -172,17 +202,17 @@ validate_subset() {
- }
- 
- if [[ -n ${AGENTS:-} ]]; then
--  AGENT_LIST=($(printf '%s' "$AGENTS" | norm_list))
-+  mapfile -t AGENT_LIST < <(printf '%s' "$AGENTS" | norm_list)
-   validate_subset agent ALL_AGENTS "${AGENT_LIST[@]}" || exit 1
- else
--  AGENT_LIST=(${ALL_AGENTS[@]})
-+  AGENT_LIST=("${ALL_AGENTS[@]}")
- fi
- 
- if [[ -n ${SCRIPTS:-} ]]; then
--  SCRIPT_LIST=($(printf '%s' "$SCRIPTS" | norm_list))
-+  mapfile -t SCRIPT_LIST < <(printf '%s' "$SCRIPTS" | norm_list)
-   validate_subset script ALL_SCRIPTS "${SCRIPT_LIST[@]}" || exit 1
- else
--  SCRIPT_LIST=(${ALL_SCRIPTS[@]})
-+  SCRIPT_LIST=("${ALL_SCRIPTS[@]}")
- fi
- 
- echo "Agents: ${AGENT_LIST[*]}"
-@@ -194,5 +224,5 @@ for agent in "${AGENT_LIST[@]}"; do
-   done
- done
- 
--echo "Archives:"
--ls -1 spec-kit-template-*-${NEW_VERSION}.zip
-+echo "Archives in $GENRELEASES_DIR:"
-+ls -1 "$GENRELEASES_DIR"/spec-kit-template-*-"${NEW_VERSION}".zip
-diff --git a/.github/workflows/scripts/generate-release-notes.sh b/.github/workflows/scripts/generate-release-notes.sh
-new file mode 100644
-index 0000000..a26d16b
---- /dev/null
-+++ b/.github/workflows/scripts/generate-release-notes.sh
-@@ -0,0 +1,36 @@
-+#!/usr/bin/env bash
-+set -euo pipefail
-+
-+# generate-release-notes.sh
-+# Generate release notes from git history
-+# Usage: generate-release-notes.sh <new_version> <last_tag>
-+
-+if [[ $# -ne 2 ]]; then
-+  echo "Usage: $0 <new_version> <last_tag>" >&2
-+  exit 1
-+fi
-+
-+NEW_VERSION="$1"
-+LAST_TAG="$2"
-+
-+# Get commits since last tag
-+if [ "$LAST_TAG" = "v0.0.0" ]; then
-+  # Check how many commits we have and use that as the limit
-+  COMMIT_COUNT=$(git rev-list --count HEAD)
-+  if [ "$COMMIT_COUNT" -gt 10 ]; then
-+    COMMITS=$(git log --oneline --pretty=format:"- %s" HEAD~10..HEAD)
-+  else
-+    COMMITS=$(git log --oneline --pretty=format:"- %s" HEAD~$COMMIT_COUNT..HEAD 2>/dev/null || git log --oneline --pretty=format:"- %s")
-+  fi
-+else
-+  COMMITS=$(git log --oneline --pretty=format:"- %s" $LAST_TAG..HEAD)
-+fi
-+
-+# Create release notes
-+cat > release_notes.md << EOF
-+This is the latest set of releases that you can use with your agent of choice. We recommend using the Specify CLI to scaffold your projects, however you can download these independently and manage them yourself.
-+
-+EOF
-+
-+echo "Generated release notes:"
-+cat release_notes.md
-\ No newline at end of file
-diff --git a/.github/workflows/scripts/get-next-version.sh b/.github/workflows/scripts/get-next-version.sh
-new file mode 100644
-index 0000000..2be0b6c
---- /dev/null
-+++ b/.github/workflows/scripts/get-next-version.sh
-@@ -0,0 +1,24 @@
-+#!/usr/bin/env bash
-+set -euo pipefail
-+
-+# get-next-version.sh
-+# Calculate the next version based on the latest git tag and output GitHub Actions variables
-+# Usage: get-next-version.sh
-+
-+# Get the latest tag, or use v0.0.0 if no tags exist
-+LATEST_TAG=$(git describe --tags --abbrev=0 2>/dev/null || echo "v0.0.0")
-+echo "latest_tag=$LATEST_TAG" >> $GITHUB_OUTPUT
-+
-+# Extract version number and increment
-+VERSION=$(echo $LATEST_TAG | sed 's/v//')
-+IFS='.' read -ra VERSION_PARTS <<< "$VERSION"
-+MAJOR=${VERSION_PARTS[0]:-0}
-+MINOR=${VERSION_PARTS[1]:-0}
-+PATCH=${VERSION_PARTS[2]:-0}
-+
-+# Increment patch version
-+PATCH=$((PATCH + 1))
-+NEW_VERSION="v$MAJOR.$MINOR.$PATCH"
-+
-+echo "new_version=$NEW_VERSION" >> $GITHUB_OUTPUT
-+echo "New version will be: $NEW_VERSION"
-\ No newline at end of file
-diff --git a/.github/workflows/scripts/update-version.sh b/.github/workflows/scripts/update-version.sh
-new file mode 100644
-index 0000000..b0dc0e6
---- /dev/null
-+++ b/.github/workflows/scripts/update-version.sh
-@@ -0,0 +1,23 @@
-+#!/usr/bin/env bash
-+set -euo pipefail
-+
-+# update-version.sh
-+# Update version in pyproject.toml (for release artifacts only)
-+# Usage: update-version.sh <version>
-+
-+if [[ $# -ne 1 ]]; then
-+  echo "Usage: $0 <version>" >&2
-+  exit 1
-+fi
-+
-+VERSION="$1"
-+
-+# Remove 'v' prefix for Python versioning
-+PYTHON_VERSION=${VERSION#v}
-+
-+if [ -f "pyproject.toml" ]; then
-+  sed -i "s/version = \".*\"/version = \"$PYTHON_VERSION\"/" pyproject.toml
-+  echo "Updated pyproject.toml version to $PYTHON_VERSION (for release artifacts only)"
-+else
-+  echo "Warning: pyproject.toml not found, skipping version update"
-+fi
-\ No newline at end of file
-diff --git a/.gitignore b/.gitignore
-index 21c7cd0..42a1fbb 100644
---- a/.gitignore
-+++ b/.gitignore
-@@ -38,3 +38,8 @@ env/
- .env
- .env.local
- *.lock
-+
-+# Spec Kit-specific files
-+.genreleases/
-+*.zip
-+sdd-*/
-\ No newline at end of file
-diff --git a/AGENTS.md b/AGENTS.md
-new file mode 100644
-index 0000000..59b9956
---- /dev/null
-+++ b/AGENTS.md
-@@ -0,0 +1,272 @@
-+# AGENTS.md
-+
-+## About Spec Kit and Specify
-+
-+**GitHub Spec Kit** is a comprehensive toolkit for implementing Spec-Driven Development (SDD) - a methodology that emphasizes creating clear specifications before implementation. The toolkit includes templates, scripts, and workflows that guide development teams through a structured approach to building software.
-+
-+**Specify CLI** is the command-line interface that bootstraps projects with the Spec Kit framework. It sets up the necessary directory structures, templates, and AI agent integrations to support the Spec-Driven Development workflow.
-+
-+The toolkit supports multiple AI coding assistants, allowing teams to use their preferred tools while maintaining consistent project structure and development practices.
-+
-+---
-+
-+## General practices
-+
-+- Any changes to `__init__.py` for the Specify CLI require a version rev in `pyproject.toml` and addition of entries to `CHANGELOG.md`.
-+
-+## Adding New Agent Support
-+
-+This section explains how to add support for new AI agents/assistants to the Specify CLI. Use this guide as a reference when integrating new AI tools into the Spec-Driven Development workflow.
-+
-+### Overview
-+
-+Specify supports multiple AI agents by generating agent-specific command files and directory structures when initializing projects. Each agent has its own conventions for:
-+
-+- **Command file formats** (Markdown, TOML, etc.)
-+- **Directory structures** (`.claude/commands/`, `.windsurf/workflows/`, etc.)
-+- **Command invocation patterns** (slash commands, CLI tools, etc.)
-+- **Argument passing conventions** (`$ARGUMENTS`, `{{args}}`, etc.)
-+
-+### Current Supported Agents
-+
-+| Agent | Directory | Format | CLI Tool | Description |
-+|-------|-----------|---------|----------|-------------|
-+| **Claude Code** | `.claude/commands/` | Markdown | `claude` | Anthropic's Claude Code CLI |
-+| **Gemini CLI** | `.gemini/commands/` | TOML | `gemini` | Google's Gemini CLI |
-+| **GitHub Copilot** | `.github/prompts/` | Markdown | N/A (IDE-based) | GitHub Copilot in VS Code |
-+| **Cursor** | `.cursor/commands/` | Markdown | `cursor-agent` | Cursor CLI |
-+| **Qwen Code** | `.qwen/commands/` | TOML | `qwen` | Alibaba's Qwen Code CLI |
-+| **opencode** | `.opencode/command/` | Markdown | `opencode` | opencode CLI |
-+| **Windsurf** | `.windsurf/workflows/` | Markdown | N/A (IDE-based) | Windsurf IDE workflows |
-+
-+### Step-by-Step Integration Guide
-+
-+Follow these steps to add a new agent (using Windsurf as an example):
-+
-+#### 1. Update AI_CHOICES Constant
-+
-+Add the new agent to the `AI_CHOICES` dictionary in `src/specify_cli/__init__.py`:
-+
-+```python
-+AI_CHOICES = {
-+    "copilot": "GitHub Copilot",
-+    "claude": "Claude Code", 
-+    "gemini": "Gemini CLI",
-+    "cursor": "Cursor",
-+    "qwen": "Qwen Code",
-+    "opencode": "opencode",
-+    "windsurf": "Windsurf"  # Add new agent here
-+}
-+```
-+
-+Also update the `agent_folder_map` in the same file to include the new agent's folder for the security notice:
-+
-+```python
-+agent_folder_map = {
-+    "claude": ".claude/",
-+    "gemini": ".gemini/",
-+    "cursor": ".cursor/",
-+    "qwen": ".qwen/",
-+    "opencode": ".opencode/",
-+    "codex": ".codex/",
-+    "windsurf": ".windsurf/",  # Add new agent folder here
-+    "kilocode": ".kilocode/",
-+    "auggie": ".auggie/",
-+    "copilot": ".github/"
-+}
-+```
-+
-+#### 2. Update CLI Help Text
-+
-+Update all help text and examples to include the new agent:
-+
-+- Command option help: `--ai` parameter description
-+- Function docstrings and examples
-+- Error messages with agent lists
-+
-+#### 3. Update README Documentation
-+
-+Update the **Supported AI Agents** section in `README.md` to include the new agent:
-+
-+- Add the new agent to the table with appropriate support level (Full/Partial)
-+- Include the agent's official website link
-+- Add any relevant notes about the agent's implementation
-+- Ensure the table formatting remains aligned and consistent
-+
-+#### 4. Update Release Package Script
-+
-+Modify `.github/workflows/scripts/create-release-packages.sh`:
-+
-+##### Add to ALL_AGENTS array:
-+```bash
-+ALL_AGENTS=(claude gemini copilot cursor qwen opencode windsurf)
-+```
-+
-+##### Add case statement for directory structure:
-+```bash
-+case $agent in
-+  # ... existing cases ...
-+  windsurf)
-+    mkdir -p "$base_dir/.windsurf/workflows"
-+    generate_commands windsurf md "\$ARGUMENTS" "$base_dir/.windsurf/workflows" "$script" ;;
-+esac
-+```
-+
-+#### 4. Update GitHub Release Script
-+
-+Modify `.github/workflows/scripts/create-github-release.sh` to include the new agent's packages:
-+
-+```bash
-+gh release create "$VERSION" \
-+  # ... existing packages ...
-+  .genreleases/spec-kit-template-windsurf-sh-"$VERSION".zip \
-+  .genreleases/spec-kit-template-windsurf-ps-"$VERSION".zip \
-+  # Add new agent packages here
-+```
-+
-+#### 5. Update Agent Context Scripts
-+
-+##### Bash script (`scripts/bash/update-agent-context.sh`):
-+
-+Add file variable:
-+```bash
-+WINDSURF_FILE="$REPO_ROOT/.windsurf/rules/specify-rules.md"
-+```
-+
-+Add to case statement:
-+```bash
-+case "$AGENT_TYPE" in
-+  # ... existing cases ...
-+  windsurf) update_agent_file "$WINDSURF_FILE" "Windsurf" ;;
-+  "") 
-+    # ... existing checks ...
-+    [ -f "$WINDSURF_FILE" ] && update_agent_file "$WINDSURF_FILE" "Windsurf";
-+    # Update default creation condition
-+    ;;
-+esac
-+```
-+
-+##### PowerShell script (`scripts/powershell/update-agent-context.ps1`):
-+
-+Add file variable:
-+```powershell
-+$windsurfFile = Join-Path $repoRoot '.windsurf/rules/specify-rules.md'
-+```
-+
-+Add to switch statement:
-+```powershell
-+switch ($AgentType) {
-+    # ... existing cases ...
-+    'windsurf' { Update-AgentFile $windsurfFile 'Windsurf' }
-+    '' {
-+        foreach ($pair in @(
-+            # ... existing pairs ...
-+            @{file=$windsurfFile; name='Windsurf'}
-+        )) {
-+            if (Test-Path $pair.file) { Update-AgentFile $pair.file $pair.name }
-+        }
-+        # Update default creation condition
-+    }
-+}
-+```
-+
-+#### 6. Update CLI Tool Checks (Optional)
-+
-+For agents that require CLI tools, add checks in the `check()` command and agent validation:
-+
-+```python
-+# In check() command
-+tracker.add("windsurf", "Windsurf IDE (optional)")
-+windsurf_ok = check_tool_for_tracker("windsurf", "https://windsurf.com/", tracker)
-+
-+# In init validation (only if CLI tool required)
-+elif selected_ai == "windsurf":
-+    if not check_tool("windsurf", "Install from: https://windsurf.com/"):
-+        console.print("[red]Error:[/red] Windsurf CLI is required for Windsurf projects")
-+        agent_tool_missing = True
-+```
-+
-+**Note**: Skip CLI checks for IDE-based agents (Copilot, Windsurf).
-+
-+## Agent Categories
-+
-+### CLI-Based Agents
-+Require a command-line tool to be installed:
-+- **Claude Code**: `claude` CLI
-+- **Gemini CLI**: `gemini` CLI  
-+- **Cursor**: `cursor-agent` CLI
-+- **Qwen Code**: `qwen` CLI
-+- **opencode**: `opencode` CLI
-+
-+### IDE-Based Agents
-+Work within integrated development environments:
-+- **GitHub Copilot**: Built into VS Code/compatible editors
-+- **Windsurf**: Built into Windsurf IDE
-+
-+## Command File Formats
-+
-+### Markdown Format
-+Used by: Claude, Cursor, opencode, Windsurf
-+
-+```markdown
-+---
-+description: "Command description"
-+---
-+
-+Command content with {SCRIPT} and $ARGUMENTS placeholders.
-+```
-+
-+### TOML Format
-+Used by: Gemini, Qwen
-+
-+```toml
-+description = "Command description"
-+
-+prompt = """
-+Command content with {SCRIPT} and {{args}} placeholders.
-+"""
-+```
-+
-+## Directory Conventions
-+
-+- **CLI agents**: Usually `.<agent-name>/commands/`
-+- **IDE agents**: Follow IDE-specific patterns:
-+  - Copilot: `.github/prompts/`
-+  - Cursor: `.cursor/commands/`
-+  - Windsurf: `.windsurf/workflows/`
-+
-+## Argument Patterns
-+
-+Different agents use different argument placeholders:
-+- **Markdown/prompt-based**: `$ARGUMENTS`
-+- **TOML-based**: `{{args}}`
-+- **Script placeholders**: `{SCRIPT}` (replaced with actual script path)
-+- **Agent placeholders**: `__AGENT__` (replaced with agent name)
-+
-+## Testing New Agent Integration
-+
-+1. **Build test**: Run package creation script locally
-+2. **CLI test**: Test `specify init --ai <agent>` command
-+3. **File generation**: Verify correct directory structure and files
-+4. **Command validation**: Ensure generated commands work with the agent
-+5. **Context update**: Test agent context update scripts
-+
-+## Common Pitfalls
-+
-+1. **Forgetting update scripts**: Both bash and PowerShell scripts must be updated
-+2. **Missing CLI checks**: Only add for agents that actually have CLI tools
-+3. **Wrong argument format**: Use correct placeholder format for each agent type
-+4. **Directory naming**: Follow agent-specific conventions exactly
-+5. **Help text inconsistency**: Update all user-facing text consistently
-+
-+## Future Considerations
-+
-+When adding new agents:
-+- Consider the agent's native command/workflow patterns
-+- Ensure compatibility with the Spec-Driven Development process
-+- Document any special requirements or limitations
-+- Update this guide with lessons learned
-+
-+---
-+
-+*This documentation should be updated whenever new agents are added to maintain accuracy and completeness.*
-\ No newline at end of file
-diff --git a/CHANGELOG.md b/CHANGELOG.md
-index 91eb47a..92cb0b8 100644
---- a/CHANGELOG.md
-+++ b/CHANGELOG.md
-@@ -1,11 +1,107 @@
- # Changelog
- 
-+<!-- markdownlint-disable MD024 -->
-+
- All notable changes to the Specify CLI will be documented in this file.
- 
- The format is based on [Keep a Changelog](https://keepachangelog.com/en/1.0.0/),
- and this project adheres to [Semantic Versioning](https://semver.org/spec/v2.0.0.html).
- 
--## [Unreleased]
-+## [0.0.17] - 2025-09-22
-+
-+### Added
-+
-+- New `/clarify` command template to surface up to 5 targeted clarification questions for an existing spec and persist answers into a Clarifications section in the spec.
-+- New `/analyze` command template providing a non-destructive cross-artifact discrepancy and alignment report (spec, clarifications, plan, tasks, constitution) inserted after `/tasks` and before `/implement`.
-+	- Note: Constitution rules are explicitly treated as non-negotiable; any conflict is a CRITICAL finding requiring artifact remediation, not weakening of principles.
-+
-+## [0.0.16] - 2025-09-22
-+
-+### Added
-+
-+- `--force` flag for `init` command to bypass confirmation when using `--here` in a non-empty directory and proceed with merging/overwriting files.
-+
-+## [0.0.15] - 2025-09-21
-+
-+### Added
-+
-+- Support for Roo Code.
-+
-+## [0.0.14] - 2025-09-21
-+
-+### Changed
-+
-+- Error messages are now shown consistently.
-+
-+## [0.0.13] - 2025-09-21
-+
-+### Added
-+
-+- Support for Kilo Code. Thank you [@shahrukhkhan489](https://github.com/shahrukhkhan489) with [#394](https://github.com/github/spec-kit/pull/394).
-+- Support for Auggie CLI. Thank you [@hungthai1401](https://github.com/hungthai1401) with [#137](https://github.com/github/spec-kit/pull/137).
-+- Agent folder security notice displayed after project provisioning completion, warning users that some agents may store credentials or auth tokens in their agent folders and recommending adding relevant folders to `.gitignore` to prevent accidental credential leakage.
-+
-+### Changed
-+
-+- Warning displayed to ensure that folks are aware that they might need to add their agent folder to `.gitignore`.
-+- Cleaned up the `check` command output.
-+
-+## [0.0.12] - 2025-09-21
-+
-+### Changed
-+
-+- Added additional context for OpenAI Codex users - they need to set an additional environment variable, as described in [#417](https://github.com/github/spec-kit/issues/417).
-+
-+## [0.0.11] - 2025-09-20
-+
-+### Added
-+
-+- Codex CLI support (thank you [@honjo-hiroaki-gtt](https://github.com/honjo-hiroaki-gtt) for the contribution in [#14](https://github.com/github/spec-kit/pull/14))
-+- Codex-aware context update tooling (Bash and PowerShell) so feature plans refresh `AGENTS.md` alongside existing assistants without manual edits.
-+
-+## [0.0.10] - 2025-09-20
-+
-+### Fixed
-+
-+- Addressed [#378](https://github.com/github/spec-kit/issues/378) where a GitHub token may be attached to the request when it was empty.
-+
-+## [0.0.9] - 2025-09-19
-+
-+### Changed
-+
-+- Improved agent selector UI with cyan highlighting for agent keys and gray parentheses for full names
-+
-+## [0.0.8] - 2025-09-19
-+
-+### Added
-+
-+- Windsurf IDE support as additional AI assistant option (thank you [@raedkit](https://github.com/raedkit) for the work in [#151](https://github.com/github/spec-kit/pull/151))
-+- GitHub token support for API requests to handle corporate environments and rate limiting (contributed by [@zryfish](https://github.com/@zryfish) in [#243](https://github.com/github/spec-kit/pull/243))
-+
-+### Changed
-+
-+- Updated README with Windsurf examples and GitHub token usage
-+- Enhanced release workflow to include Windsurf templates
-+
-+## [0.0.7] - 2025-09-18
-+
-+### Changed
-+
-+- Updated command instructions in the CLI.
-+- Cleaned up the code to not render agent-specific information when it's generic.
-+
-+
-+## [0.0.6] - 2025-09-17
-+
-+### Added
-+
-+- opencode support as additional AI assistant option
-+
-+## [0.0.5] - 2025-09-17
-+
-+### Added
-+
-+- Qwen Code support as additional AI assistant option
- 
- ## [0.0.4] - 2025-09-14
- 
-@@ -19,4 +115,4 @@ N/A
- 
- ### Changed
- 
--N/A
-\ No newline at end of file
-+N/A
-diff --git a/CONTRIBUTING.md b/CONTRIBUTING.md
-index 0b1cbd7..17baec8 100644
---- a/CONTRIBUTING.md
-+++ b/CONTRIBUTING.md
-@@ -11,7 +11,7 @@ These are one time installations required to be able to test your changes locall
- 1. Install [Python 3.11+](https://www.python.org/downloads/)
- 1. Install [uv](https://docs.astral.sh/uv/) for package management
- 1. Install [Git](https://git-scm.com/downloads)
--1. Have an AI coding agent available: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), or [Gemini CLI](https://github.com/google-gemini/gemini-cli) are recommended, but we're working on adding support for other agents as well.
-+1. Have an [AI coding agent available](README.md#-supported-ai-agents)
- 
- ## Submitting a pull request
- 
-@@ -31,7 +31,7 @@ Here are a few things you can do that will increase the likelihood of your pull
- 
- - Follow the project's coding conventions.
- - Write tests for new functionality.
--- Update documentation (`README.md,` `spec-driven.md`) if your changes affect user-facing features.
-+- Update documentation (`README.md`, `spec-driven.md`) if your changes affect user-facing features.
- - Keep your change as focused as possible. If there are multiple changes you would like to make that are not dependent upon each other, consider submitting them as separate pull requests.
- - Write a [good commit message](http://tbaggery.com/2008/04/19/a-note-about-git-commit-messages.html).
- - Test your changes with the Spec-Driven Development workflow to ensure compatibility.
-@@ -45,6 +45,33 @@ When working on spec-kit:
- 3. Test script functionality in the `scripts/` directory
- 4. Ensure memory files (`memory/constitution.md`) are updated if major process changes are made
- 
-+## AI contributions in Spec Kit
-+
-+We welcome and encourage the use of AI tools to help improve Spec Kit! Many valuable contributions have been enhanced with AI assistance for code generation, issue detection, and feature definition.
-+
-+### What we're looking for
-+
-+When submitting AI-assisted contributions, please ensure they include:
-+
-+- **Human understanding and testing** - You've personally tested the changes and understand what they do
-+- **Clear rationale** - You can explain why the change is needed and how it fits within Spec Kit's goals  
-+- **Concrete evidence** - Include test cases, scenarios, or examples that demonstrate the improvement
-+- **Your own analysis** - Share your thoughts on the end-to-end developer experience
-+
-+### What we'll close
-+
-+We reserve the right to close contributions that appear to be:
-+
-+- Untested changes submitted without verification
-+- Generic suggestions that don't address specific Spec Kit needs
-+- Bulk submissions that show no human review or understanding
-+
-+### Guidelines for success
-+
-+The key is demonstrating that you understand and have validated your proposed changes. If a maintainer can easily tell that a contribution was generated entirely by AI without human input or testing, it likely needs more work before submission.
-+
-+Contributors who consistently submit low-effort AI-generated changes may be restricted from further contributions at the maintainers' discretion.
-+
- ## Resources
- 
- - [Spec-Driven Development Methodology](./spec-driven.md)
-diff --git a/README.md b/README.md
-index a919545..226da68 100644
---- a/README.md
-+++ b/README.md
-@@ -17,6 +17,7 @@
- - [🤔 What is Spec-Driven Development?](#-what-is-spec-driven-development)
- - [⚡ Get started](#-get-started)
- - [📽️ Video Overview](#️-video-overview)
-+- [🤖 Supported AI Agents](#-supported-ai-agents)
- - [🔧 Specify CLI Reference](#-specify-cli-reference)
- - [📚 Core philosophy](#-core-philosophy)
- - [🌟 Development phases](#-development-phases)
-@@ -38,13 +39,47 @@ Spec-Driven Development **flips the script** on traditional software development
- 
- ### 1. Install Specify
- 
--Initialize your project depending on the coding agent you're using:
-+Choose your preferred installation method:
-+
-+#### Option 1: Persistent Installation (Recommended)
-+
-+Install once and use everywhere:
-+
-+```bash
-+uv tool install specify-cli --from git+https://github.com/github/spec-kit.git
-+```
-+
-+Then use the tool directly:
-+
-+```bash
-+specify init <PROJECT_NAME>
-+specify check
-+```
-+
-+#### Option 2: One-time Usage
-+
-+Run directly without installing:
- 
- ```bash
- uvx --from git+https://github.com/github/spec-kit.git specify init <PROJECT_NAME>
- ```
- 
--### 2. Create the spec
-+**Benefits of persistent installation:**
-+
-+- Tool stays installed and available in PATH
-+- No need to create shell aliases
-+- Better tool management with `uv tool list`, `uv tool upgrade`, `uv tool uninstall`
-+- Cleaner shell configuration
-+
-+### 2. Establish project principles
-+
-+Use the **`/constitution`** command to create your project's governing principles and development guidelines that will guide all subsequent development.
-+
-+```bash
-+/constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements
-+```
-+
-+### 3. Create the spec
- 
- Use the **`/specify`** command to describe what you want to build. Focus on the **what** and **why**, not the tech stack.
- 
-@@ -52,7 +87,7 @@ Use the **`/specify`** command to describe what you want to build. Focus on the
- /specify Build an application that can help me organize my photos in separate photo albums. Albums are grouped by date and can be re-organized by dragging and dropping on the main page. Albums are never in other nested albums. Within each album, photos are previewed in a tile-like interface.
- ```
- 
--### 3. Create a technical implementation plan
-+### 4. Create a technical implementation plan
- 
- Use the **`/plan`** command to provide your tech stack and architecture choices.
- 
-@@ -60,9 +95,21 @@ Use the **`/plan`** command to provide your tech stack and architecture choices.
- /plan The application uses Vite with minimal number of libraries. Use vanilla HTML, CSS, and JavaScript as much as possible. Images are not uploaded anywhere and metadata is stored in a local SQLite database.
- ```
- 
--### 4. Break down and implement
-+### 5. Break down into tasks
-+
-+Use **`/tasks`** to create an actionable task list from your implementation plan.
-+
-+```bash
-+/tasks
-+```
-+
-+### 6. Execute implementation
- 
--Use **`/tasks`** to create an actionable task list, then ask your agent to implement the feature.
-+Use **`/implement`** to execute all tasks and build your feature according to the plan.
-+
-+```bash
-+/implement
-+```
- 
- For detailed step-by-step instructions, see our [comprehensive guide](./spec-driven.md).
- 
-@@ -72,6 +119,22 @@ Want to see Spec Kit in action? Watch our [video overview](https://www.youtube.c
- 
- [![Spec Kit video header](/media/spec-kit-video-header.jpg)](https://www.youtube.com/watch?v=a9eR1xsfvHg&pp=0gcJCckJAYcqIYzv)
- 
-+## 🤖 Supported AI Agents
-+
-+| Agent                                                     | Support | Notes                                             |
-+|-----------------------------------------------------------|---------|---------------------------------------------------|
-+| [Claude Code](https://www.anthropic.com/claude-code)      | ✅ |                                                   |
-+| [GitHub Copilot](https://code.visualstudio.com/)          | ✅ |                                                   |
-+| [Gemini CLI](https://github.com/google-gemini/gemini-cli) | ✅ |                                                   |
-+| [Cursor](https://cursor.sh/)                              | ✅ |                                                   |
-+| [Qwen Code](https://github.com/QwenLM/qwen-code)          | ✅ |                                                   |
-+| [opencode](https://opencode.ai/)                          | ✅ |                                                   |
-+| [Windsurf](https://windsurf.com/)                         | ✅ |                                                   |
-+| [Kilo Code](https://github.com/Kilo-Org/kilocode)         | ✅ |                                                   |
-+| [Auggie CLI](https://docs.augmentcode.com/cli/overview)   | ✅ |                                                   |
-+| [Roo Code](https://roocode.com/)                          | ✅ |                                                   |
-+| [Codex CLI](https://github.com/openai/codex)              | ⚠️ | Codex [does not support](https://github.com/openai/codex/issues/2890) custom arguments for slash commands.  |
-+
- ## 🔧 Specify CLI Reference
- 
- The `specify` command supports the following options:
-@@ -81,20 +144,22 @@ The `specify` command supports the following options:
- | Command     | Description                                                    |
- |-------------|----------------------------------------------------------------|
- | `init`      | Initialize a new Specify project from the latest template      |
--| `check`     | Check for installed tools (`git`, `claude`, `gemini`, `code`/`code-insiders`, `cursor-agent`) |
-+| `check`     | Check for installed tools (`git`, `claude`, `gemini`, `code`/`code-insiders`, `cursor-agent`, `windsurf`, `qwen`, `opencode`, `codex`) |
- 
- ### `specify init` Arguments & Options
- 
- | Argument/Option        | Type     | Description                                                                  |
- |------------------------|----------|------------------------------------------------------------------------------|
- | `<project-name>`       | Argument | Name for your new project directory (optional if using `--here`)            |
--| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, or `cursor`             |
-+| `--ai`                 | Option   | AI assistant to use: `claude`, `gemini`, `copilot`, `cursor`, `qwen`, `opencode`, `codex`, `windsurf`, `kilocode`, `auggie`, or `roo` |
- | `--script`             | Option   | Script variant to use: `sh` (bash/zsh) or `ps` (PowerShell)                 |
- | `--ignore-agent-tools` | Flag     | Skip checks for AI agent tools like Claude Code                             |
- | `--no-git`             | Flag     | Skip git repository initialization                                          |
- | `--here`               | Flag     | Initialize project in the current directory instead of creating a new one   |
-+| `--force`              | Flag     | Force merge/overwrite when using `--here` in a non-empty directory (skip confirmation) |
- | `--skip-tls`           | Flag     | Skip SSL/TLS verification (not recommended)                                 |
- | `--debug`              | Flag     | Enable detailed debug output for troubleshooting                            |
-+| `--github-token`       | Option   | GitHub token for API requests (or set GH_TOKEN/GITHUB_TOKEN env variable)  |
- 
- ### Examples
- 
-@@ -108,22 +173,51 @@ specify init my-project --ai claude
- # Initialize with Cursor support
- specify init my-project --ai cursor
- 
-+# Initialize with Windsurf support
-+specify init my-project --ai windsurf
-+
- # Initialize with PowerShell scripts (Windows/cross-platform)
- specify init my-project --ai copilot --script ps
- 
- # Initialize in current directory
- specify init --here --ai copilot
- 
-+# Force merge into current (non-empty) directory without confirmation
-+specify init --here --force --ai copilot
-+
- # Skip git initialization
- specify init my-project --ai gemini --no-git
- 
- # Enable debug output for troubleshooting
- specify init my-project --ai claude --debug
- 
-+# Use GitHub token for API requests (helpful for corporate environments)
-+specify init my-project --ai claude --github-token ghp_your_token_here
-+
- # Check system requirements
- specify check
- ```
- 
-+### Available Slash Commands
-+
-+After running `specify init`, your AI coding agent will have access to these slash commands for structured development:
-+
-+| Command         | Description                                                           |
-+|-----------------|-----------------------------------------------------------------------|
-+| `/constitution` | Create or update project governing principles and development guidelines |
-+| `/specify`      | Define what you want to build (requirements and user stories)        |
-+| `/clarify`      | Clarify underspecified areas (must be run before `/plan` unless explicitly skipped; formerly `/quizme`) |
-+| `/plan`         | Create technical implementation plans with your chosen tech stack     |
-+| `/tasks`        | Generate actionable task lists for implementation                     |
-+| `/analyze`      | Cross-artifact consistency & coverage analysis (run after /tasks, before /implement) |
-+| `/implement`    | Execute all tasks to build the feature according to the plan         |
-+
-+### Environment Variables
-+
-+| Variable         | Description                                                                                    |
-+|------------------|------------------------------------------------------------------------------------------------|
-+| `SPECIFY_FEATURE` | Override feature detection for non-Git repositories. Set to the feature directory name (e.g., `001-photo-albums`) to work on a specific feature when not using Git branches.<br/>**Must be set in the context of the agent you're working with prior to using `/plan` or follow-up commands. |
-+
- ## 📚 Core philosophy
- 
- Spec-Driven Development is a structured process that emphasizes:
-@@ -170,11 +264,13 @@ Our research and experimentation focus on:
- ## 🔧 Prerequisites
- 
- - **Linux/macOS** (or WSL2 on Windows)
--- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), [Gemini CLI](https://github.com/google-gemini/gemini-cli), or [Cursor](https://cursor.sh/)
-+- AI coding agent: [Claude Code](https://www.anthropic.com/claude-code), [GitHub Copilot](https://code.visualstudio.com/), [Gemini CLI](https://github.com/google-gemini/gemini-cli), [Cursor](https://cursor.sh/), [Qwen CLI](https://github.com/QwenLM/qwen-code), [opencode](https://opencode.ai/), [Codex CLI](https://github.com/openai/codex), or [Windsurf](https://windsurf.com/)
- - [uv](https://docs.astral.sh/uv/) for package management
- - [Python 3.11+](https://www.python.org/downloads/)
- - [Git](https://git-scm.com/downloads)
- 
-+If you encounter issues with an agent, please open an issue so we can refine the integration.
-+
- ## 📖 Learn more
- 
- - **[Complete Spec-Driven Development Methodology](./spec-driven.md)** - Deep dive into the full process
-@@ -197,6 +293,8 @@ Or initialize in the current directory:
- 
- ```bash
- specify init --here
-+# Skip confirmation when the directory already has files
-+specify init --here --force
- ```
- 
- ![Specify CLI bootstrapping a new project in the terminal](./media/specify_cli.gif)
-@@ -207,25 +305,43 @@ You will be prompted to select the AI agent you are using. You can also proactiv
- specify init <project_name> --ai claude
- specify init <project_name> --ai gemini
- specify init <project_name> --ai copilot
-+specify init <project_name> --ai cursor
-+specify init <project_name> --ai qwen
-+specify init <project_name> --ai opencode
-+specify init <project_name> --ai codex
-+specify init <project_name> --ai windsurf
- # Or in current directory:
- specify init --here --ai claude
-+specify init --here --ai codex
-+# Force merge into a non-empty current directory
-+specify init --here --force --ai claude
- ```
- 
--The CLI will check if you have Claude Code or Gemini CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:
-+The CLI will check if you have Claude Code, Gemini CLI, Cursor CLI, Qwen CLI, opencode, or Codex CLI installed. If you do not, or you prefer to get the templates without checking for the right tools, use `--ignore-agent-tools` with your command:
- 
- ```bash
- specify init <project_name> --ai claude --ignore-agent-tools
- ```
- 
--### **STEP 1:** Bootstrap the project
-+### **STEP 1:** Establish project principles
- 
- Go to the project folder and run your AI agent. In our example, we're using `claude`.
- 
- ![Bootstrapping Claude Code environment](./media/bootstrap-claude-code.gif)
- 
--You will know that things are configured correctly if you see the `/specify`, `/plan`, and `/tasks` commands available.
-+You will know that things are configured correctly if you see the `/constitution`, `/specify`, `/plan`, `/tasks`, and `/implement` commands available.
-+
-+The first step should be establishing your project's governing principles using the `/constitution` command. This helps ensure consistent decision-making throughout all subsequent development phases:
-+
-+```text
-+/constitution Create principles focused on code quality, testing standards, user experience consistency, and performance requirements. Include governance for how these principles should guide technical decisions and implementation choices.
-+```
-+
-+This step creates or updates the `/memory/constitution.md` file with your project's foundational guidelines that the AI agent will reference during specification, planning, and implementation phases.
- 
--The first step should be creating a new project scaffolding. Use `/specify` command and then provide the concrete requirements for the project you want to develop.
-+### **STEP 2:** Create project specifications
-+
-+With your project principles established, you can now create the functional specifications. Use the `/specify` command and then provide the concrete requirements for the project you want to develop.
- 
- >[!IMPORTANT]
- >Be as explicit as possible about _what_ you are trying to build and _why_. **Do not focus on the tech stack at this point**.
-@@ -261,13 +377,11 @@ At this stage, your project folder contents should resemble the following:
- 
- ```text
- ├── memory
--│	 ├── constitution.md
--│	 └── constitution_update_checklist.md
-+│	 └── constitution.md
- ├── scripts
--│	 ├── check-task-prerequisites.sh
-+│	 ├── check-prerequisites.sh
- │	 ├── common.sh
- │	 ├── create-new-feature.sh
--│	 ├── get-feature-paths.sh
- │	 ├── setup-plan.sh
- │	 └── update-claude-md.sh
- ├── specs
-@@ -279,9 +393,19 @@ At this stage, your project folder contents should resemble the following:
-     └── tasks-template.md
- ```
- 
--### **STEP 2:** Functional specification clarification
-+### **STEP 3:** Functional specification clarification (required before planning)
-+
-+With the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt.
-+
-+You should run the structured clarification workflow **before** creating a technical plan to reduce rework downstream.
-+
-+Preferred order:
-+1. Use `/clarify` (structured) – sequential, coverage-based questioning that records answers in a Clarifications section.
-+2. Optionally follow up with ad-hoc free-form refinement if something still feels vague.
-+
-+If you intentionally want to skip clarification (e.g., spike or exploratory prototype), explicitly state that so the agent doesn't block on missing clarifications.
- 
--With the baseline specification created, you can go ahead and clarify any of the requirements that were not captured properly within the first shot attempt. For example, you could use a prompt like this within the same Claude Code session:
-+Example free-form refinement prompt (after `/clarify` if still needed):
- 
- ```text
- For each sample project or project that you create there should be a variable number of tasks between 5 and 15
-@@ -297,7 +421,7 @@ Read the review and acceptance checklist, and check off each item in the checkli
- 
- It's important to use the interaction with Claude Code as an opportunity to clarify and ask questions around the specification - **do not treat its first attempt as final**.
- 
--### **STEP 3:** Generate a plan
-+### **STEP 4:** Generate a plan
- 
- You can now be specific about the tech stack and other technical requirements. You can use the `/plan` command that is built into the project template with a prompt like this:
- 
-@@ -313,13 +437,11 @@ The output of this step will include a number of implementation detail documents
- .
- ├── CLAUDE.md
- ├── memory
--│	 ├── constitution.md
--│	 └── constitution_update_checklist.md
-+│	 └── constitution.md
- ├── scripts
--│	 ├── check-task-prerequisites.sh
-+│	 ├── check-prerequisites.sh
- │	 ├── common.sh
- │	 ├── create-new-feature.sh
--│	 ├── get-feature-paths.sh
- │	 ├── setup-plan.sh
- │	 └── update-claude-md.sh
- ├── specs
-@@ -366,7 +488,7 @@ That's way too untargeted research. The research needs to help you solve a speci
- >[!NOTE]
- >Claude Code might be over-eager and add components that you did not ask for. Ask it to clarify the rationale and the source of the change.
- 
--### **STEP 4:** Have Claude Code validate the plan
-+### **STEP 5:** Have Claude Code validate the plan
- 
- With the plan in place, you should have Claude Code run through it to make sure that there are no missing pieces. You can use a prompt like this:
- 
-@@ -385,20 +507,25 @@ You can also ask Claude Code (if you have the [GitHub CLI](https://docs.github.c
- >[!NOTE]
- >Before you have the agent implement it, it's also worth prompting Claude Code to cross-check the details to see if there are any over-engineered pieces (remember - it can be over-eager). If over-engineered components or decisions exist, you can ask Claude Code to resolve them. Ensure that Claude Code follows the [constitution](base/memory/constitution.md) as the foundational piece that it must adhere to when establishing the plan.
- 
--### STEP 5: Implementation
-+### STEP 6: Implementation
- 
--Once ready, instruct Claude Code to implement your solution (example path included):
-+Once ready, use the `/implement` command to execute your implementation plan:
- 
- ```text
--implement specs/002-create-taskify/plan.md
-+/implement
- ```
- 
--Claude Code will spring into action and will start creating the implementation.
-+The `/implement` command will:
-+- Validate that all prerequisites are in place (constitution, spec, plan, and tasks)
-+- Parse the task breakdown from `tasks.md`
-+- Execute tasks in the correct order, respecting dependencies and parallel execution markers
-+- Follow the TDD approach defined in your task plan
-+- Provide progress updates and handle errors appropriately
- 
- >[!IMPORTANT]
-->Claude Code will execute local CLI commands (such as `dotnet`) - make sure you have them installed on your machine.
-+>The AI agent will execute local CLI commands (such as `dotnet`, `npm`, etc.) - make sure you have the required tools installed on your machine.
- 
--Once the implementation step is done, ask Claude Code to try to run the application and resolve any emerging build errors. If the application runs, but there are _runtime errors_ that are not directly available to Claude Code through CLI logs (e.g., errors rendered in browser logs), copy and paste the error in Claude Code and have it attempt to resolve it.
-+Once the implementation is complete, test the application and resolve any runtime errors that may not be visible in CLI logs (e.g., browser console errors). You can copy and paste such errors back to your AI agent for resolution.
- 
- </details>
- 
-diff --git a/memory/constitution_update_checklist.md b/memory/constitution_update_checklist.md
-deleted file mode 100644
-index 7f15d7f..0000000
---- a/memory/constitution_update_checklist.md
-+++ /dev/null
-@@ -1,85 +0,0 @@
--# Constitution Update Checklist
--
--When amending the constitution (`/memory/constitution.md`), ensure all dependent documents are updated to maintain consistency.
--
--## Templates to Update
--
--### When adding/modifying ANY article:
--- [ ] `/templates/plan-template.md` - Update Constitution Check section
--- [ ] `/templates/spec-template.md` - Update if requirements/scope affected
--- [ ] `/templates/tasks-template.md` - Update if new task types needed
--- [ ] `/.claude/commands/plan.md` - Update if planning process changes
--- [ ] `/.claude/commands/tasks.md` - Update if task generation affected
--- [ ] `/CLAUDE.md` - Update runtime development guidelines
--
--### Article-specific updates:
--
--#### Article I (Library-First):
--- [ ] Ensure templates emphasize library creation
--- [ ] Update CLI command examples
--- [ ] Add llms.txt documentation requirements
--
--#### Article II (CLI Interface):
--- [ ] Update CLI flag requirements in templates
--- [ ] Add text I/O protocol reminders
--
--#### Article III (Test-First):
--- [ ] Update test order in all templates
--- [ ] Emphasize TDD requirements
--- [ ] Add test approval gates
--
--#### Article IV (Integration Testing):
--- [ ] List integration test triggers
--- [ ] Update test type priorities
--- [ ] Add real dependency requirements
--
--#### Article V (Observability):
--- [ ] Add logging requirements to templates
--- [ ] Include multi-tier log streaming
--- [ ] Update performance monitoring sections
--
--#### Article VI (Versioning):
--- [ ] Add version increment reminders
--- [ ] Include breaking change procedures
--- [ ] Update migration requirements
--
--#### Article VII (Simplicity):
--- [ ] Update project count limits
--- [ ] Add pattern prohibition examples
--- [ ] Include YAGNI reminders
--
--## Validation Steps
--
--1. **Before committing constitution changes:**
--   - [ ] All templates reference new requirements
--   - [ ] Examples updated to match new rules
--   - [ ] No contradictions between documents
--
--2. **After updating templates:**
--   - [ ] Run through a sample implementation plan
--   - [ ] Verify all constitution requirements addressed
--   - [ ] Check that templates are self-contained (readable without constitution)
--
--3. **Version tracking:**
--   - [ ] Update constitution version number
--   - [ ] Note version in template footers
--   - [ ] Add amendment to constitution history
--
--## Common Misses
--
--Watch for these often-forgotten updates:
--- Command documentation (`/commands/*.md`)
--- Checklist items in templates
--- Example code/commands
--- Domain-specific variations (web vs mobile vs CLI)
--- Cross-references between documents
--
--## Template Sync Status
--
--Last sync check: 2025-07-16
--- Constitution version: 2.1.1
--- Templates aligned: ❌ (missing versioning, observability details)
--
-----
--
--*This checklist ensures the constitution's principles are consistently applied across all project documentation.*
-\ No newline at end of file
-diff --git a/pyproject.toml b/pyproject.toml
-index 7eeeb52..559bad2 100644
---- a/pyproject.toml
-+++ b/pyproject.toml
-@@ -1,7 +1,7 @@
- [project]
- name = "specify-cli"
--version = "0.0.4"
--description = "Setup tool for Specify spec-driven development projects"
-+version = "0.0.17"
-+description = "Specify CLI, part of GitHub Spec Kit. A tool to bootstrap your projects for Spec-Driven Development (SDD)."
- requires-python = ">=3.11"
- dependencies = [
-     "typer",
-diff --git a/scripts/bash/check-prerequisites.sh b/scripts/bash/check-prerequisites.sh
-new file mode 100644
-index 0000000..f32b624
---- /dev/null
-+++ b/scripts/bash/check-prerequisites.sh
-@@ -0,0 +1,166 @@
-+#!/usr/bin/env bash
-+
-+# Consolidated prerequisite checking script
-+#
-+# This script provides unified prerequisite checking for Spec-Driven Development workflow.
-+# It replaces the functionality previously spread across multiple scripts.
-+#
-+# Usage: ./check-prerequisites.sh [OPTIONS]
-+#
-+# OPTIONS:
-+#   --json              Output in JSON format
-+#   --require-tasks     Require tasks.md to exist (for implementation phase)
-+#   --include-tasks     Include tasks.md in AVAILABLE_DOCS list
-+#   --paths-only        Only output path variables (no validation)
-+#   --help, -h          Show help message
-+#
-+# OUTPUTS:
-+#   JSON mode: {"FEATURE_DIR":"...", "AVAILABLE_DOCS":["..."]}
-+#   Text mode: FEATURE_DIR:... \n AVAILABLE_DOCS: \n ✓/✗ file.md
-+#   Paths only: REPO_ROOT: ... \n BRANCH: ... \n FEATURE_DIR: ... etc.
-+
-+set -e
-+
-+# Parse command line arguments
-+JSON_MODE=false
-+REQUIRE_TASKS=false
-+INCLUDE_TASKS=false
-+PATHS_ONLY=false
-+
-+for arg in "$@"; do
-+    case "$arg" in
-+        --json)
-+            JSON_MODE=true
-+            ;;
-+        --require-tasks)
-+            REQUIRE_TASKS=true
-+            ;;
-+        --include-tasks)
-+            INCLUDE_TASKS=true
-+            ;;
-+        --paths-only)
-+            PATHS_ONLY=true
-+            ;;
-+        --help|-h)
-+            cat << 'EOF'
-+Usage: check-prerequisites.sh [OPTIONS]
-+
-+Consolidated prerequisite checking for Spec-Driven Development workflow.
-+
-+OPTIONS:
-+  --json              Output in JSON format
-+  --require-tasks     Require tasks.md to exist (for implementation phase)
-+  --include-tasks     Include tasks.md in AVAILABLE_DOCS list
-+  --paths-only        Only output path variables (no prerequisite validation)
-+  --help, -h          Show this help message
-+
-+EXAMPLES:
-+  # Check task prerequisites (plan.md required)
-+  ./check-prerequisites.sh --json
-+  
-+  # Check implementation prerequisites (plan.md + tasks.md required)
-+  ./check-prerequisites.sh --json --require-tasks --include-tasks
-+  
-+  # Get feature paths only (no validation)
-+  ./check-prerequisites.sh --paths-only
-+  
-+EOF
-+            exit 0
-+            ;;
-+        *)
-+            echo "ERROR: Unknown option '$arg'. Use --help for usage information." >&2
-+            exit 1
-+            ;;
-+    esac
-+done
-+
-+# Source common functions
-+SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
-+source "$SCRIPT_DIR/common.sh"
-+
-+# Get feature paths and validate branch
-+eval $(get_feature_paths)
-+check_feature_branch "$CURRENT_BRANCH" "$HAS_GIT" || exit 1
-+
-+# If paths-only mode, output paths and exit (support JSON + paths-only combined)
-+if $PATHS_ONLY; then
-+    if $JSON_MODE; then
-+        # Minimal JSON paths payload (no validation performed)
-+        printf '{"REPO_ROOT":"%s","BRANCH":"%s","FEATURE_DIR":"%s","FEATURE_SPEC":"%s","IMPL_PLAN":"%s","TASKS":"%s"}\n' \
-+            "$REPO_ROOT" "$CURRENT_BRANCH" "$FEATURE_DIR" "$FEATURE_SPEC" "$IMPL_PLAN" "$TASKS"
-+    else
-+        echo "REPO_ROOT: $REPO_ROOT"
-+        echo "BRANCH: $CURRENT_BRANCH"
-+        echo "FEATURE_DIR: $FEATURE_DIR"
-+        echo "FEATURE_SPEC: $FEATURE_SPEC"
-+        echo "IMPL_PLAN: $IMPL_PLAN"
-+        echo "TASKS: $TASKS"
-+    fi
-+    exit 0
-+fi
-+
-+# Validate required directories and files
-+if [[ ! -d "$FEATURE_DIR" ]]; then
-+    echo "ERROR: Feature directory not found: $FEATURE_DIR" >&2
-+    echo "Run /specify first to create the feature structure." >&2
-+    exit 1
-+fi
-+
-+if [[ ! -f "$IMPL_PLAN" ]]; then
-+    echo "ERROR: plan.md not found in $FEATURE_DIR" >&2
-+    echo "Run /plan first to create the implementation plan." >&2
-+    exit 1
-+fi
-+
-+# Check for tasks.md if required
-+if $REQUIRE_TASKS && [[ ! -f "$TASKS" ]]; then
-+    echo "ERROR: tasks.md not found in $FEATURE_DIR" >&2
-+    echo "Run /tasks first to create the task list." >&2
-+    exit 1
-+fi
-+
-+# Build list of available documents
-+docs=()
-+
-+# Always check these optional docs
-+[[ -f "$RESEARCH" ]] && docs+=("research.md")
-+[[ -f "$DATA_MODEL" ]] && docs+=("data-model.md")
-+
-+# Check contracts directory (only if it exists and has files)
-+if [[ -d "$CONTRACTS_DIR" ]] && [[ -n "$(ls -A "$CONTRACTS_DIR" 2>/dev/null)" ]]; then
-+    docs+=("contracts/")
-+fi
-+
-+[[ -f "$QUICKSTART" ]] && docs+=("quickstart.md")
-+
-+# Include tasks.md if requested and it exists
-+if $INCLUDE_TASKS && [[ -f "$TASKS" ]]; then
-+    docs+=("tasks.md")
-+fi
-+
-+# Output results
-+if $JSON_MODE; then
-+    # Build JSON array of documents
-+    if [[ ${#docs[@]} -eq 0 ]]; then
-+        json_docs="[]"
-+    else
-+        json_docs=$(printf '"%s",' "${docs[@]}")
-+        json_docs="[${json_docs%,}]"
-+    fi
-+    
-+    printf '{"FEATURE_DIR":"%s","AVAILABLE_DOCS":%s}\n' "$FEATURE_DIR" "$json_docs"
-+else
-+    # Text output
-+    echo "FEATURE_DIR:$FEATURE_DIR"
-+    echo "AVAILABLE_DOCS:"
-+    
-+    # Show status of each potential document
-+    check_file "$RESEARCH" "research.md"
-+    check_file "$DATA_MODEL" "data-model.md"
-+    check_dir "$CONTRACTS_DIR" "contracts/"
-+    check_file "$QUICKSTART" "quickstart.md"
-+    
-+    if $INCLUDE_TASKS; then
-+        check_file "$TASKS" "tasks.md"
-+    fi
-+fi
-\ No newline at end of file
-diff --git a/scripts/bash/check-task-prerequisites.sh b/scripts/bash/check-task-prerequisites.sh
-deleted file mode 100644
-index e578f86..0000000
---- a/scripts/bash/check-task-prerequisites.sh
-+++ /dev/null
-@@ -1,15 +0,0 @@
--#!/usr/bin/env bash
--set -e
--JSON_MODE=false
--for arg in "$@"; do case "$arg" in --json) JSON_MODE=true ;; --help|-h) echo "Usage: $0 [--json]"; exit 0 ;; esac; done
--SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
--source "$SCRIPT_DIR/common.sh"
--eval $(get_feature_paths)
--check_feature_branch "$CURRENT_BRANCH" || exit 1
--if [[ ! -d "$FEATURE_DIR" ]]; then echo "ERROR: Feature directory not found: $FEATURE_DIR"; echo "Run /specify first."; exit 1; fi
--if [[ ! -f "$IMPL_PLAN" ]]; then echo "ERROR: plan.md not found in $FEATURE_DIR"; echo "Run /plan first."; exit 1; fi
--if $JSON_MODE; then
--  docs=(); [[ -f "$RESEARCH" ]] && docs+=("research.md"); [[ -f "$DATA_MODEL" ]] && docs+=("data-model.md"); ([[ -d "$CONTRACTS_DIR" ]] && [[ -n "$(ls -A "$CONTRACTS_DIR" 2>/dev/null)" ]]) && docs+=("contracts/"); [[ -f "$QUICKSTART" ]] && docs+=("quickstart.md");
--  json_docs=$(printf '"%s",' "${docs[@]}"); json_docs="[${json_docs%,}]"; printf '{"FEATURE_DIR":"%s","AVAILABLE_DOCS":%s}\n' "$FEATURE_DIR" "$json_docs"
--else
--  echo "FEATURE_DIR:$FEATURE_DIR"; echo "AVAILABLE_DOCS:"; check_file "$RESEARCH" "research.md"; check_file "$DATA_MODEL" "data-model.md"; check_dir "$CONTRACTS_DIR" "contracts/"; check_file "$QUICKSTART" "quickstart.md"; fi
-diff --git a/scripts/bash/common.sh b/scripts/bash/common.sh
-index 582d940..34e5d4b 100644
---- a/scripts/bash/common.sh
-+++ b/scripts/bash/common.sh
-@@ -1,16 +1,84 @@
- #!/usr/bin/env bash
--# (Moved to scripts/bash/) Common functions and variables for all scripts
-+# Common functions and variables for all scripts
- 
--get_repo_root() { git rev-parse --show-toplevel; }
--get_current_branch() { git rev-parse --abbrev-ref HEAD; }
-+# Get repository root, with fallback for non-git repositories
-+get_repo_root() {
-+    if git rev-parse --show-toplevel >/dev/null 2>&1; then
-+        git rev-parse --show-toplevel
-+    else
-+        # Fall back to script location for non-git repos
-+        local script_dir="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
-+        (cd "$script_dir/../../.." && pwd)
-+    fi
-+}
-+
-+# Get current branch, with fallback for non-git repositories
-+get_current_branch() {
-+    # First check if SPECIFY_FEATURE environment variable is set
-+    if [[ -n "${SPECIFY_FEATURE:-}" ]]; then
-+        echo "$SPECIFY_FEATURE"
-+        return
-+    fi
-+    
-+    # Then check git if available
-+    if git rev-parse --abbrev-ref HEAD >/dev/null 2>&1; then
-+        git rev-parse --abbrev-ref HEAD
-+        return
-+    fi
-+    
-+    # For non-git repos, try to find the latest feature directory
-+    local repo_root=$(get_repo_root)
-+    local specs_dir="$repo_root/specs"
-+    
-+    if [[ -d "$specs_dir" ]]; then
-+        local latest_feature=""
-+        local highest=0
-+        
-+        for dir in "$specs_dir"/*; do
-+            if [[ -d "$dir" ]]; then
-+                local dirname=$(basename "$dir")
-+                if [[ "$dirname" =~ ^([0-9]{3})- ]]; then
-+                    local number=${BASH_REMATCH[1]}
-+                    number=$((10#$number))
-+                    if [[ "$number" -gt "$highest" ]]; then
-+                        highest=$number
-+                        latest_feature=$dirname
-+                    fi
-+                fi
-+            fi
-+        done
-+        
-+        if [[ -n "$latest_feature" ]]; then
-+            echo "$latest_feature"
-+            return
-+        fi
-+    fi
-+    
-+    echo "main"  # Final fallback
-+}
-+
-+# Check if we have git available
-+has_git() {
-+    git rev-parse --show-toplevel >/dev/null 2>&1
-+}
- 
- check_feature_branch() {
-     local branch="$1"
-+    local has_git_repo="$2"
-+    
-+    # For non-git repos, we can't enforce branch naming but still provide output
-+    if [[ "$has_git_repo" != "true" ]]; then
-+        echo "[specify] Warning: Git repository not detected; skipped branch validation" >&2
-+        return 0
-+    fi
-+    
-     if [[ ! "$branch" =~ ^[0-9]{3}- ]]; then
-         echo "ERROR: Not on a feature branch. Current branch: $branch" >&2
-         echo "Feature branches should be named like: 001-feature-name" >&2
-         return 1
--    fi; return 0
-+    fi
-+    
-+    return 0
- }
- 
- get_feature_dir() { echo "$1/specs/$2"; }
-@@ -18,10 +86,18 @@ get_feature_dir() { echo "$1/specs/$2"; }
- get_feature_paths() {
-     local repo_root=$(get_repo_root)
-     local current_branch=$(get_current_branch)
-+    local has_git_repo="false"
-+    
-+    if has_git; then
-+        has_git_repo="true"
-+    fi
-+    
-     local feature_dir=$(get_feature_dir "$repo_root" "$current_branch")
-+    
-     cat <<EOF
- REPO_ROOT='$repo_root'
- CURRENT_BRANCH='$current_branch'
-+HAS_GIT='$has_git_repo'
- FEATURE_DIR='$feature_dir'
- FEATURE_SPEC='$feature_dir/spec.md'
- IMPL_PLAN='$feature_dir/plan.md'
-diff --git a/scripts/bash/create-new-feature.sh b/scripts/bash/create-new-feature.sh
-index bc4b406..5cb17fa 100644
---- a/scripts/bash/create-new-feature.sh
-+++ b/scripts/bash/create-new-feature.sh
-@@ -1,5 +1,5 @@
- #!/usr/bin/env bash
--# (Moved to scripts/bash/) Create a new feature with branch, directory structure, and template
-+
- set -e
- 
- JSON_MODE=false
-@@ -18,7 +18,38 @@ if [ -z "$FEATURE_DESCRIPTION" ]; then
-     exit 1
- fi
- 
--REPO_ROOT=$(git rev-parse --show-toplevel)
-+# Function to find the repository root by searching for existing project markers
-+find_repo_root() {
-+    local dir="$1"
-+    while [ "$dir" != "/" ]; do
-+        if [ -d "$dir/.git" ] || [ -d "$dir/.specify" ]; then
-+            echo "$dir"
-+            return 0
-+        fi
-+        dir="$(dirname "$dir")"
-+    done
-+    return 1
-+}
-+
-+# Resolve repository root. Prefer git information when available, but fall back
-+# to searching for repository markers so the workflow still functions in repositories that
-+# were initialised with --no-git.
-+SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
-+
-+if git rev-parse --show-toplevel >/dev/null 2>&1; then
-+    REPO_ROOT=$(git rev-parse --show-toplevel)
-+    HAS_GIT=true
-+else
-+    REPO_ROOT="$(find_repo_root "$SCRIPT_DIR")"
-+    if [ -z "$REPO_ROOT" ]; then
-+        echo "Error: Could not determine repository root. Please run this script from within the repository." >&2
-+        exit 1
-+    fi
-+    HAS_GIT=false
-+fi
-+
-+cd "$REPO_ROOT"
-+
- SPECS_DIR="$REPO_ROOT/specs"
- mkdir -p "$SPECS_DIR"
- 
-@@ -40,19 +71,27 @@ BRANCH_NAME=$(echo "$FEATURE_DESCRIPTION" | tr '[:upper:]' '[:lower:]' | sed 's/
- WORDS=$(echo "$BRANCH_NAME" | tr '-' '\n' | grep -v '^$' | head -3 | tr '\n' '-' | sed 's/-$//')
- BRANCH_NAME="${FEATURE_NUM}-${WORDS}"
- 
--git checkout -b "$BRANCH_NAME"
-+if [ "$HAS_GIT" = true ]; then
-+    git checkout -b "$BRANCH_NAME"
-+else
-+    >&2 echo "[specify] Warning: Git repository not detected; skipped branch creation for $BRANCH_NAME"
-+fi
- 
- FEATURE_DIR="$SPECS_DIR/$BRANCH_NAME"
- mkdir -p "$FEATURE_DIR"
- 
--TEMPLATE="$REPO_ROOT/templates/spec-template.md"
-+TEMPLATE="$REPO_ROOT/.specify/templates/spec-template.md"
- SPEC_FILE="$FEATURE_DIR/spec.md"
- if [ -f "$TEMPLATE" ]; then cp "$TEMPLATE" "$SPEC_FILE"; else touch "$SPEC_FILE"; fi
- 
-+# Set the SPECIFY_FEATURE environment variable for the current session
-+export SPECIFY_FEATURE="$BRANCH_NAME"
-+
- if $JSON_MODE; then
-     printf '{"BRANCH_NAME":"%s","SPEC_FILE":"%s","FEATURE_NUM":"%s"}\n' "$BRANCH_NAME" "$SPEC_FILE" "$FEATURE_NUM"
- else
-     echo "BRANCH_NAME: $BRANCH_NAME"
-     echo "SPEC_FILE: $SPEC_FILE"
-     echo "FEATURE_NUM: $FEATURE_NUM"
-+    echo "SPECIFY_FEATURE environment variable set to: $BRANCH_NAME"
- fi
-diff --git a/scripts/bash/get-feature-paths.sh b/scripts/bash/get-feature-paths.sh
-deleted file mode 100644
-index 016727d..0000000
---- a/scripts/bash/get-feature-paths.sh
-+++ /dev/null
-@@ -1,7 +0,0 @@
--#!/usr/bin/env bash
--set -e
--SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
--source "$SCRIPT_DIR/common.sh"
--eval $(get_feature_paths)
--check_feature_branch "$CURRENT_BRANCH" || exit 1
--echo "REPO_ROOT: $REPO_ROOT"; echo "BRANCH: $CURRENT_BRANCH"; echo "FEATURE_DIR: $FEATURE_DIR"; echo "FEATURE_SPEC: $FEATURE_SPEC"; echo "IMPL_PLAN: $IMPL_PLAN"; echo "TASKS: $TASKS"
-diff --git a/scripts/bash/setup-plan.sh b/scripts/bash/setup-plan.sh
-index 1da4265..654ba50 100644
---- a/scripts/bash/setup-plan.sh
-+++ b/scripts/bash/setup-plan.sh
-@@ -1,17 +1,60 @@
- #!/usr/bin/env bash
-+
- set -e
-+
-+# Parse command line arguments
- JSON_MODE=false
--for arg in "$@"; do case "$arg" in --json) JSON_MODE=true ;; --help|-h) echo "Usage: $0 [--json]"; exit 0 ;; esac; done
-+ARGS=()
-+
-+for arg in "$@"; do
-+    case "$arg" in
-+        --json) 
-+            JSON_MODE=true 
-+            ;;
-+        --help|-h) 
-+            echo "Usage: $0 [--json]"
-+            echo "  --json    Output results in JSON format"
-+            echo "  --help    Show this help message"
-+            exit 0 
-+            ;;
-+        *) 
-+            ARGS+=("$arg") 
-+            ;;
-+    esac
-+done
-+
-+# Get script directory and load common functions
- SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
- source "$SCRIPT_DIR/common.sh"
-+
-+# Get all paths and variables from common functions
- eval $(get_feature_paths)
--check_feature_branch "$CURRENT_BRANCH" || exit 1
-+
-+# Check if we're on a proper feature branch (only for git repos)
-+check_feature_branch "$CURRENT_BRANCH" "$HAS_GIT" || exit 1
-+
-+# Ensure the feature directory exists
- mkdir -p "$FEATURE_DIR"
-+
-+# Copy plan template if it exists
- TEMPLATE="$REPO_ROOT/.specify/templates/plan-template.md"
--[[ -f "$TEMPLATE" ]] && cp "$TEMPLATE" "$IMPL_PLAN"
-+if [[ -f "$TEMPLATE" ]]; then
-+    cp "$TEMPLATE" "$IMPL_PLAN"
-+    echo "Copied plan template to $IMPL_PLAN"
-+else
-+    echo "Warning: Plan template not found at $TEMPLATE"
-+    # Create a basic plan file if template doesn't exist
-+    touch "$IMPL_PLAN"
-+fi
-+
-+# Output results
- if $JSON_MODE; then
--  printf '{"FEATURE_SPEC":"%s","IMPL_PLAN":"%s","SPECS_DIR":"%s","BRANCH":"%s"}\n' \
--    "$FEATURE_SPEC" "$IMPL_PLAN" "$FEATURE_DIR" "$CURRENT_BRANCH"
-+    printf '{"FEATURE_SPEC":"%s","IMPL_PLAN":"%s","SPECS_DIR":"%s","BRANCH":"%s","HAS_GIT":"%s"}\n' \
-+        "$FEATURE_SPEC" "$IMPL_PLAN" "$FEATURE_DIR" "$CURRENT_BRANCH" "$HAS_GIT"
- else
--  echo "FEATURE_SPEC: $FEATURE_SPEC"; echo "IMPL_PLAN: $IMPL_PLAN"; echo "SPECS_DIR: $FEATURE_DIR"; echo "BRANCH: $CURRENT_BRANCH"
-+    echo "FEATURE_SPEC: $FEATURE_SPEC"
-+    echo "IMPL_PLAN: $IMPL_PLAN" 
-+    echo "SPECS_DIR: $FEATURE_DIR"
-+    echo "BRANCH: $CURRENT_BRANCH"
-+    echo "HAS_GIT: $HAS_GIT"
- fi
-diff --git a/scripts/bash/update-agent-context.sh b/scripts/bash/update-agent-context.sh
-index 2ad22cb..d3cc422 100644
---- a/scripts/bash/update-agent-context.sh
-+++ b/scripts/bash/update-agent-context.sh
-@@ -1,62 +1,719 @@
- #!/usr/bin/env bash
-+
-+# Update agent context files with information from plan.md
-+#
-+# This script maintains AI agent context files by parsing feature specifications 
-+# and updating agent-specific configuration files with project information.
-+#
-+# MAIN FUNCTIONS:
-+# 1. Environment Validation
-+#    - Verifies git repository structure and branch information
-+#    - Checks for required plan.md files and templates
-+#    - Validates file permissions and accessibility
-+#
-+# 2. Plan Data Extraction
-+#    - Parses plan.md files to extract project metadata
-+#    - Identifies language/version, frameworks, databases, and project types
-+#    - Handles missing or incomplete specification data gracefully
-+#
-+# 3. Agent File Management
-+#    - Creates new agent context files from templates when needed
-+#    - Updates existing agent files with new project information
-+#    - Preserves manual additions and custom configurations
-+#    - Supports multiple AI agent formats and directory structures
-+#
-+# 4. Content Generation
-+#    - Generates language-specific build/test commands
-+#    - Creates appropriate project directory structures
-+#    - Updates technology stacks and recent changes sections
-+#    - Maintains consistent formatting and timestamps
-+#
-+# 5. Multi-Agent Support
-+#    - Handles agent-specific file paths and naming conventions
-+#    - Supports: Claude, Gemini, Copilot, Cursor, Qwen, opencode, Codex, Windsurf
-+#    - Can update single agents or all existing agent files
-+#    - Creates default Claude file if no agent files exist
-+#
-+# Usage: ./update-agent-context.sh [agent_type]
-+# Agent types: claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf
-+# Leave empty to update all existing agent files
-+
- set -e
--REPO_ROOT=$(git rev-parse --show-toplevel)
--CURRENT_BRANCH=$(git rev-parse --abbrev-ref HEAD)
--FEATURE_DIR="$REPO_ROOT/specs/$CURRENT_BRANCH"
--NEW_PLAN="$FEATURE_DIR/plan.md"
--CLAUDE_FILE="$REPO_ROOT/CLAUDE.md"; GEMINI_FILE="$REPO_ROOT/GEMINI.md"; COPILOT_FILE="$REPO_ROOT/.github/copilot-instructions.md"; CURSOR_FILE="$REPO_ROOT/.cursor/rules/specify-rules.mdc"
--AGENT_TYPE="$1"
--[ -f "$NEW_PLAN" ] || { echo "ERROR: No plan.md found at $NEW_PLAN"; exit 1; }
--echo "=== Updating agent context files for feature $CURRENT_BRANCH ==="
--NEW_LANG=$(grep "^**Language/Version**: " "$NEW_PLAN" 2>/dev/null | head -1 | sed 's/^**Language\/Version**: //' | grep -v "NEEDS CLARIFICATION" || echo "")
--NEW_FRAMEWORK=$(grep "^**Primary Dependencies**: " "$NEW_PLAN" 2>/dev/null | head -1 | sed 's/^**Primary Dependencies**: //' | grep -v "NEEDS CLARIFICATION" || echo "")
--NEW_DB=$(grep "^**Storage**: " "$NEW_PLAN" 2>/dev/null | head -1 | sed 's/^**Storage**: //' | grep -v "N/A" | grep -v "NEEDS CLARIFICATION" || echo "")
--NEW_PROJECT_TYPE=$(grep "^**Project Type**: " "$NEW_PLAN" 2>/dev/null | head -1 | sed 's/^**Project Type**: //' || echo "")
--update_agent_file() { local target_file="$1" agent_name="$2"; echo "Updating $agent_name context file: $target_file"; local temp_file=$(mktemp); if [ ! -f "$target_file" ]; then
--  echo "Creating new $agent_name context file..."; if [ -f "$REPO_ROOT/.specify/templates/agent-file-template.md" ]; then cp "$REPO_ROOT/templates/agent-file-template.md" "$temp_file"; else echo "ERROR: Template not found"; return 1; fi;
--  sed -i.bak "s/\[PROJECT NAME\]/$(basename $REPO_ROOT)/" "$temp_file"; sed -i.bak "s/\[DATE\]/$(date +%Y-%m-%d)/" "$temp_file"; sed -i.bak "s/\[EXTRACTED FROM ALL PLAN.MD FILES\]/- $NEW_LANG + $NEW_FRAMEWORK ($CURRENT_BRANCH)/" "$temp_file";
--  if [[ "$NEW_PROJECT_TYPE" == *"web"* ]]; then sed -i.bak "s|\[ACTUAL STRUCTURE FROM PLANS\]|backend/\nfrontend/\ntests/|" "$temp_file"; else sed -i.bak "s|\[ACTUAL STRUCTURE FROM PLANS\]|src/\ntests/|" "$temp_file"; fi;
--  if [[ "$NEW_LANG" == *"Python"* ]]; then COMMANDS="cd src && pytest && ruff check ."; elif [[ "$NEW_LANG" == *"Rust"* ]]; then COMMANDS="cargo test && cargo clippy"; elif [[ "$NEW_LANG" == *"JavaScript"* ]] || [[ "$NEW_LANG" == *"TypeScript"* ]]; then COMMANDS="npm test && npm run lint"; else COMMANDS="# Add commands for $NEW_LANG"; fi; sed -i.bak "s|\[ONLY COMMANDS FOR ACTIVE TECHNOLOGIES\]|$COMMANDS|" "$temp_file";
--  sed -i.bak "s|\[LANGUAGE-SPECIFIC, ONLY FOR LANGUAGES IN USE\]|$NEW_LANG: Follow standard conventions|" "$temp_file"; sed -i.bak "s|\[LAST 3 FEATURES AND WHAT THEY ADDED\]|- $CURRENT_BRANCH: Added $NEW_LANG + $NEW_FRAMEWORK|" "$temp_file"; rm "$temp_file.bak";
--else
--  echo "Updating existing $agent_name context file..."; manual_start=$(grep -n "<!-- MANUAL ADDITIONS START -->" "$target_file" | cut -d: -f1); manual_end=$(grep -n "<!-- MANUAL ADDITIONS END -->" "$target_file" | cut -d: -f1); if [ -n "$manual_start" ] && [ -n "$manual_end" ]; then sed -n "${manual_start},${manual_end}p" "$target_file" > /tmp/manual_additions.txt; fi;
--  python3 - "$target_file" <<'EOF'
--import re,sys,datetime
--target=sys.argv[1]
--with open(target) as f: content=f.read()
--NEW_LANG="'$NEW_LANG'";NEW_FRAMEWORK="'$NEW_FRAMEWORK'";CURRENT_BRANCH="'$CURRENT_BRANCH'";NEW_DB="'$NEW_DB'";NEW_PROJECT_TYPE="'$NEW_PROJECT_TYPE'"
--# Tech section
--m=re.search(r'## Active Technologies\n(.*?)\n\n',content, re.DOTALL)
--if m:
--  existing=m.group(1)
--  additions=[]
--  if '$NEW_LANG' and '$NEW_LANG' not in existing: additions.append(f"- $NEW_LANG + $NEW_FRAMEWORK ($CURRENT_BRANCH)")
--  if '$NEW_DB' and '$NEW_DB' not in existing and '$NEW_DB'!='N/A': additions.append(f"- $NEW_DB ($CURRENT_BRANCH)")
--  if additions:
--    new_block=existing+"\n"+"\n".join(additions)
--    content=content.replace(m.group(0),f"## Active Technologies\n{new_block}\n\n")
--# Recent changes
--m2=re.search(r'## Recent Changes\n(.*?)(\n\n|$)',content, re.DOTALL)
--if m2:
--  lines=[l for l in m2.group(1).strip().split('\n') if l]
--  lines.insert(0,f"- $CURRENT_BRANCH: Added $NEW_LANG + $NEW_FRAMEWORK")
--  lines=lines[:3]
--  content=re.sub(r'## Recent Changes\n.*?(\n\n|$)', '## Recent Changes\n'+"\n".join(lines)+'\n\n', content, flags=re.DOTALL)
--content=re.sub(r'Last updated: \d{4}-\d{2}-\d{2}', 'Last updated: '+datetime.datetime.now().strftime('%Y-%m-%d'), content)
--open(target+'.tmp','w').write(content)
--EOF
--  mv "$target_file.tmp" "$target_file"; if [ -f /tmp/manual_additions.txt ]; then sed -i.bak '/<!-- MANUAL ADDITIONS START -->/,/<!-- MANUAL ADDITIONS END -->/d' "$target_file"; cat /tmp/manual_additions.txt >> "$target_file"; rm /tmp/manual_additions.txt "$target_file.bak"; fi;
--fi; mv "$temp_file" "$target_file" 2>/dev/null || true; echo "✅ $agent_name context file updated successfully"; }
--case "$AGENT_TYPE" in
--  claude) update_agent_file "$CLAUDE_FILE" "Claude Code" ;;
--  gemini) update_agent_file "$GEMINI_FILE" "Gemini CLI" ;;
--  copilot) update_agent_file "$COPILOT_FILE" "GitHub Copilot" ;;
--  cursor) update_agent_file "$CURSOR_FILE" "Cursor IDE" ;;
--  "") [ -f "$CLAUDE_FILE" ] && update_agent_file "$CLAUDE_FILE" "Claude Code"; \
--       [ -f "$GEMINI_FILE" ] && update_agent_file "$GEMINI_FILE" "Gemini CLI"; \
--       [ -f "$COPILOT_FILE" ] && update_agent_file "$COPILOT_FILE" "GitHub Copilot"; \
--       [ -f "$CURSOR_FILE" ] && update_agent_file "$CURSOR_FILE" "Cursor IDE"; \
--       if [ ! -f "$CLAUDE_FILE" ] && [ ! -f "$GEMINI_FILE" ] && [ ! -f "$COPILOT_FILE" ] && [ ! -f "$CURSOR_FILE" ]; then update_agent_file "$CLAUDE_FILE" "Claude Code"; fi ;;
--  *) echo "ERROR: Unknown agent type '$AGENT_TYPE' (expected claude|gemini|copilot|cursor)"; exit 1 ;;
--esac
--echo; echo "Summary of changes:"; [ -n "$NEW_LANG" ] && echo "- Added language: $NEW_LANG"; [ -n "$NEW_FRAMEWORK" ] && echo "- Added framework: $NEW_FRAMEWORK"; [ -n "$NEW_DB" ] && [ "$NEW_DB" != "N/A" ] && echo "- Added database: $NEW_DB"; echo; echo "Usage: $0 [claude|gemini|copilot|cursor]"
-+
-+# Enable strict error handling
-+set -u
-+set -o pipefail
-+
-+#==============================================================================
-+# Configuration and Global Variables
-+#==============================================================================
-+
-+# Get script directory and load common functions
-+SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
-+source "$SCRIPT_DIR/common.sh"
-+
-+# Get all paths and variables from common functions
-+eval $(get_feature_paths)
-+
-+NEW_PLAN="$IMPL_PLAN"  # Alias for compatibility with existing code
-+AGENT_TYPE="${1:-}"
-+
-+# Agent-specific file paths  
-+CLAUDE_FILE="$REPO_ROOT/CLAUDE.md"
-+GEMINI_FILE="$REPO_ROOT/GEMINI.md"
-+COPILOT_FILE="$REPO_ROOT/.github/copilot-instructions.md"
-+CURSOR_FILE="$REPO_ROOT/.cursor/rules/specify-rules.mdc"
-+QWEN_FILE="$REPO_ROOT/QWEN.md"
-+AGENTS_FILE="$REPO_ROOT/AGENTS.md"
-+WINDSURF_FILE="$REPO_ROOT/.windsurf/rules/specify-rules.md"
-+KILOCODE_FILE="$REPO_ROOT/.kilocode/rules/specify-rules.md"
-+AUGGIE_FILE="$REPO_ROOT/.augment/rules/specify-rules.md"
-+ROO_FILE="$REPO_ROOT/.roo/rules/specify-rules.md"
-+
-+# Template file
-+TEMPLATE_FILE="$REPO_ROOT/.specify/templates/agent-file-template.md"
-+
-+# Global variables for parsed plan data
-+NEW_LANG=""
-+NEW_FRAMEWORK=""
-+NEW_DB=""
-+NEW_PROJECT_TYPE=""
-+
-+#==============================================================================
-+# Utility Functions
-+#==============================================================================
-+
-+log_info() {
-+    echo "INFO: $1"
-+}
-+
-+log_success() {
-+    echo "✓ $1"
-+}
-+
-+log_error() {
-+    echo "ERROR: $1" >&2
-+}
-+
-+log_warning() {
-+    echo "WARNING: $1" >&2
-+}
-+
-+# Cleanup function for temporary files
-+cleanup() {
-+    local exit_code=$?
-+    rm -f /tmp/agent_update_*_$$
-+    rm -f /tmp/manual_additions_$$
-+    exit $exit_code
-+}
-+
-+# Set up cleanup trap
-+trap cleanup EXIT INT TERM
-+
-+#==============================================================================
-+# Validation Functions
-+#==============================================================================
-+
-+validate_environment() {
-+    # Check if we have a current branch/feature (git or non-git)
-+    if [[ -z "$CURRENT_BRANCH" ]]; then
-+        log_error "Unable to determine current feature"
-+        if [[ "$HAS_GIT" == "true" ]]; then
-+            log_info "Make sure you're on a feature branch"
-+        else
-+            log_info "Set SPECIFY_FEATURE environment variable or create a feature first"
-+        fi
-+        exit 1
-+    fi
-+    
-+    # Check if plan.md exists
-+    if [[ ! -f "$NEW_PLAN" ]]; then
-+        log_error "No plan.md found at $NEW_PLAN"
-+        log_info "Make sure you're working on a feature with a corresponding spec directory"
-+        if [[ "$HAS_GIT" != "true" ]]; then
-+            log_info "Use: export SPECIFY_FEATURE=your-feature-name or create a new feature first"
-+        fi
-+        exit 1
-+    fi
-+    
-+    # Check if template exists (needed for new files)
-+    if [[ ! -f "$TEMPLATE_FILE" ]]; then
-+        log_warning "Template file not found at $TEMPLATE_FILE"
-+        log_warning "Creating new agent files will fail"
-+    fi
-+}
-+
-+#==============================================================================
-+# Plan Parsing Functions
-+#==============================================================================
-+
-+extract_plan_field() {
-+    local field_pattern="$1"
-+    local plan_file="$2"
-+    
-+    grep "^\*\*${field_pattern}\*\*: " "$plan_file" 2>/dev/null | \
-+        head -1 | \
-+        sed "s|^\*\*${field_pattern}\*\*: ||" | \
-+        sed 's/^[ \t]*//;s/[ \t]*$//' | \
-+        grep -v "NEEDS CLARIFICATION" | \
-+        grep -v "^N/A$" || echo ""
-+}
-+
-+parse_plan_data() {
-+    local plan_file="$1"
-+    
-+    if [[ ! -f "$plan_file" ]]; then
-+        log_error "Plan file not found: $plan_file"
-+        return 1
-+    fi
-+    
-+    if [[ ! -r "$plan_file" ]]; then
-+        log_error "Plan file is not readable: $plan_file"
-+        return 1
-+    fi
-+    
-+    log_info "Parsing plan data from $plan_file"
-+    
-+    NEW_LANG=$(extract_plan_field "Language/Version" "$plan_file")
-+    NEW_FRAMEWORK=$(extract_plan_field "Primary Dependencies" "$plan_file")
-+    NEW_DB=$(extract_plan_field "Storage" "$plan_file")
-+    NEW_PROJECT_TYPE=$(extract_plan_field "Project Type" "$plan_file")
-+    
-+    # Log what we found
-+    if [[ -n "$NEW_LANG" ]]; then
-+        log_info "Found language: $NEW_LANG"
-+    else
-+        log_warning "No language information found in plan"
-+    fi
-+    
-+    if [[ -n "$NEW_FRAMEWORK" ]]; then
-+        log_info "Found framework: $NEW_FRAMEWORK"
-+    fi
-+    
-+    if [[ -n "$NEW_DB" ]] && [[ "$NEW_DB" != "N/A" ]]; then
-+        log_info "Found database: $NEW_DB"
-+    fi
-+    
-+    if [[ -n "$NEW_PROJECT_TYPE" ]]; then
-+        log_info "Found project type: $NEW_PROJECT_TYPE"
-+    fi
-+}
-+
-+format_technology_stack() {
-+    local lang="$1"
-+    local framework="$2"
-+    local parts=()
-+    
-+    # Add non-empty parts
-+    [[ -n "$lang" && "$lang" != "NEEDS CLARIFICATION" ]] && parts+=("$lang")
-+    [[ -n "$framework" && "$framework" != "NEEDS CLARIFICATION" && "$framework" != "N/A" ]] && parts+=("$framework")
-+    
-+    # Join with proper formatting
-+    if [[ ${#parts[@]} -eq 0 ]]; then
-+        echo ""
-+    elif [[ ${#parts[@]} -eq 1 ]]; then
-+        echo "${parts[0]}"
-+    else
-+        # Join multiple parts with " + "
-+        local result="${parts[0]}"
-+        for ((i=1; i<${#parts[@]}; i++)); do
-+            result="$result + ${parts[i]}"
-+        done
-+        echo "$result"
-+    fi
-+}
-+
-+#==============================================================================
-+# Template and Content Generation Functions
-+#==============================================================================
-+
-+get_project_structure() {
-+    local project_type="$1"
-+    
-+    if [[ "$project_type" == *"web"* ]]; then
-+        echo "backend/\\nfrontend/\\ntests/"
-+    else
-+        echo "src/\\ntests/"
-+    fi
-+}
-+
-+get_commands_for_language() {
-+    local lang="$1"
-+    
-+    case "$lang" in
-+        *"Python"*)
-+            echo "cd src && pytest && ruff check ."
-+            ;;
-+        *"Rust"*)
-+            echo "cargo test && cargo clippy"
-+            ;;
-+        *"JavaScript"*|*"TypeScript"*)
-+            echo "npm test && npm run lint"
-+            ;;
-+        *)
-+            echo "# Add commands for $lang"
-+            ;;
-+    esac
-+}
-+
-+get_language_conventions() {
-+    local lang="$1"
-+    echo "$lang: Follow standard conventions"
-+}
-+
-+create_new_agent_file() {
-+    local target_file="$1"
-+    local temp_file="$2"
-+    local project_name="$3"
-+    local current_date="$4"
-+    
-+    if [[ ! -f "$TEMPLATE_FILE" ]]; then
-+        log_error "Template not found at $TEMPLATE_FILE"
-+        return 1
-+    fi
-+    
-+    if [[ ! -r "$TEMPLATE_FILE" ]]; then
-+        log_error "Template file is not readable: $TEMPLATE_FILE"
-+        return 1
-+    fi
-+    
-+    log_info "Creating new agent context file from template..."
-+    
-+    if ! cp "$TEMPLATE_FILE" "$temp_file"; then
-+        log_error "Failed to copy template file"
-+        return 1
-+    fi
-+    
-+    # Replace template placeholders
-+    local project_structure
-+    project_structure=$(get_project_structure "$NEW_PROJECT_TYPE")
-+    
-+    local commands
-+    commands=$(get_commands_for_language "$NEW_LANG")
-+    
-+    local language_conventions
-+    language_conventions=$(get_language_conventions "$NEW_LANG")
-+    
-+    # Perform substitutions with error checking using safer approach
-+    # Escape special characters for sed by using a different delimiter or escaping
-+    local escaped_lang=$(printf '%s\n' "$NEW_LANG" | sed 's/[\[\.*^$()+{}|]/\\&/g')
-+    local escaped_framework=$(printf '%s\n' "$NEW_FRAMEWORK" | sed 's/[\[\.*^$()+{}|]/\\&/g')
-+    local escaped_branch=$(printf '%s\n' "$CURRENT_BRANCH" | sed 's/[\[\.*^$()+{}|]/\\&/g')
-+    
-+    # Build technology stack and recent change strings conditionally
-+    local tech_stack
-+    if [[ -n "$escaped_lang" && -n "$escaped_framework" ]]; then
-+        tech_stack="- $escaped_lang + $escaped_framework ($escaped_branch)"
-+    elif [[ -n "$escaped_lang" ]]; then
-+        tech_stack="- $escaped_lang ($escaped_branch)"
-+    elif [[ -n "$escaped_framework" ]]; then
-+        tech_stack="- $escaped_framework ($escaped_branch)"
-+    else
-+        tech_stack="- ($escaped_branch)"
-+    fi
-+
-+    local recent_change
-+    if [[ -n "$escaped_lang" && -n "$escaped_framework" ]]; then
-+        recent_change="- $escaped_branch: Added $escaped_lang + $escaped_framework"
-+    elif [[ -n "$escaped_lang" ]]; then
-+        recent_change="- $escaped_branch: Added $escaped_lang"
-+    elif [[ -n "$escaped_framework" ]]; then
-+        recent_change="- $escaped_branch: Added $escaped_framework"
-+    else
-+        recent_change="- $escaped_branch: Added"
-+    fi
-+
-+    local substitutions=(
-+        "s|\[PROJECT NAME\]|$project_name|"
-+        "s|\[DATE\]|$current_date|"
-+        "s|\[EXTRACTED FROM ALL PLAN.MD FILES\]|$tech_stack|"
-+        "s|\[ACTUAL STRUCTURE FROM PLANS\]|$project_structure|g"
-+        "s|\[ONLY COMMANDS FOR ACTIVE TECHNOLOGIES\]|$commands|"
-+        "s|\[LANGUAGE-SPECIFIC, ONLY FOR LANGUAGES IN USE\]|$language_conventions|"
-+        "s|\[LAST 3 FEATURES AND WHAT THEY ADDED\]|$recent_change|"
-+    )
-+    
-+    for substitution in "${substitutions[@]}"; do
-+        if ! sed -i.bak -e "$substitution" "$temp_file"; then
-+            log_error "Failed to perform substitution: $substitution"
-+            rm -f "$temp_file" "$temp_file.bak"
-+            return 1
-+        fi
-+    done
-+    
-+    # Convert \n sequences to actual newlines
-+    newline=$(printf '\n')
-+    sed -i.bak2 "s/\\\\n/${newline}/g" "$temp_file"
-+    
-+    # Clean up backup files
-+    rm -f "$temp_file.bak" "$temp_file.bak2"
-+    
-+    return 0
-+}
-+
-+
-+
-+
-+update_existing_agent_file() {
-+    local target_file="$1"
-+    local current_date="$2"
-+    
-+    log_info "Updating existing agent context file..."
-+    
-+    # Use a single temporary file for atomic update
-+    local temp_file
-+    temp_file=$(mktemp) || {
-+        log_error "Failed to create temporary file"
-+        return 1
-+    }
-+    
-+    # Process the file in one pass
-+    local tech_stack=$(format_technology_stack "$NEW_LANG" "$NEW_FRAMEWORK")
-+    local new_tech_entries=()
-+    local new_change_entry=""
-+    
-+    # Prepare new technology entries
-+    if [[ -n "$tech_stack" ]] && ! grep -q "$tech_stack" "$target_file"; then
-+        new_tech_entries+=("- $tech_stack ($CURRENT_BRANCH)")
-+    fi
-+    
-+    if [[ -n "$NEW_DB" ]] && [[ "$NEW_DB" != "N/A" ]] && [[ "$NEW_DB" != "NEEDS CLARIFICATION" ]] && ! grep -q "$NEW_DB" "$target_file"; then
-+        new_tech_entries+=("- $NEW_DB ($CURRENT_BRANCH)")
-+    fi
-+    
-+    # Prepare new change entry
-+    if [[ -n "$tech_stack" ]]; then
-+        new_change_entry="- $CURRENT_BRANCH: Added $tech_stack"
-+    elif [[ -n "$NEW_DB" ]] && [[ "$NEW_DB" != "N/A" ]] && [[ "$NEW_DB" != "NEEDS CLARIFICATION" ]]; then
-+        new_change_entry="- $CURRENT_BRANCH: Added $NEW_DB"
-+    fi
-+    
-+    # Process file line by line
-+    local in_tech_section=false
-+    local in_changes_section=false
-+    local tech_entries_added=false
-+    local changes_entries_added=false
-+    local existing_changes_count=0
-+    
-+    while IFS= read -r line || [[ -n "$line" ]]; do
-+        # Handle Active Technologies section
-+        if [[ "$line" == "## Active Technologies" ]]; then
-+            echo "$line" >> "$temp_file"
-+            in_tech_section=true
-+            continue
-+        elif [[ $in_tech_section == true ]] && [[ "$line" =~ ^##[[:space:]] ]]; then
-+            # Add new tech entries before closing the section
-+            if [[ $tech_entries_added == false ]] && [[ ${#new_tech_entries[@]} -gt 0 ]]; then
-+                printf '%s\n' "${new_tech_entries[@]}" >> "$temp_file"
-+                tech_entries_added=true
-+            fi
-+            echo "$line" >> "$temp_file"
-+            in_tech_section=false
-+            continue
-+        elif [[ $in_tech_section == true ]] && [[ -z "$line" ]]; then
-+            # Add new tech entries before empty line in tech section
-+            if [[ $tech_entries_added == false ]] && [[ ${#new_tech_entries[@]} -gt 0 ]]; then
-+                printf '%s\n' "${new_tech_entries[@]}" >> "$temp_file"
-+                tech_entries_added=true
-+            fi
-+            echo "$line" >> "$temp_file"
-+            continue
-+        fi
-+        
-+        # Handle Recent Changes section
-+        if [[ "$line" == "## Recent Changes" ]]; then
-+            echo "$line" >> "$temp_file"
-+            # Add new change entry right after the heading
-+            if [[ -n "$new_change_entry" ]]; then
-+                echo "$new_change_entry" >> "$temp_file"
-+            fi
-+            in_changes_section=true
-+            changes_entries_added=true
-+            continue
-+        elif [[ $in_changes_section == true ]] && [[ "$line" =~ ^##[[:space:]] ]]; then
-+            echo "$line" >> "$temp_file"
-+            in_changes_section=false
-+            continue
-+        elif [[ $in_changes_section == true ]] && [[ "$line" == "- "* ]]; then
-+            # Keep only first 2 existing changes
-+            if [[ $existing_changes_count -lt 2 ]]; then
-+                echo "$line" >> "$temp_file"
-+                ((existing_changes_count++))
-+            fi
-+            continue
-+        fi
-+        
-+        # Update timestamp
-+        if [[ "$line" =~ \*\*Last\ updated\*\*:.*[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9] ]]; then
-+            echo "$line" | sed "s/[0-9][0-9][0-9][0-9]-[0-9][0-9]-[0-9][0-9]/$current_date/" >> "$temp_file"
-+        else
-+            echo "$line" >> "$temp_file"
-+        fi
-+    done < "$target_file"
-+    
-+    # Post-loop check: if we're still in the Active Technologies section and haven't added new entries
-+    if [[ $in_tech_section == true ]] && [[ $tech_entries_added == false ]] && [[ ${#new_tech_entries[@]} -gt 0 ]]; then
-+        printf '%s\n' "${new_tech_entries[@]}" >> "$temp_file"
-+    fi
-+    
-+    # Move temp file to target atomically
-+    if ! mv "$temp_file" "$target_file"; then
-+        log_error "Failed to update target file"
-+        rm -f "$temp_file"
-+        return 1
-+    fi
-+    
-+    return 0
-+}
-+#==============================================================================
-+# Main Agent File Update Function
-+#==============================================================================
-+
-+update_agent_file() {
-+    local target_file="$1"
-+    local agent_name="$2"
-+    
-+    if [[ -z "$target_file" ]] || [[ -z "$agent_name" ]]; then
-+        log_error "update_agent_file requires target_file and agent_name parameters"
-+        return 1
-+    fi
-+    
-+    log_info "Updating $agent_name context file: $target_file"
-+    
-+    local project_name
-+    project_name=$(basename "$REPO_ROOT")
-+    local current_date
-+    current_date=$(date +%Y-%m-%d)
-+    
-+    # Create directory if it doesn't exist
-+    local target_dir
-+    target_dir=$(dirname "$target_file")
-+    if [[ ! -d "$target_dir" ]]; then
-+        if ! mkdir -p "$target_dir"; then
-+            log_error "Failed to create directory: $target_dir"
-+            return 1
-+        fi
-+    fi
-+    
-+    if [[ ! -f "$target_file" ]]; then
-+        # Create new file from template
-+        local temp_file
-+        temp_file=$(mktemp) || {
-+            log_error "Failed to create temporary file"
-+            return 1
-+        }
-+        
-+        if create_new_agent_file "$target_file" "$temp_file" "$project_name" "$current_date"; then
-+            if mv "$temp_file" "$target_file"; then
-+                log_success "Created new $agent_name context file"
-+            else
-+                log_error "Failed to move temporary file to $target_file"
-+                rm -f "$temp_file"
-+                return 1
-+            fi
-+        else
-+            log_error "Failed to create new agent file"
-+            rm -f "$temp_file"
-+            return 1
-+        fi
-+    else
-+        # Update existing file
-+        if [[ ! -r "$target_file" ]]; then
-+            log_error "Cannot read existing file: $target_file"
-+            return 1
-+        fi
-+        
-+        if [[ ! -w "$target_file" ]]; then
-+            log_error "Cannot write to existing file: $target_file"
-+            return 1
-+        fi
-+        
-+        if update_existing_agent_file "$target_file" "$current_date"; then
-+            log_success "Updated existing $agent_name context file"
-+        else
-+            log_error "Failed to update existing agent file"
-+            return 1
-+        fi
-+    fi
-+    
-+    return 0
-+}
-+
-+#==============================================================================
-+# Agent Selection and Processing
-+#==============================================================================
-+
-+update_specific_agent() {
-+    local agent_type="$1"
-+    
-+    case "$agent_type" in
-+        claude)
-+            update_agent_file "$CLAUDE_FILE" "Claude Code"
-+            ;;
-+        gemini)
-+            update_agent_file "$GEMINI_FILE" "Gemini CLI"
-+            ;;
-+        copilot)
-+            update_agent_file "$COPILOT_FILE" "GitHub Copilot"
-+            ;;
-+        cursor)
-+            update_agent_file "$CURSOR_FILE" "Cursor IDE"
-+            ;;
-+        qwen)
-+            update_agent_file "$QWEN_FILE" "Qwen Code"
-+            ;;
-+        opencode)
-+            update_agent_file "$AGENTS_FILE" "opencode"
-+            ;;
-+        codex)
-+            update_agent_file "$AGENTS_FILE" "Codex CLI"
-+            ;;
-+        windsurf)
-+            update_agent_file "$WINDSURF_FILE" "Windsurf"
-+            ;;
-+        kilocode)
-+            update_agent_file "$KILOCODE_FILE" "Kilo Code"
-+            ;;
-+        auggie)
-+            update_agent_file "$AUGGIE_FILE" "Auggie CLI"
-+            ;;
-+        roo)
-+            update_agent_file "$ROO_FILE" "Roo Code"
-+            ;;
-+        *)
-+            log_error "Unknown agent type '$agent_type'"
-+            log_error "Expected: claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo"
-+            exit 1
-+            ;;
-+    esac
-+}
-+
-+update_all_existing_agents() {
-+    local found_agent=false
-+    
-+    # Check each possible agent file and update if it exists
-+    if [[ -f "$CLAUDE_FILE" ]]; then
-+        update_agent_file "$CLAUDE_FILE" "Claude Code"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$GEMINI_FILE" ]]; then
-+        update_agent_file "$GEMINI_FILE" "Gemini CLI"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$COPILOT_FILE" ]]; then
-+        update_agent_file "$COPILOT_FILE" "GitHub Copilot"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$CURSOR_FILE" ]]; then
-+        update_agent_file "$CURSOR_FILE" "Cursor IDE"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$QWEN_FILE" ]]; then
-+        update_agent_file "$QWEN_FILE" "Qwen Code"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$AGENTS_FILE" ]]; then
-+        update_agent_file "$AGENTS_FILE" "Codex/opencode"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$WINDSURF_FILE" ]]; then
-+        update_agent_file "$WINDSURF_FILE" "Windsurf"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$KILOCODE_FILE" ]]; then
-+        update_agent_file "$KILOCODE_FILE" "Kilo Code"
-+        found_agent=true
-+    fi
-+
-+    if [[ -f "$AUGGIE_FILE" ]]; then
-+        update_agent_file "$AUGGIE_FILE" "Auggie CLI"
-+        found_agent=true
-+    fi
-+    
-+    if [[ -f "$ROO_FILE" ]]; then
-+        update_agent_file "$ROO_FILE" "Roo Code"
-+        found_agent=true
-+    fi
-+    
-+    # If no agent files exist, create a default Claude file
-+    if [[ "$found_agent" == false ]]; then
-+        log_info "No existing agent files found, creating default Claude file..."
-+        update_agent_file "$CLAUDE_FILE" "Claude Code"
-+    fi
-+}
-+print_summary() {
-+    echo
-+    log_info "Summary of changes:"
-+    
-+    if [[ -n "$NEW_LANG" ]]; then
-+        echo "  - Added language: $NEW_LANG"
-+    fi
-+    
-+    if [[ -n "$NEW_FRAMEWORK" ]]; then
-+        echo "  - Added framework: $NEW_FRAMEWORK"
-+    fi
-+    
-+    if [[ -n "$NEW_DB" ]] && [[ "$NEW_DB" != "N/A" ]]; then
-+        echo "  - Added database: $NEW_DB"
-+    fi
-+    
-+    echo
-+    log_info "Usage: $0 [claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo]"
-+}
-+
-+#==============================================================================
-+# Main Execution
-+#==============================================================================
-+
-+main() {
-+    # Validate environment before proceeding
-+    validate_environment
-+    
-+    log_info "=== Updating agent context files for feature $CURRENT_BRANCH ==="
-+    
-+    # Parse the plan file to extract project information
-+    if ! parse_plan_data "$NEW_PLAN"; then
-+        log_error "Failed to parse plan data"
-+        exit 1
-+    fi
-+    
-+    # Process based on agent type argument
-+    local success=true
-+    
-+    if [[ -z "$AGENT_TYPE" ]]; then
-+        # No specific agent provided - update all existing agent files
-+        log_info "No agent specified, updating all existing agent files..."
-+        if ! update_all_existing_agents; then
-+            success=false
-+        fi
-+    else
-+        # Specific agent provided - update only that agent
-+        log_info "Updating specific agent: $AGENT_TYPE"
-+        if ! update_specific_agent "$AGENT_TYPE"; then
-+            success=false
-+        fi
-+    fi
-+    
-+    # Print summary
-+    print_summary
-+    
-+    if [[ "$success" == true ]]; then
-+        log_success "Agent context update completed successfully"
-+        exit 0
-+    else
-+        log_error "Agent context update completed with errors"
-+        exit 1
-+    fi
-+}
-+
-+# Execute main function if script is run directly
-+if [[ "${BASH_SOURCE[0]}" == "${0}" ]]; then
-+    main "$@"
-+fi
-diff --git a/scripts/powershell/check-prerequisites.ps1 b/scripts/powershell/check-prerequisites.ps1
-new file mode 100644
-index 0000000..d61c3b9
---- /dev/null
-+++ b/scripts/powershell/check-prerequisites.ps1
-@@ -0,0 +1,148 @@
-+#!/usr/bin/env pwsh
-+
-+# Consolidated prerequisite checking script (PowerShell)
-+#
-+# This script provides unified prerequisite checking for Spec-Driven Development workflow.
-+# It replaces the functionality previously spread across multiple scripts.
-+#
-+# Usage: ./check-prerequisites.ps1 [OPTIONS]
-+#
-+# OPTIONS:
-+#   -Json               Output in JSON format
-+#   -RequireTasks       Require tasks.md to exist (for implementation phase)
-+#   -IncludeTasks       Include tasks.md in AVAILABLE_DOCS list
-+#   -PathsOnly          Only output path variables (no validation)
-+#   -Help, -h           Show help message
-+
-+[CmdletBinding()]
-+param(
-+    [switch]$Json,
-+    [switch]$RequireTasks,
-+    [switch]$IncludeTasks,
-+    [switch]$PathsOnly,
-+    [switch]$Help
-+)
-+
-+$ErrorActionPreference = 'Stop'
-+
-+# Show help if requested
-+if ($Help) {
-+    Write-Output @"
-+Usage: check-prerequisites.ps1 [OPTIONS]
-+
-+Consolidated prerequisite checking for Spec-Driven Development workflow.
-+
-+OPTIONS:
-+  -Json               Output in JSON format
-+  -RequireTasks       Require tasks.md to exist (for implementation phase)
-+  -IncludeTasks       Include tasks.md in AVAILABLE_DOCS list
-+  -PathsOnly          Only output path variables (no prerequisite validation)
-+  -Help, -h           Show this help message
-+
-+EXAMPLES:
-+  # Check task prerequisites (plan.md required)
-+  .\check-prerequisites.ps1 -Json
-+  
-+  # Check implementation prerequisites (plan.md + tasks.md required)
-+  .\check-prerequisites.ps1 -Json -RequireTasks -IncludeTasks
-+  
-+  # Get feature paths only (no validation)
-+  .\check-prerequisites.ps1 -PathsOnly
-+
-+"@
-+    exit 0
-+}
-+
-+# Source common functions
-+. "$PSScriptRoot/common.ps1"
-+
-+# Get feature paths and validate branch
-+$paths = Get-FeaturePathsEnv
-+
-+if (-not (Test-FeatureBranch -Branch $paths.CURRENT_BRANCH -HasGit:$paths.HAS_GIT)) { 
-+    exit 1 
-+}
-+
-+# If paths-only mode, output paths and exit (support combined -Json -PathsOnly)
-+if ($PathsOnly) {
-+    if ($Json) {
-+        [PSCustomObject]@{
-+            REPO_ROOT    = $paths.REPO_ROOT
-+            BRANCH       = $paths.CURRENT_BRANCH
-+            FEATURE_DIR  = $paths.FEATURE_DIR
-+            FEATURE_SPEC = $paths.FEATURE_SPEC
-+            IMPL_PLAN    = $paths.IMPL_PLAN
-+            TASKS        = $paths.TASKS
-+        } | ConvertTo-Json -Compress
-+    } else {
-+        Write-Output "REPO_ROOT: $($paths.REPO_ROOT)"
-+        Write-Output "BRANCH: $($paths.CURRENT_BRANCH)"
-+        Write-Output "FEATURE_DIR: $($paths.FEATURE_DIR)"
-+        Write-Output "FEATURE_SPEC: $($paths.FEATURE_SPEC)"
-+        Write-Output "IMPL_PLAN: $($paths.IMPL_PLAN)"
-+        Write-Output "TASKS: $($paths.TASKS)"
-+    }
-+    exit 0
-+}
-+
-+# Validate required directories and files
-+if (-not (Test-Path $paths.FEATURE_DIR -PathType Container)) {
-+    Write-Output "ERROR: Feature directory not found: $($paths.FEATURE_DIR)"
-+    Write-Output "Run /specify first to create the feature structure."
-+    exit 1
-+}
-+
-+if (-not (Test-Path $paths.IMPL_PLAN -PathType Leaf)) {
-+    Write-Output "ERROR: plan.md not found in $($paths.FEATURE_DIR)"
-+    Write-Output "Run /plan first to create the implementation plan."
-+    exit 1
-+}
-+
-+# Check for tasks.md if required
-+if ($RequireTasks -and -not (Test-Path $paths.TASKS -PathType Leaf)) {
-+    Write-Output "ERROR: tasks.md not found in $($paths.FEATURE_DIR)"
-+    Write-Output "Run /tasks first to create the task list."
-+    exit 1
-+}
-+
-+# Build list of available documents
-+$docs = @()
-+
-+# Always check these optional docs
-+if (Test-Path $paths.RESEARCH) { $docs += 'research.md' }
-+if (Test-Path $paths.DATA_MODEL) { $docs += 'data-model.md' }
-+
-+# Check contracts directory (only if it exists and has files)
-+if ((Test-Path $paths.CONTRACTS_DIR) -and (Get-ChildItem -Path $paths.CONTRACTS_DIR -ErrorAction SilentlyContinue | Select-Object -First 1)) { 
-+    $docs += 'contracts/' 
-+}
-+
-+if (Test-Path $paths.QUICKSTART) { $docs += 'quickstart.md' }
-+
-+# Include tasks.md if requested and it exists
-+if ($IncludeTasks -and (Test-Path $paths.TASKS)) { 
-+    $docs += 'tasks.md' 
-+}
-+
-+# Output results
-+if ($Json) {
-+    # JSON output
-+    [PSCustomObject]@{ 
-+        FEATURE_DIR = $paths.FEATURE_DIR
-+        AVAILABLE_DOCS = $docs 
-+    } | ConvertTo-Json -Compress
-+} else {
-+    # Text output
-+    Write-Output "FEATURE_DIR:$($paths.FEATURE_DIR)"
-+    Write-Output "AVAILABLE_DOCS:"
-+    
-+    # Show status of each potential document
-+    Test-FileExists -Path $paths.RESEARCH -Description 'research.md' | Out-Null
-+    Test-FileExists -Path $paths.DATA_MODEL -Description 'data-model.md' | Out-Null
-+    Test-DirHasFiles -Path $paths.CONTRACTS_DIR -Description 'contracts/' | Out-Null
-+    Test-FileExists -Path $paths.QUICKSTART -Description 'quickstart.md' | Out-Null
-+    
-+    if ($IncludeTasks) {
-+        Test-FileExists -Path $paths.TASKS -Description 'tasks.md' | Out-Null
-+    }
-+}
-\ No newline at end of file
-diff --git a/scripts/powershell/check-task-prerequisites.ps1 b/scripts/powershell/check-task-prerequisites.ps1
-deleted file mode 100644
-index 3be870f..0000000
---- a/scripts/powershell/check-task-prerequisites.ps1
-+++ /dev/null
-@@ -1,35 +0,0 @@
--#!/usr/bin/env pwsh
--[CmdletBinding()]
--param([switch]$Json)
--$ErrorActionPreference = 'Stop'
--. "$PSScriptRoot/common.ps1"
--
--$paths = Get-FeaturePathsEnv
--if (-not (Test-FeatureBranch -Branch $paths.CURRENT_BRANCH)) { exit 1 }
--
--if (-not (Test-Path $paths.FEATURE_DIR -PathType Container)) {
--    Write-Output "ERROR: Feature directory not found: $($paths.FEATURE_DIR)"
--    Write-Output "Run /specify first to create the feature structure."
--    exit 1
--}
--if (-not (Test-Path $paths.IMPL_PLAN -PathType Leaf)) {
--    Write-Output "ERROR: plan.md not found in $($paths.FEATURE_DIR)"
--    Write-Output "Run /plan first to create the plan."
--    exit 1
--}
--
--if ($Json) {
--    $docs = @()
--    if (Test-Path $paths.RESEARCH) { $docs += 'research.md' }
--    if (Test-Path $paths.DATA_MODEL) { $docs += 'data-model.md' }
--    if ((Test-Path $paths.CONTRACTS_DIR) -and (Get-ChildItem -Path $paths.CONTRACTS_DIR -ErrorAction SilentlyContinue | Select-Object -First 1)) { $docs += 'contracts/' }
--    if (Test-Path $paths.QUICKSTART) { $docs += 'quickstart.md' }
--    [PSCustomObject]@{ FEATURE_DIR=$paths.FEATURE_DIR; AVAILABLE_DOCS=$docs } | ConvertTo-Json -Compress
--} else {
--    Write-Output "FEATURE_DIR:$($paths.FEATURE_DIR)"
--    Write-Output "AVAILABLE_DOCS:"
--    Test-FileExists -Path $paths.RESEARCH -Description 'research.md' | Out-Null
--    Test-FileExists -Path $paths.DATA_MODEL -Description 'data-model.md' | Out-Null
--    Test-DirHasFiles -Path $paths.CONTRACTS_DIR -Description 'contracts/' | Out-Null
--    Test-FileExists -Path $paths.QUICKSTART -Description 'quickstart.md' | Out-Null
--}
-diff --git a/scripts/powershell/common.ps1 b/scripts/powershell/common.ps1
-index 3e04a1e..c8e34b2 100644
---- a/scripts/powershell/common.ps1
-+++ b/scripts/powershell/common.ps1
-@@ -1,16 +1,84 @@
- #!/usr/bin/env pwsh
--# Common PowerShell functions analogous to common.sh (moved to powershell/)
-+# Common PowerShell functions analogous to common.sh
- 
- function Get-RepoRoot {
--    git rev-parse --show-toplevel
-+    try {
-+        $result = git rev-parse --show-toplevel 2>$null
-+        if ($LASTEXITCODE -eq 0) {
-+            return $result
-+        }
-+    } catch {
-+        # Git command failed
-+    }
-+    
-+    # Fall back to script location for non-git repos
-+    return (Resolve-Path (Join-Path $PSScriptRoot "../../..")).Path
- }
- 
- function Get-CurrentBranch {
--    git rev-parse --abbrev-ref HEAD
-+    # First check if SPECIFY_FEATURE environment variable is set
-+    if ($env:SPECIFY_FEATURE) {
-+        return $env:SPECIFY_FEATURE
-+    }
-+    
-+    # Then check git if available
-+    try {
-+        $result = git rev-parse --abbrev-ref HEAD 2>$null
-+        if ($LASTEXITCODE -eq 0) {
-+            return $result
-+        }
-+    } catch {
-+        # Git command failed
-+    }
-+    
-+    # For non-git repos, try to find the latest feature directory
-+    $repoRoot = Get-RepoRoot
-+    $specsDir = Join-Path $repoRoot "specs"
-+    
-+    if (Test-Path $specsDir) {
-+        $latestFeature = ""
-+        $highest = 0
-+        
-+        Get-ChildItem -Path $specsDir -Directory | ForEach-Object {
-+            if ($_.Name -match '^(\d{3})-') {
-+                $num = [int]$matches[1]
-+                if ($num -gt $highest) {
-+                    $highest = $num
-+                    $latestFeature = $_.Name
-+                }
-+            }
-+        }
-+        
-+        if ($latestFeature) {
-+            return $latestFeature
-+        }
-+    }
-+    
-+    # Final fallback
-+    return "main"
-+}
-+
-+function Test-HasGit {
-+    try {
-+        git rev-parse --show-toplevel 2>$null | Out-Null
-+        return ($LASTEXITCODE -eq 0)
-+    } catch {
-+        return $false
-+    }
- }
- 
- function Test-FeatureBranch {
--    param([string]$Branch)
-+    param(
-+        [string]$Branch,
-+        [bool]$HasGit = $true
-+    )
-+    
-+    # For non-git repos, we can't enforce branch naming but still provide output
-+    if (-not $HasGit) {
-+        Write-Warning "[specify] Warning: Git repository not detected; skipped branch validation"
-+        return $true
-+    }
-+    
-     if ($Branch -notmatch '^[0-9]{3}-') {
-         Write-Output "ERROR: Not on a feature branch. Current branch: $Branch"
-         Write-Output "Feature branches should be named like: 001-feature-name"
-@@ -27,17 +95,20 @@ function Get-FeatureDir {
- function Get-FeaturePathsEnv {
-     $repoRoot = Get-RepoRoot
-     $currentBranch = Get-CurrentBranch
-+    $hasGit = Test-HasGit
-     $featureDir = Get-FeatureDir -RepoRoot $repoRoot -Branch $currentBranch
-+    
-     [PSCustomObject]@{
--        REPO_ROOT    = $repoRoot
-+        REPO_ROOT     = $repoRoot
-         CURRENT_BRANCH = $currentBranch
--        FEATURE_DIR  = $featureDir
--        FEATURE_SPEC = Join-Path $featureDir 'spec.md'
--        IMPL_PLAN    = Join-Path $featureDir 'plan.md'
--        TASKS        = Join-Path $featureDir 'tasks.md'
--        RESEARCH     = Join-Path $featureDir 'research.md'
--        DATA_MODEL   = Join-Path $featureDir 'data-model.md'
--        QUICKSTART   = Join-Path $featureDir 'quickstart.md'
-+        HAS_GIT       = $hasGit
-+        FEATURE_DIR   = $featureDir
-+        FEATURE_SPEC  = Join-Path $featureDir 'spec.md'
-+        IMPL_PLAN     = Join-Path $featureDir 'plan.md'
-+        TASKS         = Join-Path $featureDir 'tasks.md'
-+        RESEARCH      = Join-Path $featureDir 'research.md'
-+        DATA_MODEL    = Join-Path $featureDir 'data-model.md'
-+        QUICKSTART    = Join-Path $featureDir 'quickstart.md'
-         CONTRACTS_DIR = Join-Path $featureDir 'contracts'
-     }
- }
-diff --git a/scripts/powershell/create-new-feature.ps1 b/scripts/powershell/create-new-feature.ps1
-index b99f088..0f1f591 100644
---- a/scripts/powershell/create-new-feature.ps1
-+++ b/scripts/powershell/create-new-feature.ps1
-@@ -1,5 +1,5 @@
- #!/usr/bin/env pwsh
--# Create a new feature (moved to powershell/)
-+# Create a new feature
- [CmdletBinding()]
- param(
-     [switch]$Json,
-@@ -9,11 +9,54 @@ param(
- $ErrorActionPreference = 'Stop'
- 
- if (-not $FeatureDescription -or $FeatureDescription.Count -eq 0) {
--    Write-Error "Usage: ./create-new-feature.ps1 [-Json] <feature description>"; exit 1
-+    Write-Error "Usage: ./create-new-feature.ps1 [-Json] <feature description>"
-+    exit 1
- }
- $featureDesc = ($FeatureDescription -join ' ').Trim()
- 
--$repoRoot = git rev-parse --show-toplevel
-+# Resolve repository root. Prefer git information when available, but fall back
-+# to searching for repository markers so the workflow still functions in repositories that
-+# were initialised with --no-git.
-+function Find-RepositoryRoot {
-+    param(
-+        [string]$StartDir,
-+        [string[]]$Markers = @('.git', '.specify')
-+    )
-+    $current = Resolve-Path $StartDir
-+    while ($true) {
-+        foreach ($marker in $Markers) {
-+            if (Test-Path (Join-Path $current $marker)) {
-+                return $current
-+            }
-+        }
-+        $parent = Split-Path $current -Parent
-+        if ($parent -eq $current) {
-+            # Reached filesystem root without finding markers
-+            return $null
-+        }
-+        $current = $parent
-+    }
-+}
-+$fallbackRoot = (Find-RepositoryRoot -StartDir $PSScriptRoot)
-+if (-not $fallbackRoot) {
-+    Write-Error "Error: Could not determine repository root. Please run this script from within the repository."
-+    exit 1
-+}
-+
-+try {
-+    $repoRoot = git rev-parse --show-toplevel 2>$null
-+    if ($LASTEXITCODE -eq 0) {
-+        $hasGit = $true
-+    } else {
-+        throw "Git not available"
-+    }
-+} catch {
-+    $repoRoot = $fallbackRoot
-+    $hasGit = $false
-+}
-+
-+Set-Location $repoRoot
-+
- $specsDir = Join-Path $repoRoot 'specs'
- New-Item -ItemType Directory -Path $specsDir -Force | Out-Null
- 
-@@ -33,20 +76,42 @@ $branchName = $featureDesc.ToLower() -replace '[^a-z0-9]', '-' -replace '-{2,}',
- $words = ($branchName -split '-') | Where-Object { $_ } | Select-Object -First 3
- $branchName = "$featureNum-$([string]::Join('-', $words))"
- 
--git checkout -b $branchName | Out-Null
-+if ($hasGit) {
-+    try {
-+        git checkout -b $branchName | Out-Null
-+    } catch {
-+        Write-Warning "Failed to create git branch: $branchName"
-+    }
-+} else {
-+    Write-Warning "[specify] Warning: Git repository not detected; skipped branch creation for $branchName"
-+}
- 
- $featureDir = Join-Path $specsDir $branchName
- New-Item -ItemType Directory -Path $featureDir -Force | Out-Null
- 
--$template = Join-Path $repoRoot 'templates/spec-template.md'
-+$template = Join-Path $repoRoot '.specify/templates/spec-template.md'
- $specFile = Join-Path $featureDir 'spec.md'
--if (Test-Path $template) { Copy-Item $template $specFile -Force } else { New-Item -ItemType File -Path $specFile | Out-Null }
-+if (Test-Path $template) { 
-+    Copy-Item $template $specFile -Force 
-+} else { 
-+    New-Item -ItemType File -Path $specFile | Out-Null 
-+}
-+
-+# Set the SPECIFY_FEATURE environment variable for the current session
-+$env:SPECIFY_FEATURE = $branchName
- 
- if ($Json) {
--    $obj = [PSCustomObject]@{ BRANCH_NAME = $branchName; SPEC_FILE = $specFile; FEATURE_NUM = $featureNum }
-+    $obj = [PSCustomObject]@{ 
-+        BRANCH_NAME = $branchName
-+        SPEC_FILE = $specFile
-+        FEATURE_NUM = $featureNum
-+        HAS_GIT = $hasGit
-+    }
-     $obj | ConvertTo-Json -Compress
- } else {
-     Write-Output "BRANCH_NAME: $branchName"
-     Write-Output "SPEC_FILE: $specFile"
-     Write-Output "FEATURE_NUM: $featureNum"
-+    Write-Output "HAS_GIT: $hasGit"
-+    Write-Output "SPECIFY_FEATURE environment variable set to: $branchName"
- }
-diff --git a/scripts/powershell/get-feature-paths.ps1 b/scripts/powershell/get-feature-paths.ps1
-deleted file mode 100644
-index fc09585..0000000
---- a/scripts/powershell/get-feature-paths.ps1
-+++ /dev/null
-@@ -1,15 +0,0 @@
--#!/usr/bin/env pwsh
--param()
--$ErrorActionPreference = 'Stop'
--
--. "$PSScriptRoot/common.ps1"
--
--$paths = Get-FeaturePathsEnv
--if (-not (Test-FeatureBranch -Branch $paths.CURRENT_BRANCH)) { exit 1 }
--
--Write-Output "REPO_ROOT: $($paths.REPO_ROOT)"
--Write-Output "BRANCH: $($paths.CURRENT_BRANCH)"
--Write-Output "FEATURE_DIR: $($paths.FEATURE_DIR)"
--Write-Output "FEATURE_SPEC: $($paths.FEATURE_SPEC)"
--Write-Output "IMPL_PLAN: $($paths.IMPL_PLAN)"
--Write-Output "TASKS: $($paths.TASKS)"
-diff --git a/scripts/powershell/setup-plan.ps1 b/scripts/powershell/setup-plan.ps1
-index b026440..d0ed582 100644
---- a/scripts/powershell/setup-plan.ps1
-+++ b/scripts/powershell/setup-plan.ps1
-@@ -1,21 +1,61 @@
- #!/usr/bin/env pwsh
-+# Setup implementation plan for a feature
-+
- [CmdletBinding()]
--param([switch]$Json)
-+param(
-+    [switch]$Json,
-+    [switch]$Help
-+)
-+
- $ErrorActionPreference = 'Stop'
-+
-+# Show help if requested
-+if ($Help) {
-+    Write-Output "Usage: ./setup-plan.ps1 [-Json] [-Help]"
-+    Write-Output "  -Json     Output results in JSON format"
-+    Write-Output "  -Help     Show this help message"
-+    exit 0
-+}
-+
-+# Load common functions
- . "$PSScriptRoot/common.ps1"
- 
-+# Get all paths and variables from common functions
- $paths = Get-FeaturePathsEnv
--if (-not (Test-FeatureBranch -Branch $paths.CURRENT_BRANCH)) { exit 1 }
- 
-+# Check if we're on a proper feature branch (only for git repos)
-+if (-not (Test-FeatureBranch -Branch $paths.CURRENT_BRANCH -HasGit $paths.HAS_GIT)) { 
-+    exit 1 
-+}
-+
-+# Ensure the feature directory exists
- New-Item -ItemType Directory -Path $paths.FEATURE_DIR -Force | Out-Null
--$template = Join-Path $paths.REPO_ROOT 'templates/plan-template.md'
--if (Test-Path $template) { Copy-Item $template $paths.IMPL_PLAN -Force }
- 
-+# Copy plan template if it exists, otherwise note it or create empty file
-+$template = Join-Path $paths.REPO_ROOT '.specify/templates/plan-template.md'
-+if (Test-Path $template) { 
-+    Copy-Item $template $paths.IMPL_PLAN -Force
-+    Write-Output "Copied plan template to $($paths.IMPL_PLAN)"
-+} else {
-+    Write-Warning "Plan template not found at $template"
-+    # Create a basic plan file if template doesn't exist
-+    New-Item -ItemType File -Path $paths.IMPL_PLAN -Force | Out-Null
-+}
-+
-+# Output results
- if ($Json) {
--    [PSCustomObject]@{ FEATURE_SPEC=$paths.FEATURE_SPEC; IMPL_PLAN=$paths.IMPL_PLAN; SPECS_DIR=$paths.FEATURE_DIR; BRANCH=$paths.CURRENT_BRANCH } | ConvertTo-Json -Compress
-+    $result = [PSCustomObject]@{ 
-+        FEATURE_SPEC = $paths.FEATURE_SPEC
-+        IMPL_PLAN = $paths.IMPL_PLAN
-+        SPECS_DIR = $paths.FEATURE_DIR
-+        BRANCH = $paths.CURRENT_BRANCH
-+        HAS_GIT = $paths.HAS_GIT
-+    }
-+    $result | ConvertTo-Json -Compress
- } else {
-     Write-Output "FEATURE_SPEC: $($paths.FEATURE_SPEC)"
-     Write-Output "IMPL_PLAN: $($paths.IMPL_PLAN)"
-     Write-Output "SPECS_DIR: $($paths.FEATURE_DIR)"
-     Write-Output "BRANCH: $($paths.CURRENT_BRANCH)"
-+    Write-Output "HAS_GIT: $($paths.HAS_GIT)"
- }
-diff --git a/scripts/powershell/update-agent-context.ps1 b/scripts/powershell/update-agent-context.ps1
-index 4578ed3..8f4830a 100644
---- a/scripts/powershell/update-agent-context.ps1
-+++ b/scripts/powershell/update-agent-context.ps1
-@@ -1,98 +1,430 @@
- #!/usr/bin/env pwsh
--[CmdletBinding()]
--param([string]$AgentType)
-+<#!
-+.SYNOPSIS
-+Update agent context files with information from plan.md (PowerShell version)
-+
-+.DESCRIPTION
-+Mirrors the behavior of scripts/bash/update-agent-context.sh:
-+ 1. Environment Validation
-+ 2. Plan Data Extraction
-+ 3. Agent File Management (create from template or update existing)
-+ 4. Content Generation (technology stack, recent changes, timestamp)
-+ 5. Multi-Agent Support (claude, gemini, copilot, cursor, qwen, opencode, codex, windsurf)
-+
-+.PARAMETER AgentType
-+Optional agent key to update a single agent. If omitted, updates all existing agent files (creating a default Claude file if none exist).
-+
-+.EXAMPLE
-+./update-agent-context.ps1 -AgentType claude
-+
-+.EXAMPLE
-+./update-agent-context.ps1   # Updates all existing agent files
-+
-+.NOTES
-+Relies on common helper functions in common.ps1
-+#>
-+param(
-+    [Parameter(Position=0)]
-+    [ValidateSet('claude','gemini','copilot','cursor','qwen','opencode','codex','windsurf','kilocode','auggie','roo')]
-+    [string]$AgentType
-+)
-+
- $ErrorActionPreference = 'Stop'
- 
--$repoRoot = git rev-parse --show-toplevel
--$currentBranch = git rev-parse --abbrev-ref HEAD
--$featureDir = Join-Path $repoRoot "specs/$currentBranch"
--$newPlan = Join-Path $featureDir 'plan.md'
--if (-not (Test-Path $newPlan)) { Write-Error "ERROR: No plan.md found at $newPlan"; exit 1 }
--
--$claudeFile = Join-Path $repoRoot 'CLAUDE.md'
--$geminiFile = Join-Path $repoRoot 'GEMINI.md'
--$copilotFile = Join-Path $repoRoot '.github/copilot-instructions.md'
--$cursorFile = Join-Path $repoRoot '.cursor/rules/specify-rules.mdc'
--
--Write-Output "=== Updating agent context files for feature $currentBranch ==="
--
--function Get-PlanValue($pattern) {
--    if (-not (Test-Path $newPlan)) { return '' }
--    $line = Select-String -Path $newPlan -Pattern $pattern | Select-Object -First 1
--    if ($line) { return ($line.Line -replace "^\*\*$pattern\*\*: ", '') }
--    return ''
--}
--
--$newLang = Get-PlanValue 'Language/Version'
--$newFramework = Get-PlanValue 'Primary Dependencies'
--$newTesting = Get-PlanValue 'Testing'
--$newDb = Get-PlanValue 'Storage'
--$newProjectType = Get-PlanValue 'Project Type'
--
--function Initialize-AgentFile($targetFile, $agentName) {
--    if (Test-Path $targetFile) { return }
--    $template = Join-Path $repoRoot '.specify/templates/agent-file-template.md'
--    if (-not (Test-Path $template)) { Write-Error "Template not found: $template"; return }
--    $content = Get-Content $template -Raw
--    $content = $content.Replace('[PROJECT NAME]', (Split-Path $repoRoot -Leaf))
--    $content = $content.Replace('[DATE]', (Get-Date -Format 'yyyy-MM-dd'))
--    $content = $content.Replace('[EXTRACTED FROM ALL PLAN.MD FILES]', "- $newLang + $newFramework ($currentBranch)")
--    if ($newProjectType -match 'web') { $structure = "backend/`nfrontend/`ntests/" } else { $structure = "src/`ntests/" }
--    $content = $content.Replace('[ACTUAL STRUCTURE FROM PLANS]', $structure)
--    if ($newLang -match 'Python') { $commands = 'cd src && pytest && ruff check .' }
--    elseif ($newLang -match 'Rust') { $commands = 'cargo test && cargo clippy' }
--    elseif ($newLang -match 'JavaScript|TypeScript') { $commands = 'npm test && npm run lint' }
--    else { $commands = "# Add commands for $newLang" }
--    $content = $content.Replace('[ONLY COMMANDS FOR ACTIVE TECHNOLOGIES]', $commands)
--    $content = $content.Replace('[LANGUAGE-SPECIFIC, ONLY FOR LANGUAGES IN USE]', "${newLang}: Follow standard conventions")
--    $content = $content.Replace('[LAST 3 FEATURES AND WHAT THEY ADDED]', "- ${currentBranch}: Added ${newLang} + ${newFramework}")
--    $content | Set-Content $targetFile -Encoding UTF8
--}
--
--function Update-AgentFile($targetFile, $agentName) {
--    if (-not (Test-Path $targetFile)) { Initialize-AgentFile $targetFile $agentName; return }
--    $content = Get-Content $targetFile -Raw
--    if ($newLang -and ($content -notmatch [regex]::Escape($newLang))) { $content = $content -replace '(## Active Technologies\n)', "`$1- $newLang + $newFramework ($currentBranch)`n" }
--    if ($newDb -and $newDb -ne 'N/A' -and ($content -notmatch [regex]::Escape($newDb))) { $content = $content -replace '(## Active Technologies\n)', "`$1- $newDb ($currentBranch)`n" }
--    if ($content -match '## Recent Changes\n([\s\S]*?)(\n\n|$)') {
--        $changesBlock = $matches[1].Trim().Split("`n")
--    $changesBlock = ,"- ${currentBranch}: Added ${newLang} + ${newFramework}" + $changesBlock
--        $changesBlock = $changesBlock | Where-Object { $_ } | Select-Object -First 3
--        $joined = ($changesBlock -join "`n")
--        $content = [regex]::Replace($content, '## Recent Changes\n([\s\S]*?)(\n\n|$)', "## Recent Changes`n$joined`n`n")
-+# Import common helpers
-+$ScriptDir = Split-Path -Parent $MyInvocation.MyCommand.Path
-+. (Join-Path $ScriptDir 'common.ps1')
-+
-+# Acquire environment paths
-+$envData = Get-FeaturePathsEnv
-+$REPO_ROOT     = $envData.REPO_ROOT
-+$CURRENT_BRANCH = $envData.CURRENT_BRANCH
-+$HAS_GIT       = $envData.HAS_GIT
-+$IMPL_PLAN     = $envData.IMPL_PLAN
-+$NEW_PLAN = $IMPL_PLAN
-+
-+# Agent file paths
-+$CLAUDE_FILE   = Join-Path $REPO_ROOT 'CLAUDE.md'
-+$GEMINI_FILE   = Join-Path $REPO_ROOT 'GEMINI.md'
-+$COPILOT_FILE  = Join-Path $REPO_ROOT '.github/copilot-instructions.md'
-+$CURSOR_FILE   = Join-Path $REPO_ROOT '.cursor/rules/specify-rules.mdc'
-+$QWEN_FILE     = Join-Path $REPO_ROOT 'QWEN.md'
-+$AGENTS_FILE   = Join-Path $REPO_ROOT 'AGENTS.md'
-+$WINDSURF_FILE = Join-Path $REPO_ROOT '.windsurf/rules/specify-rules.md'
-+$KILOCODE_FILE = Join-Path $REPO_ROOT '.kilocode/rules/specify-rules.md'
-+$AUGGIE_FILE   = Join-Path $REPO_ROOT '.augment/rules/specify-rules.md'
-+$ROO_FILE      = Join-Path $REPO_ROOT '.roo/rules/specify-rules.md'
-+
-+$TEMPLATE_FILE = Join-Path $REPO_ROOT '.specify/templates/agent-file-template.md'
-+
-+# Parsed plan data placeholders
-+$script:NEW_LANG = ''
-+$script:NEW_FRAMEWORK = ''
-+$script:NEW_DB = ''
-+$script:NEW_PROJECT_TYPE = ''
-+
-+function Write-Info { 
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$Message
-+    )
-+    Write-Host "INFO: $Message" 
-+}
-+
-+function Write-Success { 
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$Message
-+    )
-+    Write-Host "$([char]0x2713) $Message" 
-+}
-+
-+function Write-WarningMsg { 
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$Message
-+    )
-+    Write-Warning $Message 
-+}
-+
-+function Write-Err { 
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$Message
-+    )
-+    Write-Host "ERROR: $Message" -ForegroundColor Red 
-+}
-+
-+function Validate-Environment {
-+    if (-not $CURRENT_BRANCH) {
-+        Write-Err 'Unable to determine current feature'
-+        if ($HAS_GIT) { Write-Info "Make sure you're on a feature branch" } else { Write-Info 'Set SPECIFY_FEATURE environment variable or create a feature first' }
-+        exit 1
-+    }
-+    if (-not (Test-Path $NEW_PLAN)) {
-+        Write-Err "No plan.md found at $NEW_PLAN"
-+        Write-Info 'Ensure you are working on a feature with a corresponding spec directory'
-+        if (-not $HAS_GIT) { Write-Info 'Use: $env:SPECIFY_FEATURE=your-feature-name or create a new feature first' }
-+        exit 1
-     }
--    $content = [regex]::Replace($content, 'Last updated: \d{4}-\d{2}-\d{2}', "Last updated: $(Get-Date -Format 'yyyy-MM-dd')")
--    $content | Set-Content $targetFile -Encoding UTF8
--    Write-Output "✅ $agentName context file updated successfully"
--}
--
--switch ($AgentType) {
--    'claude' { Update-AgentFile $claudeFile 'Claude Code' }
--    'gemini' { Update-AgentFile $geminiFile 'Gemini CLI' }
--    'copilot' { Update-AgentFile $copilotFile 'GitHub Copilot' }
--    'cursor' { Update-AgentFile $cursorFile 'Cursor IDE' }
--    '' {
--        foreach ($pair in @(
--            @{file=$claudeFile; name='Claude Code'},
--            @{file=$geminiFile; name='Gemini CLI'},
--            @{file=$copilotFile; name='GitHub Copilot'},
--            @{file=$cursorFile; name='Cursor IDE'}
--        )) {
--            if (Test-Path $pair.file) { Update-AgentFile $pair.file $pair.name }
-+    if (-not (Test-Path $TEMPLATE_FILE)) {
-+        Write-Err "Template file not found at $TEMPLATE_FILE"
-+        Write-Info 'Run specify init to scaffold .specify/templates, or add agent-file-template.md there.'
-+        exit 1
-+    }
-+}
-+
-+function Extract-PlanField {
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$FieldPattern,
-+        [Parameter(Mandatory=$true)]
-+        [string]$PlanFile
-+    )
-+    if (-not (Test-Path $PlanFile)) { return '' }
-+    # Lines like **Language/Version**: Python 3.12
-+    $regex = "^\*\*$([Regex]::Escape($FieldPattern))\*\*: (.+)$"
-+    Get-Content -LiteralPath $PlanFile | ForEach-Object {
-+        if ($_ -match $regex) { 
-+            $val = $Matches[1].Trim()
-+            if ($val -notin @('NEEDS CLARIFICATION','N/A')) { return $val }
-         }
--        if (-not (Test-Path $claudeFile) -and -not (Test-Path $geminiFile) -and -not (Test-Path $copilotFile) -and -not (Test-Path $cursorFile)) {
--            Write-Output 'No agent context files found. Creating Claude Code context file by default.'
--            Update-AgentFile $claudeFile 'Claude Code'
-+    } | Select-Object -First 1
-+}
-+
-+function Parse-PlanData {
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$PlanFile
-+    )
-+    if (-not (Test-Path $PlanFile)) { Write-Err "Plan file not found: $PlanFile"; return $false }
-+    Write-Info "Parsing plan data from $PlanFile"
-+    $script:NEW_LANG        = Extract-PlanField -FieldPattern 'Language/Version' -PlanFile $PlanFile
-+    $script:NEW_FRAMEWORK   = Extract-PlanField -FieldPattern 'Primary Dependencies' -PlanFile $PlanFile
-+    $script:NEW_DB          = Extract-PlanField -FieldPattern 'Storage' -PlanFile $PlanFile
-+    $script:NEW_PROJECT_TYPE = Extract-PlanField -FieldPattern 'Project Type' -PlanFile $PlanFile
-+
-+    if ($NEW_LANG) { Write-Info "Found language: $NEW_LANG" } else { Write-WarningMsg 'No language information found in plan' }
-+    if ($NEW_FRAMEWORK) { Write-Info "Found framework: $NEW_FRAMEWORK" }
-+    if ($NEW_DB -and $NEW_DB -ne 'N/A') { Write-Info "Found database: $NEW_DB" }
-+    if ($NEW_PROJECT_TYPE) { Write-Info "Found project type: $NEW_PROJECT_TYPE" }
-+    return $true
-+}
-+
-+function Format-TechnologyStack {
-+    param(
-+        [Parameter(Mandatory=$false)]
-+        [string]$Lang,
-+        [Parameter(Mandatory=$false)]
-+        [string]$Framework
-+    )
-+    $parts = @()
-+    if ($Lang -and $Lang -ne 'NEEDS CLARIFICATION') { $parts += $Lang }
-+    if ($Framework -and $Framework -notin @('NEEDS CLARIFICATION','N/A')) { $parts += $Framework }
-+    if (-not $parts) { return '' }
-+    return ($parts -join ' + ')
-+}
-+
-+function Get-ProjectStructure { 
-+    param(
-+        [Parameter(Mandatory=$false)]
-+        [string]$ProjectType
-+    )
-+    if ($ProjectType -match 'web') { return "backend/`nfrontend/`ntests/" } else { return "src/`ntests/" } 
-+}
-+
-+function Get-CommandsForLanguage { 
-+    param(
-+        [Parameter(Mandatory=$false)]
-+        [string]$Lang
-+    )
-+    switch -Regex ($Lang) {
-+        'Python' { return "cd src; pytest; ruff check ." }
-+        'Rust' { return "cargo test; cargo clippy" }
-+        'JavaScript|TypeScript' { return "npm test; npm run lint" }
-+        default { return "# Add commands for $Lang" }
-+    }
-+}
-+
-+function Get-LanguageConventions { 
-+    param(
-+        [Parameter(Mandatory=$false)]
-+        [string]$Lang
-+    )
-+    if ($Lang) { "${Lang}: Follow standard conventions" } else { 'General: Follow standard conventions' } 
-+}
-+
-+function New-AgentFile {
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$TargetFile,
-+        [Parameter(Mandatory=$true)]
-+        [string]$ProjectName,
-+        [Parameter(Mandatory=$true)]
-+        [datetime]$Date
-+    )
-+    if (-not (Test-Path $TEMPLATE_FILE)) { Write-Err "Template not found at $TEMPLATE_FILE"; return $false }
-+    $temp = New-TemporaryFile
-+    Copy-Item -LiteralPath $TEMPLATE_FILE -Destination $temp -Force
-+
-+    $projectStructure = Get-ProjectStructure -ProjectType $NEW_PROJECT_TYPE
-+    $commands = Get-CommandsForLanguage -Lang $NEW_LANG
-+    $languageConventions = Get-LanguageConventions -Lang $NEW_LANG
-+
-+    $escaped_lang = $NEW_LANG
-+    $escaped_framework = $NEW_FRAMEWORK
-+    $escaped_branch = $CURRENT_BRANCH
-+
-+    $content = Get-Content -LiteralPath $temp -Raw
-+    $content = $content -replace '\[PROJECT NAME\]',$ProjectName
-+    $content = $content -replace '\[DATE\]',$Date.ToString('yyyy-MM-dd')
-+    
-+    # Build the technology stack string safely
-+    $techStackForTemplate = ""
-+    if ($escaped_lang -and $escaped_framework) {
-+        $techStackForTemplate = "- $escaped_lang + $escaped_framework ($escaped_branch)"
-+    } elseif ($escaped_lang) {
-+        $techStackForTemplate = "- $escaped_lang ($escaped_branch)"
-+    } elseif ($escaped_framework) {
-+        $techStackForTemplate = "- $escaped_framework ($escaped_branch)"
-+    }
-+    
-+    $content = $content -replace '\[EXTRACTED FROM ALL PLAN.MD FILES\]',$techStackForTemplate
-+    # For project structure we manually embed (keep newlines)
-+    $escapedStructure = [Regex]::Escape($projectStructure)
-+    $content = $content -replace '\[ACTUAL STRUCTURE FROM PLANS\]',$escapedStructure
-+    # Replace escaped newlines placeholder after all replacements
-+    $content = $content -replace '\[ONLY COMMANDS FOR ACTIVE TECHNOLOGIES\]',$commands
-+    $content = $content -replace '\[LANGUAGE-SPECIFIC, ONLY FOR LANGUAGES IN USE\]',$languageConventions
-+    
-+    # Build the recent changes string safely
-+    $recentChangesForTemplate = ""
-+    if ($escaped_lang -and $escaped_framework) {
-+        $recentChangesForTemplate = "- ${escaped_branch}: Added ${escaped_lang} + ${escaped_framework}"
-+    } elseif ($escaped_lang) {
-+        $recentChangesForTemplate = "- ${escaped_branch}: Added ${escaped_lang}"
-+    } elseif ($escaped_framework) {
-+        $recentChangesForTemplate = "- ${escaped_branch}: Added ${escaped_framework}"
-+    }
-+    
-+    $content = $content -replace '\[LAST 3 FEATURES AND WHAT THEY ADDED\]',$recentChangesForTemplate
-+    # Convert literal \n sequences introduced by Escape to real newlines
-+    $content = $content -replace '\\n',[Environment]::NewLine
-+
-+    $parent = Split-Path -Parent $TargetFile
-+    if (-not (Test-Path $parent)) { New-Item -ItemType Directory -Path $parent | Out-Null }
-+    Set-Content -LiteralPath $TargetFile -Value $content -NoNewline
-+    Remove-Item $temp -Force
-+    return $true
-+}
-+
-+function Update-ExistingAgentFile {
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$TargetFile,
-+        [Parameter(Mandatory=$true)]
-+        [datetime]$Date
-+    )
-+    if (-not (Test-Path $TargetFile)) { return (New-AgentFile -TargetFile $TargetFile -ProjectName (Split-Path $REPO_ROOT -Leaf) -Date $Date) }
-+
-+    $techStack = Format-TechnologyStack -Lang $NEW_LANG -Framework $NEW_FRAMEWORK
-+    $newTechEntries = @()
-+    if ($techStack) {
-+        $escapedTechStack = [Regex]::Escape($techStack)
-+        if (-not (Select-String -Pattern $escapedTechStack -Path $TargetFile -Quiet)) { 
-+            $newTechEntries += "- $techStack ($CURRENT_BRANCH)" 
-+        }
-+    }
-+    if ($NEW_DB -and $NEW_DB -notin @('N/A','NEEDS CLARIFICATION')) {
-+        $escapedDB = [Regex]::Escape($NEW_DB)
-+        if (-not (Select-String -Pattern $escapedDB -Path $TargetFile -Quiet)) { 
-+            $newTechEntries += "- $NEW_DB ($CURRENT_BRANCH)" 
-+        }
-+    }
-+    $newChangeEntry = ''
-+    if ($techStack) { $newChangeEntry = "- ${CURRENT_BRANCH}: Added ${techStack}" }
-+    elseif ($NEW_DB -and $NEW_DB -notin @('N/A','NEEDS CLARIFICATION')) { $newChangeEntry = "- ${CURRENT_BRANCH}: Added ${NEW_DB}" }
-+
-+    $lines = Get-Content -LiteralPath $TargetFile
-+    $output = New-Object System.Collections.Generic.List[string]
-+    $inTech = $false; $inChanges = $false; $techAdded = $false; $changeAdded = $false; $existingChanges = 0
-+
-+    for ($i=0; $i -lt $lines.Count; $i++) {
-+        $line = $lines[$i]
-+        if ($line -eq '## Active Technologies') {
-+            $output.Add($line)
-+            $inTech = $true
-+            continue
-+        }
-+        if ($inTech -and $line -match '^##\s') {
-+            if (-not $techAdded -and $newTechEntries.Count -gt 0) { $newTechEntries | ForEach-Object { $output.Add($_) }; $techAdded = $true }
-+            $output.Add($line); $inTech = $false; continue
-+        }
-+        if ($inTech -and [string]::IsNullOrWhiteSpace($line)) {
-+            if (-not $techAdded -and $newTechEntries.Count -gt 0) { $newTechEntries | ForEach-Object { $output.Add($_) }; $techAdded = $true }
-+            $output.Add($line); continue
-+        }
-+        if ($line -eq '## Recent Changes') {
-+            $output.Add($line)
-+            if ($newChangeEntry) { $output.Add($newChangeEntry); $changeAdded = $true }
-+            $inChanges = $true
-+            continue
-+        }
-+        if ($inChanges -and $line -match '^##\s') { $output.Add($line); $inChanges = $false; continue }
-+        if ($inChanges -and $line -match '^- ') {
-+            if ($existingChanges -lt 2) { $output.Add($line); $existingChanges++ }
-+            continue
-+        }
-+        if ($line -match '\*\*Last updated\*\*: .*\d{4}-\d{2}-\d{2}') {
-+            $output.Add(($line -replace '\d{4}-\d{2}-\d{2}',$Date.ToString('yyyy-MM-dd')))
-+            continue
-+        }
-+        $output.Add($line)
-+    }
-+
-+    # Post-loop check: if we're still in the Active Technologies section and haven't added new entries
-+    if ($inTech -and -not $techAdded -and $newTechEntries.Count -gt 0) {
-+        $newTechEntries | ForEach-Object { $output.Add($_) }
-+    }
-+
-+    Set-Content -LiteralPath $TargetFile -Value ($output -join [Environment]::NewLine)
-+    return $true
-+}
-+
-+function Update-AgentFile {
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$TargetFile,
-+        [Parameter(Mandatory=$true)]
-+        [string]$AgentName
-+    )
-+    if (-not $TargetFile -or -not $AgentName) { Write-Err 'Update-AgentFile requires TargetFile and AgentName'; return $false }
-+    Write-Info "Updating $AgentName context file: $TargetFile"
-+    $projectName = Split-Path $REPO_ROOT -Leaf
-+    $date = Get-Date
-+
-+    $dir = Split-Path -Parent $TargetFile
-+    if (-not (Test-Path $dir)) { New-Item -ItemType Directory -Path $dir | Out-Null }
-+
-+    if (-not (Test-Path $TargetFile)) {
-+        if (New-AgentFile -TargetFile $TargetFile -ProjectName $projectName -Date $date) { Write-Success "Created new $AgentName context file" } else { Write-Err 'Failed to create new agent file'; return $false }
-+    } else {
-+        try {
-+            if (Update-ExistingAgentFile -TargetFile $TargetFile -Date $date) { Write-Success "Updated existing $AgentName context file" } else { Write-Err 'Failed to update agent file'; return $false }
-+        } catch {
-+            Write-Err "Cannot access or update existing file: $TargetFile. $_"
-+            return $false
-         }
-     }
--    Default { Write-Error "ERROR: Unknown agent type '$AgentType'. Use: claude, gemini, copilot, cursor or leave empty for all."; exit 1 }
-+    return $true
- }
- 
--Write-Output ''
--Write-Output 'Summary of changes:'
--if ($newLang) { Write-Output "- Added language: $newLang" }
--if ($newFramework) { Write-Output "- Added framework: $newFramework" }
--if ($newDb -and $newDb -ne 'N/A') { Write-Output "- Added database: $newDb" }
-+function Update-SpecificAgent {
-+    param(
-+        [Parameter(Mandatory=$true)]
-+        [string]$Type
-+    )
-+    switch ($Type) {
-+        'claude'   { Update-AgentFile -TargetFile $CLAUDE_FILE   -AgentName 'Claude Code' }
-+        'gemini'   { Update-AgentFile -TargetFile $GEMINI_FILE   -AgentName 'Gemini CLI' }
-+        'copilot'  { Update-AgentFile -TargetFile $COPILOT_FILE  -AgentName 'GitHub Copilot' }
-+        'cursor'   { Update-AgentFile -TargetFile $CURSOR_FILE   -AgentName 'Cursor IDE' }
-+        'qwen'     { Update-AgentFile -TargetFile $QWEN_FILE     -AgentName 'Qwen Code' }
-+        'opencode' { Update-AgentFile -TargetFile $AGENTS_FILE   -AgentName 'opencode' }
-+        'codex'    { Update-AgentFile -TargetFile $AGENTS_FILE   -AgentName 'Codex CLI' }
-+        'windsurf' { Update-AgentFile -TargetFile $WINDSURF_FILE -AgentName 'Windsurf' }
-+        'kilocode' { Update-AgentFile -TargetFile $KILOCODE_FILE -AgentName 'Kilo Code' }
-+        'auggie'   { Update-AgentFile -TargetFile $AUGGIE_FILE   -AgentName 'Auggie CLI' }
-+        'roo'      { Update-AgentFile -TargetFile $ROO_FILE      -AgentName 'Roo Code' }
-+        default { Write-Err "Unknown agent type '$Type'"; Write-Err 'Expected: claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo'; return $false }
-+    }
-+}
-+
-+function Update-AllExistingAgents {
-+    $found = $false
-+    $ok = $true
-+    if (Test-Path $CLAUDE_FILE)   { if (-not (Update-AgentFile -TargetFile $CLAUDE_FILE   -AgentName 'Claude Code')) { $ok = $false }; $found = $true }
-+    if (Test-Path $GEMINI_FILE)   { if (-not (Update-AgentFile -TargetFile $GEMINI_FILE   -AgentName 'Gemini CLI')) { $ok = $false }; $found = $true }
-+    if (Test-Path $COPILOT_FILE)  { if (-not (Update-AgentFile -TargetFile $COPILOT_FILE  -AgentName 'GitHub Copilot')) { $ok = $false }; $found = $true }
-+    if (Test-Path $CURSOR_FILE)   { if (-not (Update-AgentFile -TargetFile $CURSOR_FILE   -AgentName 'Cursor IDE')) { $ok = $false }; $found = $true }
-+    if (Test-Path $QWEN_FILE)     { if (-not (Update-AgentFile -TargetFile $QWEN_FILE     -AgentName 'Qwen Code')) { $ok = $false }; $found = $true }
-+    if (Test-Path $AGENTS_FILE)   { if (-not (Update-AgentFile -TargetFile $AGENTS_FILE   -AgentName 'Codex/opencode')) { $ok = $false }; $found = $true }
-+    if (Test-Path $WINDSURF_FILE) { if (-not (Update-AgentFile -TargetFile $WINDSURF_FILE -AgentName 'Windsurf')) { $ok = $false }; $found = $true }
-+    if (Test-Path $KILOCODE_FILE) { if (-not (Update-AgentFile -TargetFile $KILOCODE_FILE -AgentName 'Kilo Code')) { $ok = $false }; $found = $true }
-+    if (Test-Path $AUGGIE_FILE)   { if (-not (Update-AgentFile -TargetFile $AUGGIE_FILE   -AgentName 'Auggie CLI')) { $ok = $false }; $found = $true }
-+    if (Test-Path $ROO_FILE)      { if (-not (Update-AgentFile -TargetFile $ROO_FILE      -AgentName 'Roo Code')) { $ok = $false }; $found = $true }
-+    if (-not $found) {
-+        Write-Info 'No existing agent files found, creating default Claude file...'
-+        if (-not (Update-AgentFile -TargetFile $CLAUDE_FILE -AgentName 'Claude Code')) { $ok = $false }
-+    }
-+    return $ok
-+}
-+
-+function Print-Summary {
-+    Write-Host ''
-+    Write-Info 'Summary of changes:'
-+    if ($NEW_LANG) { Write-Host "  - Added language: $NEW_LANG" }
-+    if ($NEW_FRAMEWORK) { Write-Host "  - Added framework: $NEW_FRAMEWORK" }
-+    if ($NEW_DB -and $NEW_DB -ne 'N/A') { Write-Host "  - Added database: $NEW_DB" }
-+    Write-Host ''
-+    Write-Info 'Usage: ./update-agent-context.ps1 [-AgentType claude|gemini|copilot|cursor|qwen|opencode|codex|windsurf|kilocode|auggie|roo]'
-+}
-+
-+function Main {
-+    Validate-Environment
-+    Write-Info "=== Updating agent context files for feature $CURRENT_BRANCH ==="
-+    if (-not (Parse-PlanData -PlanFile $NEW_PLAN)) { Write-Err 'Failed to parse plan data'; exit 1 }
-+    $success = $true
-+    if ($AgentType) {
-+        Write-Info "Updating specific agent: $AgentType"
-+        if (-not (Update-SpecificAgent -Type $AgentType)) { $success = $false }
-+    }
-+    else {
-+        Write-Info 'No agent specified, updating all existing agent files...'
-+        if (-not (Update-AllExistingAgents)) { $success = $false }
-+    }
-+    Print-Summary
-+    if ($success) { Write-Success 'Agent context update completed successfully'; exit 0 } else { Write-Err 'Agent context update completed with errors'; exit 1 }
-+}
- 
--Write-Output ''
--Write-Output 'Usage: ./update-agent-context.ps1 [claude|gemini|copilot|cursor]'
-+Main
-diff --git a/spec-driven.md b/spec-driven.md
-index 0b763b9..a932c2e 100644
---- a/spec-driven.md
-+++ b/spec-driven.md
-@@ -2,15 +2,15 @@
- 
- ## The Power Inversion
- 
--For decades, code has been king. Specifications served code—they were the scaffolding we built and then discarded once the "real work" of coding began. We wrote PRDs to guide development, created design docs to inform implementation, drew diagrams to visualize architecture. But these were always subordinate to the code itself. Code was truth. Everything else was, at best, good intentions. Code was the source of truth, as it moved forward, and spec's rarely kept pace. As the asset (code) and the implementation are one, it's not easy to have a parallel implementation without trying to build from the code.
-+For decades, code has been king. Specifications served code—they were the scaffolding we built and then discarded once the "real work" of coding began. We wrote PRDs to guide development, created design docs to inform implementation, drew diagrams to visualize architecture. But these were always subordinate to the code itself. Code was truth. Everything else was, at best, good intentions. Code was the source of truth, and as it moved forward, specs rarely kept pace. As the asset (code) and the implementation are one, it's not easy to have a parallel implementation without trying to build from the code.
- 
--Spec-Driven Development (SDD) inverts this power structure. Specifications don't serve code—code serves specifications. The (Product Requirements Document-Specification) PRD isn't a guide for implementation; it's the source that generates implementation. Technical plans aren't documents that inform coding; they're precise definitions that produce code. This isn't an incremental improvement to how we build software. It's a fundamental rethinking of what drives development.
-+Spec-Driven Development (SDD) inverts this power structure. Specifications don't serve code—code serves specifications. The Product Requirements Document (PRD) isn't a guide for implementation; it's the source that generates implementation. Technical plans aren't documents that inform coding; they're precise definitions that produce code. This isn't an incremental improvement to how we build software. It's a fundamental rethinking of what drives development.
- 
--The gap between specification and implementation has plagued software development since its inception. We've tried to bridge it with better documentation, more detailed requirements, stricter processes. These approaches fail because they accept the gap as inevitable. They try to narrow it but never eliminate it. SDD eliminates the gap by making specifications or and their concrete implementation plans born from the specification executable. When specifications to implementation plans generate code, there is no gap—only transformation.
-+The gap between specification and implementation has plagued software development since its inception. We've tried to bridge it with better documentation, more detailed requirements, stricter processes. These approaches fail because they accept the gap as inevitable. They try to narrow it but never eliminate it. SDD eliminates the gap by making specifications and their concrete implementation plans born from the specification executable. When specifications and implementation plans generate code, there is no gap—only transformation.
- 
- This transformation is now possible because AI can understand and implement complex specifications, and create detailed implementation plans. But raw AI generation without structure produces chaos. SDD provides that structure through specifications and subsequent implementation plans that are precise, complete, and unambiguous enough to generate working systems. The specification becomes the primary artifact. Code becomes its expression (as an implementation from the implementation plan) in a particular language and framework.
- 
--In this new world, maintaining software means evolving specifications. The intent of the development team is expressed in natural language ("**intent-driven development**"), design assets, core principles and other guidelines . The **lingua franca** of development moves to a higher-level, and code is the last-mile approach.
-+In this new world, maintaining software means evolving specifications. The intent of the development team is expressed in natural language ("**intent-driven development**"), design assets, core principles and other guidelines. The **lingua franca** of development moves to a higher level, and code is the last-mile approach.
- 
- Debugging means fixing specifications and their implementation plans that generate incorrect code. Refactoring means restructuring for clarity. The entire development workflow reorganizes around specifications as the central source of truth, with implementation plans and code as the continuously regenerated output. Updating apps with new features or creating a new parallel implementation because we are creative beings, means revisiting the specification and creating new implementation plans. This process is therefore a 0 -> 1, (1', ..), 2, 3, N.
- 
-@@ -18,7 +18,7 @@ The development team focuses in on their creativity, experimentation, their crit
- 
- ## The SDD Workflow in Practice
- 
--The workflow begins with an idea—often vague and incomplete. Through iterative dialogue with AI, this idea becomes a comprehensive PRD. The AI asks clarifying questions, identifies edge cases, and helps define precise acceptance criteria. What might take days of meetings and documentation in traditional development happens in hours of focused specification work. This transforms the traditional SDLC—requirements and design become continuous activities rather than discrete phases. This is supportive of a **team process**, that's team reviewed-specifications are expressed and versioned, created in branches, and merged.
-+The workflow begins with an idea—often vague and incomplete. Through iterative dialogue with AI, this idea becomes a comprehensive PRD. The AI asks clarifying questions, identifies edge cases, and helps define precise acceptance criteria. What might take days of meetings and documentation in traditional development happens in hours of focused specification work. This transforms the traditional SDLC—requirements and design become continuous activities rather than discrete phases. This is supportive of a **team process**, where team-reviewed specifications are expressed and versioned, created in branches, and merged.
- 
- When a product manager updates acceptance criteria, implementation plans automatically flag affected technical decisions. When an architect discovers a better pattern, the PRD updates to reflect new possibilities.
- 
-@@ -34,13 +34,13 @@ The feedback loop extends beyond initial development. Production metrics and inc
- 
- Three trends make SDD not just possible but necessary:
- 
--First, AI capabilities have reached a threshold where natural language specifications can reliably generate working code. This isn't about replacing developers—it's about amplifying their effectiveness by automating the mechanical translation from specification to implementation. It can amplify exploration and creativity, it can support "start-over" easily, it supports addition subtraction and critical thinking.
-+First, AI capabilities have reached a threshold where natural language specifications can reliably generate working code. This isn't about replacing developers—it's about amplifying their effectiveness by automating the mechanical translation from specification to implementation. It can amplify exploration and creativity, support "start-over" easily, and support addition, subtraction, and critical thinking.
- 
- Second, software complexity continues to grow exponentially. Modern systems integrate dozens of services, frameworks, and dependencies. Keeping all these pieces aligned with original intent through manual processes becomes increasingly difficult. SDD provides systematic alignment through specification-driven generation. Frameworks may evolve to provide AI-first support, not human-first support, or architect around reusable components.
- 
- Third, the pace of change accelerates. Requirements change far more rapidly today than ever before. Pivoting is no longer exceptional—it's expected. Modern product development demands rapid iteration based on user feedback, market conditions, and competitive pressures. Traditional development treats these changes as disruptions. Each pivot requires manually propagating changes through documentation, design, and code. The result is either slow, careful updates that limit velocity, or fast, reckless changes that accumulate technical debt.
- 
--SDD can support what-if/simulation experiments, "If we need to re-implement or change the application to promote a business need to sell more T-shirts, how would we implement and experiment for that?".
-+SDD can support what-if/simulation experiments: "If we need to re-implement or change the application to promote a business need to sell more T-shirts, how would we implement and experiment for that?"
- 
- SDD transforms requirement changes from obstacles into normal workflow. When specifications drive implementation, pivots become systematic regenerations rather than manual rewrites. Change a core requirement in the PRD, and affected implementation plans update automatically. Modify a user story, and corresponding API endpoints regenerate. This isn't just about initial development—it's about maintaining engineering velocity through inevitable changes.
- 
-diff --git a/src/specify_cli/__init__.py b/src/specify_cli/__init__.py
-index 88c1669..83d2fdf 100644
---- a/src/specify_cli/__init__.py
-+++ b/src/specify_cli/__init__.py
-@@ -28,6 +28,7 @@ import sys
- import zipfile
- import tempfile
- import shutil
-+import shlex
- import json
- from pathlib import Path
- from typing import Optional, Tuple
-@@ -52,12 +53,28 @@ import truststore
- ssl_context = truststore.SSLContext(ssl.PROTOCOL_TLS_CLIENT)
- client = httpx.Client(verify=ssl_context)
- 
-+def _github_token(cli_token: str | None = None) -> str | None:
-+    """Return sanitized GitHub token (cli arg takes precedence) or None."""
-+    return ((cli_token or os.getenv("GH_TOKEN") or os.getenv("GITHUB_TOKEN") or "").strip()) or None
-+
-+def _github_auth_headers(cli_token: str | None = None) -> dict:
-+    """Return Authorization header dict only when a non-empty token exists."""
-+    token = _github_token(cli_token)
-+    return {"Authorization": f"Bearer {token}"} if token else {}
-+
- # Constants
- AI_CHOICES = {
-     "copilot": "GitHub Copilot",
-     "claude": "Claude Code",
-     "gemini": "Gemini CLI",
--    "cursor": "Cursor"
-+    "cursor": "Cursor",
-+    "qwen": "Qwen Code",
-+    "opencode": "opencode",
-+    "codex": "Codex CLI",
-+    "windsurf": "Windsurf",
-+    "kilocode": "Kilo Code",
-+    "auggie": "Auggie CLI",
-+    "roo": "Roo Code",
- }
- # Add script type choices
- SCRIPT_TYPE_CHOICES = {"sh": "POSIX Shell (bash/zsh)", "ps": "PowerShell"}
-@@ -75,7 +92,7 @@ BANNER = """
- ╚══════╝╚═╝     ╚══════╝ ╚═════╝╚═╝╚═╝        ╚═╝   
- """
- 
--TAGLINE = "Spec-Driven Development Toolkit"
-+TAGLINE = "GitHub Spec Kit - Spec-Driven Development Toolkit"
- class StepTracker:
-     """Track and render hierarchical steps without emojis, similar to Claude Code tree output.
-     Supports live auto-refresh via an attached refresh callback.
-@@ -126,7 +143,7 @@ class StepTracker:
-                 pass
- 
-     def render(self):
--        tree = Tree(f"[bold cyan]{self.title}[/bold cyan]", guide_style="grey50")
-+        tree = Tree(f"[cyan]{self.title}[/cyan]", guide_style="grey50")
-         for step in self.steps:
-             label = step["label"]
-             detail_text = step["detail"].strip() if step["detail"] else ""
-@@ -219,14 +236,14 @@ def select_with_arrows(options: dict, prompt_text: str = "Select an option", def
-     def create_selection_panel():
-         """Create the selection panel with current selection highlighted."""
-         table = Table.grid(padding=(0, 2))
--        table.add_column(style="bright_cyan", justify="left", width=3)
-+        table.add_column(style="cyan", justify="left", width=3)
-         table.add_column(style="white", justify="left")
-         
-         for i, key in enumerate(option_keys):
-             if i == selected_index:
--                table.add_row("▶", f"[bright_cyan]{key}: {options[key]}[/bright_cyan]")
-+                table.add_row("▶", f"[cyan]{key}[/cyan] [dim]({options[key]})[/dim]")
-             else:
--                table.add_row(" ", f"[white]{key}: {options[key]}[/white]")
-+                table.add_row(" ", f"[cyan]{key}[/cyan] [dim]({options[key]})[/dim]")
-         
-         table.add_row("", "")
-         table.add_row("", "[dim]Use ↑/↓ to navigate, Enter to select, Esc to cancel[/dim]")
-@@ -341,13 +358,13 @@ def run_command(cmd: list[str], check_return: bool = True, capture: bool = False
-         return None
- 
- 
--def check_tool_for_tracker(tool: str, install_hint: str, tracker: StepTracker) -> bool:
-+def check_tool_for_tracker(tool: str, tracker: StepTracker) -> bool:
-     """Check if a tool is installed and update tracker."""
-     if shutil.which(tool):
-         tracker.complete(tool, "available")
-         return True
-     else:
--        tracker.error(tool, f"not found - {install_hint}")
-+        tracker.error(tool, "not found")
-         return False
- 
- 
-@@ -366,8 +383,6 @@ def check_tool(tool: str, install_hint: str) -> bool:
-     if shutil.which(tool):
-         return True
-     else:
--        console.print(f"[yellow]⚠️  {tool} not found[/yellow]")
--        console.print(f"   Install with: [cyan]{install_hint}[/cyan]")
-         return False
- 
- 
-@@ -416,7 +431,7 @@ def init_git_repo(project_path: Path, quiet: bool = False) -> bool:
-         os.chdir(original_cwd)
- 
- 
--def download_template_from_github(ai_assistant: str, download_dir: Path, *, script_type: str = "sh", verbose: bool = True, show_progress: bool = True, client: httpx.Client = None, debug: bool = False) -> Tuple[Path, dict]:
-+def download_template_from_github(ai_assistant: str, download_dir: Path, *, script_type: str = "sh", verbose: bool = True, show_progress: bool = True, client: httpx.Client = None, debug: bool = False, github_token: str = None) -> Tuple[Path, dict]:
-     repo_owner = "github"
-     repo_name = "spec-kit"
-     if client is None:
-@@ -427,7 +442,12 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
-     api_url = f"https://api.github.com/repos/{repo_owner}/{repo_name}/releases/latest"
-     
-     try:
--        response = client.get(api_url, timeout=30, follow_redirects=True)
-+        response = client.get(
-+            api_url,
-+            timeout=30,
-+            follow_redirects=True,
-+            headers=_github_auth_headers(github_token),
-+        )
-         status = response.status_code
-         if status != 200:
-             msg = f"GitHub API returned {status} for {api_url}"
-@@ -444,20 +464,21 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
-         raise typer.Exit(1)
-     
-     # Find the template asset for the specified AI assistant
-+    assets = release_data.get("assets", [])
-     pattern = f"spec-kit-template-{ai_assistant}-{script_type}"
-     matching_assets = [
--        asset for asset in release_data.get("assets", [])
-+        asset for asset in assets
-         if pattern in asset["name"] and asset["name"].endswith(".zip")
-     ]
--    
--    if not matching_assets:
--        console.print(f"[red]No matching release asset found[/red] for pattern: [bold]{pattern}[/bold]")
--        asset_names = [a.get('name','?') for a in release_data.get('assets', [])]
-+
-+    asset = matching_assets[0] if matching_assets else None
-+
-+    if asset is None:
-+        console.print(f"[red]No matching release asset found[/red] for [bold]{ai_assistant}[/bold] (expected pattern: [bold]{pattern}[/bold])")
-+        asset_names = [a.get('name', '?') for a in assets]
-         console.print(Panel("\n".join(asset_names) or "(no assets)", title="Available Assets", border_style="yellow"))
-         raise typer.Exit(1)
--    
--    # Use the first matching asset
--    asset = matching_assets[0]
-+
-     download_url = asset["browser_download_url"]
-     filename = asset["name"]
-     file_size = asset["size"]
-@@ -466,14 +487,19 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
-         console.print(f"[cyan]Found template:[/cyan] {filename}")
-         console.print(f"[cyan]Size:[/cyan] {file_size:,} bytes")
-         console.print(f"[cyan]Release:[/cyan] {release_data['tag_name']}")
--    
--    # Download the file
-+
-     zip_path = download_dir / filename
-     if verbose:
-         console.print(f"[cyan]Downloading template...[/cyan]")
-     
-     try:
--        with client.stream("GET", download_url, timeout=60, follow_redirects=True) as response:
-+        with client.stream(
-+            "GET",
-+            download_url,
-+            timeout=60,
-+            follow_redirects=True,
-+            headers=_github_auth_headers(github_token),
-+        ) as response:
-             if response.status_code != 200:
-                 body_sample = response.text[:400]
-                 raise RuntimeError(f"Download failed with {response.status_code}\nHeaders: {response.headers}\nBody (truncated): {body_sample}")
-@@ -517,7 +543,7 @@ def download_template_from_github(ai_assistant: str, download_dir: Path, *, scri
-     return zip_path, metadata
- 
- 
--def download_and_extract_template(project_path: Path, ai_assistant: str, script_type: str, is_current_dir: bool = False, *, verbose: bool = True, tracker: StepTracker | None = None, client: httpx.Client = None, debug: bool = False) -> Path:
-+def download_and_extract_template(project_path: Path, ai_assistant: str, script_type: str, is_current_dir: bool = False, *, verbose: bool = True, tracker: StepTracker | None = None, client: httpx.Client = None, debug: bool = False, github_token: str = None) -> Path:
-     """Download the latest release and extract it to create a new project.
-     Returns project_path. Uses tracker if provided (with keys: fetch, download, extract, cleanup)
-     """
-@@ -534,7 +560,8 @@ def download_and_extract_template(project_path: Path, ai_assistant: str, script_
-             verbose=verbose and tracker is None,
-             show_progress=(tracker is None),
-             client=client,
--            debug=debug
-+            debug=debug,
-+            github_token=github_token
-         )
-         if tracker:
-             tracker.complete("fetch", f"release {meta['release']} ({meta['size']:,} bytes)")
-@@ -718,24 +745,25 @@ def ensure_executable_scripts(project_path: Path, tracker: StepTracker | None =
-             for f in failures:
-                 console.print(f"  - {f}")
- 
--
- @app.command()
- def init(
-     project_name: str = typer.Argument(None, help="Name for your new project directory (optional if using --here)"),
--    ai_assistant: str = typer.Option(None, "--ai", help="AI assistant to use: claude, gemini, copilot, or cursor"),
-+    ai_assistant: str = typer.Option(None, "--ai", help="AI assistant to use: claude, gemini, copilot, cursor, qwen, opencode, codex, windsurf, kilocode, or auggie"),
-     script_type: str = typer.Option(None, "--script", help="Script type to use: sh or ps"),
-     ignore_agent_tools: bool = typer.Option(False, "--ignore-agent-tools", help="Skip checks for AI agent tools like Claude Code"),
-     no_git: bool = typer.Option(False, "--no-git", help="Skip git repository initialization"),
-     here: bool = typer.Option(False, "--here", help="Initialize project in the current directory instead of creating a new one"),
-+    force: bool = typer.Option(False, "--force", help="Force merge/overwrite when using --here (skip confirmation)"),
-     skip_tls: bool = typer.Option(False, "--skip-tls", help="Skip SSL/TLS verification (not recommended)"),
-     debug: bool = typer.Option(False, "--debug", help="Show verbose diagnostic output for network and extraction failures"),
-+    github_token: str = typer.Option(None, "--github-token", help="GitHub token to use for API requests (or set GH_TOKEN or GITHUB_TOKEN environment variable)"),
- ):
-     """
-     Initialize a new Specify project from the latest template.
-     
-     This command will:
-     1. Check that required tools are installed (git is optional)
--    2. Let you choose your AI assistant (Claude Code, Gemini CLI, GitHub Copilot, or Cursor)
-+    2. Let you choose your AI assistant (Claude Code, Gemini CLI, GitHub Copilot, Cursor, Qwen Code, opencode, Codex CLI, Windsurf, Kilo Code, or Auggie CLI)
-     3. Download the appropriate template from GitHub
-     4. Extract the template to a new project directory or current directory
-     5. Initialize a fresh git repository (if not --no-git and no existing repo)
-@@ -747,9 +775,16 @@ def init(
-         specify init my-project --ai gemini
-         specify init my-project --ai copilot --no-git
-         specify init my-project --ai cursor
-+        specify init my-project --ai qwen
-+        specify init my-project --ai opencode
-+        specify init my-project --ai codex
-+        specify init my-project --ai windsurf
-+        specify init my-project --ai auggie
-         specify init --ignore-agent-tools my-project
-         specify init --here --ai claude
-+        specify init --here --ai codex
-         specify init --here
-+        specify init --here --force  # Skip confirmation when current directory not empty
-     """
-     # Show banner first
-     show_banner()
-@@ -773,31 +808,51 @@ def init(
-         if existing_items:
-             console.print(f"[yellow]Warning:[/yellow] Current directory is not empty ({len(existing_items)} items)")
-             console.print("[yellow]Template files will be merged with existing content and may overwrite existing files[/yellow]")
--            
--            # Ask for confirmation
--            response = typer.confirm("Do you want to continue?")
--            if not response:
--                console.print("[yellow]Operation cancelled[/yellow]")
--                raise typer.Exit(0)
-+            if force:
-+                console.print("[cyan]--force supplied: skipping confirmation and proceeding with merge[/cyan]")
-+            else:
-+                # Ask for confirmation
-+                response = typer.confirm("Do you want to continue?")
-+                if not response:
-+                    console.print("[yellow]Operation cancelled[/yellow]")
-+                    raise typer.Exit(0)
-     else:
-         project_path = Path(project_name).resolve()
-         # Check if project directory already exists
-         if project_path.exists():
--            console.print(f"[red]Error:[/red] Directory '{project_name}' already exists")
-+            error_panel = Panel(
-+                f"Directory '[cyan]{project_name}[/cyan]' already exists\n"
-+                "Please choose a different project name or remove the existing directory.",
-+                title="[red]Directory Conflict[/red]",
-+                border_style="red",
-+                padding=(1, 2)
-+            )
-+            console.print()
-+            console.print(error_panel)
-             raise typer.Exit(1)
-     
--    console.print(Panel.fit(
--        "[bold cyan]Specify Project Setup[/bold cyan]\n"
--        f"{'Initializing in current directory:' if here else 'Creating new project:'} [green]{project_path.name}[/green]"
--        + (f"\n[dim]Path: {project_path}[/dim]" if here else ""),
--        border_style="cyan"
--    ))
-+    # Create formatted setup info with column alignment
-+    current_dir = Path.cwd()
-+    
-+    setup_lines = [
-+        "[cyan]Specify Project Setup[/cyan]",
-+        "",
-+        f"{'Project':<15} [green]{project_path.name}[/green]",
-+        f"{'Working Path':<15} [dim]{current_dir}[/dim]",
-+    ]
-+    
-+    # Add target path only if different from working dir
-+    if not here:
-+        setup_lines.append(f"{'Target Path':<15} [dim]{project_path}[/dim]")
-+    
-+    console.print(Panel("\n".join(setup_lines), border_style="cyan", padding=(1, 2)))
-     
-     # Check git only if we might need it (not --no-git)
--    git_available = True
-+    # Only set to True if the user wants it and the tool is available
-+    should_init_git = False
-     if not no_git:
--        git_available = check_tool("git", "https://git-scm.com/downloads")
--        if not git_available:
-+        should_init_git = check_tool("git", "https://git-scm.com/downloads")
-+        if not should_init_git:
-             console.print("[yellow]Git not found - will skip repository initialization[/yellow]")
- 
-     # AI assistant selection
-@@ -817,18 +872,45 @@ def init(
-     # Check agent tools unless ignored
-     if not ignore_agent_tools:
-         agent_tool_missing = False
-+        install_url = ""
-         if selected_ai == "claude":
--            if not check_tool("claude", "Install from: https://docs.anthropic.com/en/docs/claude-code/setup"):
--                console.print("[red]Error:[/red] Claude CLI is required for Claude Code projects")
-+            if not check_tool("claude", "https://docs.anthropic.com/en/docs/claude-code/setup"):
-+                install_url = "https://docs.anthropic.com/en/docs/claude-code/setup"
-                 agent_tool_missing = True
-         elif selected_ai == "gemini":
--            if not check_tool("gemini", "Install from: https://github.com/google-gemini/gemini-cli"):
--                console.print("[red]Error:[/red] Gemini CLI is required for Gemini projects")
-+            if not check_tool("gemini", "https://github.com/google-gemini/gemini-cli"):
-+                install_url = "https://github.com/google-gemini/gemini-cli"
-+                agent_tool_missing = True
-+        elif selected_ai == "qwen":
-+            if not check_tool("qwen", "https://github.com/QwenLM/qwen-code"):
-+                install_url = "https://github.com/QwenLM/qwen-code"
-+                agent_tool_missing = True
-+        elif selected_ai == "opencode":
-+            if not check_tool("opencode", "https://opencode.ai"):
-+                install_url = "https://opencode.ai"
-                 agent_tool_missing = True
-+        elif selected_ai == "codex":
-+            if not check_tool("codex", "https://github.com/openai/codex"):
-+                install_url = "https://github.com/openai/codex"
-+                agent_tool_missing = True
-+        elif selected_ai == "auggie":
-+            if not check_tool("auggie", "https://docs.augmentcode.com/cli/setup-auggie/install-auggie-cli"):
-+                install_url = "https://docs.augmentcode.com/cli/setup-auggie/install-auggie-cli"
-+                agent_tool_missing = True
-+        # GitHub Copilot and Cursor checks are not needed as they're typically available in supported IDEs
- 
-         if agent_tool_missing:
--            console.print("\n[red]Required AI tool is missing![/red]")
--            console.print("[yellow]Tip:[/yellow] Use --ignore-agent-tools to skip this check")
-+            error_panel = Panel(
-+                f"[cyan]{selected_ai}[/cyan] not found\n"
-+                f"Install with: [cyan]{install_url}[/cyan]\n"
-+                f"{AI_CHOICES[selected_ai]} is required to continue with this project type.\n\n"
-+                "Tip: Use [cyan]--ignore-agent-tools[/cyan] to skip this check",
-+                title="[red]Agent Detection Error[/red]",
-+                border_style="red",
-+                padding=(1, 2)
-+            )
-+            console.print()
-+            console.print(error_panel)
-             raise typer.Exit(1)
-     
-     # Determine script type (explicit, interactive, or OS default)
-@@ -867,7 +949,7 @@ def init(
-         ("extract", "Extract template"),
-         ("zip-list", "Archive contents"),
-         ("extracted-summary", "Extraction summary"),
--    ("chmod", "Ensure scripts executable"),
-+        ("chmod", "Ensure scripts executable"),
-         ("cleanup", "Cleanup"),
-         ("git", "Initialize git repository"),
-         ("final", "Finalize")
-@@ -883,7 +965,7 @@ def init(
-             local_ssl_context = ssl_context if verify else False
-             local_client = httpx.Client(verify=local_ssl_context)
- 
--            download_and_extract_template(project_path, selected_ai, selected_script, here, verbose=False, tracker=tracker, client=local_client, debug=debug)
-+            download_and_extract_template(project_path, selected_ai, selected_script, here, verbose=False, tracker=tracker, client=local_client, debug=debug, github_token=github_token)
- 
-             # Ensure scripts are executable (POSIX)
-             ensure_executable_scripts(project_path, tracker=tracker)
-@@ -893,7 +975,7 @@ def init(
-                 tracker.start("git")
-                 if is_git_repo(project_path):
-                     tracker.complete("git", "existing repo detected")
--                elif git_available:
-+                elif should_init_git:
-                     if init_git_repo(project_path, quiet=True):
-                         tracker.complete("git", "initialized")
-                     else:
-@@ -927,40 +1009,77 @@ def init(
-     console.print(tracker.render())
-     console.print("\n[bold green]Project ready.[/bold green]")
-     
-+    # Agent folder security notice
-+    agent_folder_map = {
-+        "claude": ".claude/",
-+        "gemini": ".gemini/",
-+        "cursor": ".cursor/",
-+        "qwen": ".qwen/",
-+        "opencode": ".opencode/",
-+        "codex": ".codex/",
-+        "windsurf": ".windsurf/",
-+        "kilocode": ".kilocode/",
-+        "auggie": ".augment/",
-+        "copilot": ".github/",
-+        "roo": ".roo/"
-+    }
-+    
-+    if selected_ai in agent_folder_map:
-+        agent_folder = agent_folder_map[selected_ai]
-+        security_notice = Panel(
-+            f"Some agents may store credentials, auth tokens, or other identifying and private artifacts in the agent folder within your project.\n"
-+            f"Consider adding [cyan]{agent_folder}[/cyan] (or parts of it) to [cyan].gitignore[/cyan] to prevent accidental credential leakage.",
-+            title="[yellow]Agent Folder Security[/yellow]",
-+            border_style="yellow",
-+            padding=(1, 2)
-+        )
-+        console.print()
-+        console.print(security_notice)
-+    
-     # Boxed "Next steps" section
-     steps_lines = []
-     if not here:
--        steps_lines.append(f"1. [bold green]cd {project_name}[/bold green]")
-+        steps_lines.append(f"1. Go to the project folder: [cyan]cd {project_name}[/cyan]")
-         step_num = 2
-     else:
-         steps_lines.append("1. You're already in the project directory!")
-         step_num = 2
- 
--    if selected_ai == "claude":
--        steps_lines.append(f"{step_num}. Open in Visual Studio Code and start using / commands with Claude Code")
--        steps_lines.append("   - Type / in any file to see available commands")
--        steps_lines.append("   - Use /specify to create specifications")
--        steps_lines.append("   - Use /plan to create implementation plans")
--        steps_lines.append("   - Use /tasks to generate tasks")
--    elif selected_ai == "gemini":
--        steps_lines.append(f"{step_num}. Use / commands with Gemini CLI")
--        steps_lines.append("   - Run gemini /specify to create specifications")
--        steps_lines.append("   - Run gemini /plan to create implementation plans")
--        steps_lines.append("   - Run gemini /tasks to generate tasks")
--        steps_lines.append("   - See GEMINI.md for all available commands")
--    elif selected_ai == "copilot":
--        steps_lines.append(f"{step_num}. Open in Visual Studio Code and use [bold cyan]/specify[/], [bold cyan]/plan[/], [bold cyan]/tasks[/] commands with GitHub Copilot")
--
--    # Removed script variant step (scripts are transparent to users)
--    step_num += 1
--    steps_lines.append(f"{step_num}. Update [bold magenta]CONSTITUTION.md[/bold magenta] with your project's non-negotiable principles")
--
--    steps_panel = Panel("\n".join(steps_lines), title="Next steps", border_style="cyan", padding=(1,2))
--    console.print()  # blank line
-+    # Add Codex-specific setup step if needed
-+    if selected_ai == "codex":
-+        codex_path = project_path / ".codex"
-+        quoted_path = shlex.quote(str(codex_path))
-+        if os.name == "nt":  # Windows
-+            cmd = f"setx CODEX_HOME {quoted_path}"
-+        else:  # Unix-like systems
-+            cmd = f"export CODEX_HOME={quoted_path}"
-+        
-+        steps_lines.append(f"{step_num}. Set [cyan]CODEX_HOME[/cyan] environment variable before running Codex: [cyan]{cmd}[/cyan]")
-+        step_num += 1
-+
-+    steps_lines.append(f"{step_num}. Start using slash commands with your AI agent:")
-+    steps_lines.append("   2.1 [cyan]/constitution[/] - Establish project principles")
-+    steps_lines.append("   2.2 [cyan]/specify[/] - Create specifications")
-+    steps_lines.append("   2.3 [cyan]/clarify[/] - Clarify and de-risk specification (run before [cyan]/plan[/cyan])")
-+    steps_lines.append("   2.4 [cyan]/plan[/] - Create implementation plans")
-+    steps_lines.append("   2.5 [cyan]/tasks[/] - Generate actionable tasks")
-+    steps_lines.append("   2.6 [cyan]/analyze[/] - Validate alignment & surface inconsistencies (read-only)")
-+    steps_lines.append("   2.7 [cyan]/implement[/] - Execute implementation")
-+
-+    steps_panel = Panel("\n".join(steps_lines), title="Next Steps", border_style="cyan", padding=(1,2))
-+    console.print()
-     console.print(steps_panel)
--    
--    # Removed farewell line per user request
- 
-+    if selected_ai == "codex":
-+        warning_text = """[bold yellow]Important Note:[/bold yellow]
-+
-+Custom prompts do not yet support arguments in Codex. You may need to manually specify additional project instructions directly in prompt files located in [cyan].codex/prompts/[/cyan].
-+
-+For more information, see: [cyan]https://github.com/openai/codex/issues/2890[/cyan]"""
-+        
-+        warning_panel = Panel(warning_text, title="Slash Commands in Codex", border_style="yellow", padding=(1,2))
-+        console.print()
-+        console.print(warning_panel)
- 
- @app.command()
- def check():
-@@ -968,36 +1087,41 @@ def check():
-     show_banner()
-     console.print("[bold]Checking for installed tools...[/bold]\n")
- 
--    # Create tracker for checking tools
-     tracker = StepTracker("Check Available Tools")
-     
--    # Add all tools we want to check
-     tracker.add("git", "Git version control")
-     tracker.add("claude", "Claude Code CLI")
-     tracker.add("gemini", "Gemini CLI")
--    tracker.add("code", "VS Code (for GitHub Copilot)")
--    tracker.add("cursor-agent", "Cursor IDE agent (optional)")
--    
--    # Check each tool
--    git_ok = check_tool_for_tracker("git", "https://git-scm.com/downloads", tracker)
--    claude_ok = check_tool_for_tracker("claude", "https://docs.anthropic.com/en/docs/claude-code/setup", tracker)  
--    gemini_ok = check_tool_for_tracker("gemini", "https://github.com/google-gemini/gemini-cli", tracker)
--    # Check for VS Code (code or code-insiders)
--    code_ok = check_tool_for_tracker("code", "https://code.visualstudio.com/", tracker)
--    if not code_ok:
--        code_ok = check_tool_for_tracker("code-insiders", "https://code.visualstudio.com/insiders/", tracker)
--    cursor_ok = check_tool_for_tracker("cursor-agent", "https://cursor.sh/", tracker)
--    
--    # Render the final tree
--    console.print(tracker.render())
-+    tracker.add("qwen", "Qwen Code CLI")
-+    tracker.add("code", "Visual Studio Code")
-+    tracker.add("code-insiders", "Visual Studio Code Insiders")
-+    tracker.add("cursor-agent", "Cursor IDE agent")
-+    tracker.add("windsurf", "Windsurf IDE")
-+    tracker.add("kilocode", "Kilo Code IDE")
-+    tracker.add("opencode", "opencode")
-+    tracker.add("codex", "Codex CLI")
-+    tracker.add("auggie", "Auggie CLI")
-     
--    # Summary
-+    git_ok = check_tool_for_tracker("git", tracker)
-+    claude_ok = check_tool_for_tracker("claude", tracker)  
-+    gemini_ok = check_tool_for_tracker("gemini", tracker)
-+    qwen_ok = check_tool_for_tracker("qwen", tracker)
-+    code_ok = check_tool_for_tracker("code", tracker)
-+    code_insiders_ok = check_tool_for_tracker("code-insiders", tracker)
-+    cursor_ok = check_tool_for_tracker("cursor-agent", tracker)
-+    windsurf_ok = check_tool_for_tracker("windsurf", tracker)
-+    kilocode_ok = check_tool_for_tracker("kilocode", tracker)
-+    opencode_ok = check_tool_for_tracker("opencode", tracker)
-+    codex_ok = check_tool_for_tracker("codex", tracker)
-+    auggie_ok = check_tool_for_tracker("auggie", tracker)
-+
-+    console.print(tracker.render())
-+
-     console.print("\n[bold green]Specify CLI is ready to use![/bold green]")
--    
--    # Recommendations
-+
-     if not git_ok:
-         console.print("[dim]Tip: Install git for repository management[/dim]")
--    if not (claude_ok or gemini_ok):
-+    if not (claude_ok or gemini_ok or cursor_ok or qwen_ok or windsurf_ok or kilocode_ok or opencode_ok or codex_ok or auggie_ok):
-         console.print("[dim]Tip: Install an AI assistant for the best experience[/dim]")
- 
- 
-diff --git a/templates/commands/analyze.md b/templates/commands/analyze.md
-new file mode 100644
-index 0000000..c07d550
---- /dev/null
-+++ b/templates/commands/analyze.md
-@@ -0,0 +1,104 @@
-+---
-+description: Perform a non-destructive cross-artifact consistency and quality analysis across spec.md, plan.md, and tasks.md after task generation.
-+scripts:
-+  sh: scripts/bash/check-prerequisites.sh --json --require-tasks --include-tasks
-+  ps: scripts/powershell/check-prerequisites.ps1 -Json -RequireTasks -IncludeTasks
-+---
-+
-+The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
-+
-+Goal: Identify inconsistencies, duplications, ambiguities, and underspecified items across the three core artifacts (`spec.md`, `plan.md`, `tasks.md`) before implementation. This command MUST run only after `/tasks` has successfully produced a complete `tasks.md`.
-+
-+STRICTLY READ-ONLY: Do **not** modify any files. Output a structured analysis report. Offer an optional remediation plan (user must explicitly approve before any follow-up editing commands would be invoked manually).
-+
-+Constitution Authority: The project constitution (`/memory/constitution.md`) is **non-negotiable** within this analysis scope. Constitution conflicts are automatically CRITICAL and require adjustment of the spec, plan, or tasks—not dilution, reinterpretation, or silent ignoring of the principle. If a principle itself needs to change, that must occur in a separate, explicit constitution update outside `/analyze`.
-+
-+Execution steps:
-+
-+1. Run `{SCRIPT}` once from repo root and parse JSON for FEATURE_DIR and AVAILABLE_DOCS. Derive absolute paths:
-+   - SPEC = FEATURE_DIR/spec.md
-+   - PLAN = FEATURE_DIR/plan.md
-+   - TASKS = FEATURE_DIR/tasks.md
-+   Abort with an error message if any required file is missing (instruct the user to run missing prerequisite command).
-+
-+2. Load artifacts:
-+   - Parse spec.md sections: Overview/Context, Functional Requirements, Non-Functional Requirements, User Stories, Edge Cases (if present).
-+   - Parse plan.md: Architecture/stack choices, Data Model references, Phases, Technical constraints.
-+   - Parse tasks.md: Task IDs, descriptions, phase grouping, parallel markers [P], referenced file paths.
-+   - Load constitution `/memory/constitution.md` for principle validation.
-+
-+3. Build internal semantic models:
-+   - Requirements inventory: Each functional + non-functional requirement with a stable key (derive slug based on imperative phrase; e.g., "User can upload file" -> `user-can-upload-file`).
-+   - User story/action inventory.
-+   - Task coverage mapping: Map each task to one or more requirements or stories (inference by keyword / explicit reference patterns like IDs or key phrases).
-+   - Constitution rule set: Extract principle names and any MUST/SHOULD normative statements.
-+
-+4. Detection passes:
-+   A. Duplication detection:
-+      - Identify near-duplicate requirements. Mark lower-quality phrasing for consolidation.
-+   B. Ambiguity detection:
-+      - Flag vague adjectives (fast, scalable, secure, intuitive, robust) lacking measurable criteria.
-+      - Flag unresolved placeholders (TODO, TKTK, ???, <placeholder>, etc.).
-+   C. Underspecification:
-+      - Requirements with verbs but missing object or measurable outcome.
-+      - User stories missing acceptance criteria alignment.
-+      - Tasks referencing files or components not defined in spec/plan.
-+   D. Constitution alignment:
-+      - Any requirement or plan element conflicting with a MUST principle.
-+      - Missing mandated sections or quality gates from constitution.
-+   E. Coverage gaps:
-+      - Requirements with zero associated tasks.
-+      - Tasks with no mapped requirement/story.
-+      - Non-functional requirements not reflected in tasks (e.g., performance, security).
-+   F. Inconsistency:
-+      - Terminology drift (same concept named differently across files).
-+      - Data entities referenced in plan but absent in spec (or vice versa).
-+      - Task ordering contradictions (e.g., integration tasks before foundational setup tasks without dependency note).
-+      - Conflicting requirements (e.g., one requires to use Next.js while other says to use Vue as the framework).
-+
-+5. Severity assignment heuristic:
-+   - CRITICAL: Violates constitution MUST, missing core spec artifact, or requirement with zero coverage that blocks baseline functionality.
-+   - HIGH: Duplicate or conflicting requirement, ambiguous security/performance attribute, untestable acceptance criterion.
-+   - MEDIUM: Terminology drift, missing non-functional task coverage, underspecified edge case.
-+   - LOW: Style/wording improvements, minor redundancy not affecting execution order.
-+
-+6. Produce a Markdown report (no file writes) with sections:
-+
-+   ### Specification Analysis Report
-+   | ID | Category | Severity | Location(s) | Summary | Recommendation |
-+   |----|----------|----------|-------------|---------|----------------|
-+   | A1 | Duplication | HIGH | spec.md:L120-134 | Two similar requirements ... | Merge phrasing; keep clearer version |
-+   (Add one row per finding; generate stable IDs prefixed by category initial.)
-+
-+   Additional subsections:
-+   - Coverage Summary Table:
-+     | Requirement Key | Has Task? | Task IDs | Notes |
-+   - Constitution Alignment Issues (if any)
-+   - Unmapped Tasks (if any)
-+   - Metrics:
-+     * Total Requirements
-+     * Total Tasks
-+     * Coverage % (requirements with >=1 task)
-+     * Ambiguity Count
-+     * Duplication Count
-+     * Critical Issues Count
-+
-+7. At end of report, output a concise Next Actions block:
-+   - If CRITICAL issues exist: Recommend resolving before `/implement`.
-+   - If only LOW/MEDIUM: User may proceed, but provide improvement suggestions.
-+   - Provide explicit command suggestions: e.g., "Run /specify with refinement", "Run /plan to adjust architecture", "Manually edit tasks.md to add coverage for 'performance-metrics'".
-+
-+8. Ask the user: "Would you like me to suggest concrete remediation edits for the top N issues?" (Do NOT apply them automatically.)
-+
-+Behavior rules:
-+- NEVER modify files.
-+- NEVER hallucinate missing sections—if absent, report them.
-+- KEEP findings deterministic: if rerun without changes, produce consistent IDs and counts.
-+- LIMIT total findings in the main table to 50; aggregate remainder in a summarized overflow note.
-+- If zero issues found, emit a success report with coverage statistics and proceed recommendation.
-+
-+Context: {ARGS}
-diff --git a/templates/commands/clarify.md b/templates/commands/clarify.md
-new file mode 100644
-index 0000000..e3f4a79
---- /dev/null
-+++ b/templates/commands/clarify.md
-@@ -0,0 +1,161 @@
-+---
-+description: Identify underspecified areas in the current feature spec by asking up to 5 highly targeted clarification questions and encoding answers back into the spec.
-+scripts:
-+   sh: scripts/bash/check-prerequisites.sh --json --paths-only
-+   ps: scripts/powershell/check-prerequisites.ps1 -Json -PathsOnly
-+---
-+
-+The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
-+
-+Goal: Detect and reduce ambiguity or missing decision points in the active feature specification and record the clarifications directly in the spec file.
-+
-+Note: This clarification workflow is expected to run (and be completed) BEFORE invoking `/plan`. If the user explicitly states they are skipping clarification (e.g., exploratory spike), you may proceed, but must warn that downstream rework risk increases.
-+
-+Execution steps:
-+
-+1. Run `{SCRIPT}` from repo root **once** (combined `--json --paths-only` mode / `-Json -PathsOnly`). Parse minimal JSON payload fields:
-+   - `FEATURE_DIR`
-+   - `FEATURE_SPEC`
-+   - (Optionally capture `IMPL_PLAN`, `TASKS` for future chained flows.)
-+   - If JSON parsing fails, abort and instruct user to re-run `/specify` or verify feature branch environment.
-+
-+2. Load the current spec file. Perform a structured ambiguity & coverage scan using this taxonomy. For each category, mark status: Clear / Partial / Missing. Produce an internal coverage map used for prioritization (do not output raw map unless no questions will be asked).
-+
-+   Functional Scope & Behavior:
-+   - Core user goals & success criteria
-+   - Explicit out-of-scope declarations
-+   - User roles / personas differentiation
-+
-+   Domain & Data Model:
-+   - Entities, attributes, relationships
-+   - Identity & uniqueness rules
-+   - Lifecycle/state transitions
-+   - Data volume / scale assumptions
-+
-+   Interaction & UX Flow:
-+   - Critical user journeys / sequences
-+   - Error/empty/loading states
-+   - Accessibility or localization notes
-+
-+   Non-Functional Quality Attributes:
-+   - Performance (latency, throughput targets)
-+   - Scalability (horizontal/vertical, limits)
-+   - Reliability & availability (uptime, recovery expectations)
-+   - Observability (logging, metrics, tracing signals)
-+   - Security & privacy (authN/Z, data protection, threat assumptions)
-+   - Compliance / regulatory constraints (if any)
-+
-+   Integration & External Dependencies:
-+   - External services/APIs and failure modes
-+   - Data import/export formats
-+   - Protocol/versioning assumptions
-+
-+   Edge Cases & Failure Handling:
-+   - Negative scenarios
-+   - Rate limiting / throttling
-+   - Conflict resolution (e.g., concurrent edits)
-+
-+   Constraints & Tradeoffs:
-+   - Technical constraints (language, storage, hosting)
-+   - Explicit tradeoffs or rejected alternatives
-+
-+   Terminology & Consistency:
-+   - Canonical glossary terms
-+   - Avoided synonyms / deprecated terms
-+
-+   Completion Signals:
-+   - Acceptance criteria testability
-+   - Measurable Definition of Done style indicators
-+
-+   Misc / Placeholders:
-+   - TODO markers / unresolved decisions
-+   - Ambiguous adjectives ("robust", "intuitive") lacking quantification
-+
-+   For each category with Partial or Missing status, add a candidate question opportunity unless:
-+   - Clarification would not materially change implementation or validation strategy
-+   - Information is better deferred to planning phase (note internally)
-+
-+3. Generate (internally) a prioritized queue of candidate clarification questions (maximum 5). Do NOT output them all at once. Apply these constraints:
-+    - Maximum of 5 total questions across the whole session.
-+    - Each question must be answerable with EITHER:
-+       * A short multiple‑choice selection (2–5 distinct, mutually exclusive options), OR
-+       * A one-word / short‑phrase answer (explicitly constrain: "Answer in <=5 words").
-+   - Only include questions whose answers materially impact architecture, data modeling, task decomposition, test design, UX behavior, operational readiness, or compliance validation.
-+   - Ensure category coverage balance: attempt to cover the highest impact unresolved categories first; avoid asking two low-impact questions when a single high-impact area (e.g., security posture) is unresolved.
-+   - Exclude questions already answered, trivial stylistic preferences, or plan-level execution details (unless blocking correctness).
-+   - Favor clarifications that reduce downstream rework risk or prevent misaligned acceptance tests.
-+   - If more than 5 categories remain unresolved, select the top 5 by (Impact * Uncertainty) heuristic.
-+
-+4. Sequential questioning loop (interactive):
-+    - Present EXACTLY ONE question at a time.
-+    - For multiple‑choice questions render options as a Markdown table:
-+
-+       | Option | Description |
-+       |--------|-------------|
-+       | A | <Option A description> |
-+       | B | <Option B description> |
-+       | C | <Option C description> | (add D/E as needed up to 5)
-+       | Short | Provide a different short answer (<=5 words) | (Include only if free-form alternative is appropriate)
-+
-+    - For short‑answer style (no meaningful discrete options), output a single line after the question: `Format: Short answer (<=5 words)`.
-+    - After the user answers:
-+       * Validate the answer maps to one option or fits the <=5 word constraint.
-+       * If ambiguous, ask for a quick disambiguation (count still belongs to same question; do not advance).
-+       * Once satisfactory, record it in working memory (do not yet write to disk) and move to the next queued question.
-+    - Stop asking further questions when:
-+       * All critical ambiguities resolved early (remaining queued items become unnecessary), OR
-+       * User signals completion ("done", "good", "no more"), OR
-+       * You reach 5 asked questions.
-+    - Never reveal future queued questions in advance.
-+    - If no valid questions exist at start, immediately report no critical ambiguities.
-+
-+5. Integration after EACH accepted answer (incremental update approach):
-+    - Maintain in-memory representation of the spec (loaded once at start) plus the raw file contents.
-+    - For the first integrated answer in this session:
-+       * Ensure a `## Clarifications` section exists (create it just after the highest-level contextual/overview section per the spec template if missing).
-+       * Under it, create (if not present) a `### Session YYYY-MM-DD` subheading for today.
-+    - Append a bullet line immediately after acceptance: `- Q: <question> → A: <final answer>`.
-+    - Then immediately apply the clarification to the most appropriate section(s):
-+       * Functional ambiguity → Update or add a bullet in Functional Requirements.
-+       * User interaction / actor distinction → Update User Stories or Actors subsection (if present) with clarified role, constraint, or scenario.
-+       * Data shape / entities → Update Data Model (add fields, types, relationships) preserving ordering; note added constraints succinctly.
-+       * Non-functional constraint → Add/modify measurable criteria in Non-Functional / Quality Attributes section (convert vague adjective to metric or explicit target).
-+       * Edge case / negative flow → Add a new bullet under Edge Cases / Error Handling (or create such subsection if template provides placeholder for it).
-+       * Terminology conflict → Normalize term across spec; retain original only if necessary by adding `(formerly referred to as "X")` once.
-+    - If the clarification invalidates an earlier ambiguous statement, replace that statement instead of duplicating; leave no obsolete contradictory text.
-+    - Save the spec file AFTER each integration to minimize risk of context loss (atomic overwrite).
-+    - Preserve formatting: do not reorder unrelated sections; keep heading hierarchy intact.
-+    - Keep each inserted clarification minimal and testable (avoid narrative drift).
-+
-+6. Validation (performed after EACH write plus final pass):
-+   - Clarifications session contains exactly one bullet per accepted answer (no duplicates).
-+   - Total asked (accepted) questions ≤ 5.
-+   - Updated sections contain no lingering vague placeholders the new answer was meant to resolve.
-+   - No contradictory earlier statement remains (scan for now-invalid alternative choices removed).
-+   - Markdown structure valid; only allowed new headings: `## Clarifications`, `### Session YYYY-MM-DD`.
-+   - Terminology consistency: same canonical term used across all updated sections.
-+
-+7. Write the updated spec back to `FEATURE_SPEC`.
-+
-+8. Report completion (after questioning loop ends or early termination):
-+   - Number of questions asked & answered.
-+   - Path to updated spec.
-+   - Sections touched (list names).
-+   - Coverage summary table listing each taxonomy category with Status: Resolved (was Partial/Missing and addressed), Deferred (exceeds question quota or better suited for planning), Clear (already sufficient), Outstanding (still Partial/Missing but low impact).
-+   - If any Outstanding or Deferred remain, recommend whether to proceed to `/plan` or run `/clarify` again later post-plan.
-+   - Suggested next command.
-+
-+Behavior rules:
-+- If no meaningful ambiguities found (or all potential questions would be low-impact), respond: "No critical ambiguities detected worth formal clarification." and suggest proceeding.
-+- If spec file missing, instruct user to run `/specify` first (do not create a new spec here).
-+- Never exceed 5 total asked questions (clarification retries for a single question do not count as new questions).
-+- Avoid speculative tech stack questions unless the absence blocks functional clarity.
-+- Respect user early termination signals ("stop", "done", "proceed").
-+ - If no questions asked due to full coverage, output a compact coverage summary (all categories Clear) then suggest advancing.
-+ - If quota reached with unresolved high-impact categories remaining, explicitly flag them under Deferred with rationale.
-+
-+Context for prioritization: {ARGS}
-diff --git a/templates/commands/constitution.md b/templates/commands/constitution.md
-new file mode 100644
-index 0000000..605e936
---- /dev/null
-+++ b/templates/commands/constitution.md
-@@ -0,0 +1,73 @@
-+---
-+description: Create or update the project constitution from interactive or provided principle inputs, ensuring all dependent templates stay in sync.
-+---
-+
-+The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
-+
-+You are updating the project constitution at `/memory/constitution.md`. This file is a TEMPLATE containing placeholder tokens in square brackets (e.g. `[PROJECT_NAME]`, `[PRINCIPLE_1_NAME]`). Your job is to (a) collect/derive concrete values, (b) fill the template precisely, and (c) propagate any amendments across dependent artifacts.
-+
-+Follow this execution flow:
-+
-+1. Load the existing constitution template at `/memory/constitution.md`.
-+   - Identify every placeholder token of the form `[ALL_CAPS_IDENTIFIER]`.
-+   **IMPORTANT**: The user might require less or more principles than the ones used in the template. If a number is specified, respect that - follow the general template. You will update the doc accordingly.
-+
-+2. Collect/derive values for placeholders:
-+   - If user input (conversation) supplies a value, use it.
-+   - Otherwise infer from existing repo context (README, docs, prior constitution versions if embedded).
-+   - For governance dates: `RATIFICATION_DATE` is the original adoption date (if unknown ask or mark TODO), `LAST_AMENDED_DATE` is today if changes are made, otherwise keep previous.
-+   - `CONSTITUTION_VERSION` must increment according to semantic versioning rules:
-+     * MAJOR: Backward incompatible governance/principle removals or redefinitions.
-+     * MINOR: New principle/section added or materially expanded guidance.
-+     * PATCH: Clarifications, wording, typo fixes, non-semantic refinements.
-+   - If version bump type ambiguous, propose reasoning before finalizing.
-+
-+3. Draft the updated constitution content:
-+   - Replace every placeholder with concrete text (no bracketed tokens left except intentionally retained template slots that the project has chosen not to define yet—explicitly justify any left).
-+   - Preserve heading hierarchy and comments can be removed once replaced unless they still add clarifying guidance.
-+   - Ensure each Principle section: succinct name line, paragraph (or bullet list) capturing non‑negotiable rules, explicit rationale if not obvious.
-+   - Ensure Governance section lists amendment procedure, versioning policy, and compliance review expectations.
-+
-+4. Consistency propagation checklist (convert prior checklist into active validations):
-+   - Read `/templates/plan-template.md` and ensure any "Constitution Check" or rules align with updated principles.
-+   - Read `/templates/spec-template.md` for scope/requirements alignment—update if constitution adds/removes mandatory sections or constraints.
-+   - Read `/templates/tasks-template.md` and ensure task categorization reflects new or removed principle-driven task types (e.g., observability, versioning, testing discipline).
-+   - Read each command file in `/templates/commands/*.md` (including this one) to verify no outdated references (agent-specific names like CLAUDE only) remain when generic guidance is required.
-+   - Read any runtime guidance docs (e.g., `README.md`, `docs/quickstart.md`, or agent-specific guidance files if present). Update references to principles changed.
-+
-+5. Produce a Sync Impact Report (prepend as an HTML comment at top of the constitution file after update):
-+   - Version change: old → new
-+   - List of modified principles (old title → new title if renamed)
-+   - Added sections
-+   - Removed sections
-+   - Templates requiring updates (✅ updated / ⚠ pending) with file paths
-+   - Follow-up TODOs if any placeholders intentionally deferred.
-+
-+6. Validation before final output:
-+   - No remaining unexplained bracket tokens.
-+   - Version line matches report.
-+   - Dates ISO format YYYY-MM-DD.
-+   - Principles are declarative, testable, and free of vague language ("should" → replace with MUST/SHOULD rationale where appropriate).
-+
-+7. Write the completed constitution back to `/memory/constitution.md` (overwrite).
-+
-+8. Output a final summary to the user with:
-+   - New version and bump rationale.
-+   - Any files flagged for manual follow-up.
-+   - Suggested commit message (e.g., `docs: amend constitution to vX.Y.Z (principle additions + governance update)`).
-+
-+Formatting & Style Requirements:
-+- Use Markdown headings exactly as in the template (do not demote/promote levels).
-+- Wrap long rationale lines to keep readability (<100 chars ideally) but do not hard enforce with awkward breaks.
-+- Keep a single blank line between sections.
-+- Avoid trailing whitespace.
-+
-+If the user supplies partial updates (e.g., only one principle revision), still perform validation and version decision steps.
-+
-+If critical info missing (e.g., ratification date truly unknown), insert `TODO(<FIELD_NAME>): explanation` and include in the Sync Impact Report under deferred items.
-+
-+Do not create a new template; always operate on the existing `/memory/constitution.md` file.
-diff --git a/templates/commands/implement.md b/templates/commands/implement.md
-new file mode 100644
-index 0000000..ff2f1b6
---- /dev/null
-+++ b/templates/commands/implement.md
-@@ -0,0 +1,59 @@
-+---
-+description: Execute the implementation plan by processing and executing all tasks defined in tasks.md
-+scripts:
-+  sh: scripts/bash/check-prerequisites.sh --json --require-tasks --include-tasks
-+  ps: scripts/powershell/check-prerequisites.ps1 -Json -RequireTasks -IncludeTasks
-+---
-+
-+The user input can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
-+
-+1. Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute.
-+
-+2. Load and analyze the implementation context:
-+   - **REQUIRED**: Read tasks.md for the complete task list and execution plan
-+   - **REQUIRED**: Read plan.md for tech stack, architecture, and file structure
-+   - **IF EXISTS**: Read data-model.md for entities and relationships
-+   - **IF EXISTS**: Read contracts/ for API specifications and test requirements
-+   - **IF EXISTS**: Read research.md for technical decisions and constraints
-+   - **IF EXISTS**: Read quickstart.md for integration scenarios
-+
-+3. Parse tasks.md structure and extract:
-+   - **Task phases**: Setup, Tests, Core, Integration, Polish
-+   - **Task dependencies**: Sequential vs parallel execution rules
-+   - **Task details**: ID, description, file paths, parallel markers [P]
-+   - **Execution flow**: Order and dependency requirements
-+
-+4. Execute implementation following the task plan:
-+   - **Phase-by-phase execution**: Complete each phase before moving to the next
-+   - **Respect dependencies**: Run sequential tasks in order, parallel tasks [P] can run together  
-+   - **Follow TDD approach**: Execute test tasks before their corresponding implementation tasks
-+   - **File-based coordination**: Tasks affecting the same files must run sequentially
-+   - **Validation checkpoints**: Verify each phase completion before proceeding
-+
-+5. Implementation execution rules:
-+   - **Setup first**: Initialize project structure, dependencies, configuration
-+   - **Tests before code**: If you need to write tests for contracts, entities, and integration scenarios
-+   - **Core development**: Implement models, services, CLI commands, endpoints
-+   - **Integration work**: Database connections, middleware, logging, external services
-+   - **Polish and validation**: Unit tests, performance optimization, documentation
-+
-+6. Progress tracking and error handling:
-+   - Report progress after each completed task
-+   - Halt execution if any non-parallel task fails
-+   - For parallel tasks [P], continue with successful tasks, report failed ones
-+   - Provide clear error messages with context for debugging
-+   - Suggest next steps if implementation cannot proceed
-+   - **IMPORTANT** For completed tasks, make sure to mark the task off as [X] in the tasks file.
-+
-+7. Completion validation:
-+   - Verify all required tasks are completed
-+   - Check that implemented features match the original specification
-+   - Validate that tests pass and coverage meets requirements
-+   - Confirm the implementation follows the technical plan
-+   - Report final status with summary of completed work
-+
-+Note: This command assumes a complete task breakdown exists in tasks.md. If tasks are incomplete or missing, suggest running `/tasks` first to regenerate the task list.
-\ No newline at end of file
-diff --git a/templates/commands/plan.md b/templates/commands/plan.md
-index 18a0b5c..32522c2 100644
---- a/templates/commands/plan.md
-+++ b/templates/commands/plan.md
-@@ -5,9 +5,16 @@ scripts:
-   ps: scripts/powershell/setup-plan.ps1 -Json
- ---
- 
-+The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
-+
- Given the implementation details provided as an argument, do this:
- 
- 1. Run `{SCRIPT}` from the repo root and parse JSON for FEATURE_SPEC, IMPL_PLAN, SPECS_DIR, BRANCH. All future file paths must be absolute.
-+   - BEFORE proceeding, inspect FEATURE_SPEC for a `## Clarifications` section with at least one `Session` subheading. If missing or clearly ambiguous areas remain (vague adjectives, unresolved critical choices), PAUSE and instruct the user to run `/clarify` first to reduce rework. Only continue if: (a) Clarifications exist OR (b) an explicit user override is provided (e.g., "proceed without clarification"). Do not attempt to fabricate clarifications yourself.
- 2. Read and analyze the feature specification to understand:
-    - The feature requirements and user stories
-    - Functional and non-functional requirements
-diff --git a/templates/commands/specify.md b/templates/commands/specify.md
-index 41b8f6f..652c86a 100644
---- a/templates/commands/specify.md
-+++ b/templates/commands/specify.md
-@@ -5,9 +5,18 @@ scripts:
-   ps: scripts/powershell/create-new-feature.ps1 -Json "{ARGS}"
- ---
- 
--Given the feature description provided as an argument, do this:
-+The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
-+
-+The text the user typed after `/specify` in the triggering message **is** the feature description. Assume you always have it available in this conversation even if `{ARGS}` appears literally below. Do not ask the user to repeat it unless they provided an empty command.
-+
-+Given that feature description, do this:
- 
- 1. Run the script `{SCRIPT}` from repo root and parse its JSON output for BRANCH_NAME and SPEC_FILE. All file paths must be absolute.
-+  **IMPORTANT** You must only ever run this script once. The JSON is provided in the terminal as output - always refer to it to get the actual content you're looking for.
- 2. Load `templates/spec-template.md` to understand required sections.
- 3. Write the specification to SPEC_FILE using the template structure, replacing placeholders with concrete details derived from the feature description (arguments) while preserving section order and headings.
- 4. Report completion with branch name, spec file path, and readiness for the next phase.
-diff --git a/templates/commands/tasks.md b/templates/commands/tasks.md
-index 29b4cd2..eb0ef2b 100644
---- a/templates/commands/tasks.md
-+++ b/templates/commands/tasks.md
-@@ -1,11 +1,15 @@
- ---
- description: Generate an actionable, dependency-ordered tasks.md for the feature based on available design artifacts.
- scripts:
--  sh: scripts/bash/check-task-prerequisites.sh --json
--  ps: scripts/powershell/check-task-prerequisites.ps1 -Json
-+  sh: scripts/bash/check-prerequisites.sh --json
-+  ps: scripts/powershell/check-prerequisites.ps1 -Json
- ---
- 
--Given the context provided as an argument, do this:
-+The user input to you can be provided directly by the agent or as a command argument - you **MUST** consider it before proceeding with the prompt (if not empty).
-+
-+User input:
-+
-+$ARGUMENTS
- 
- 1. Run `{SCRIPT}` from repo root and parse FEATURE_DIR and AVAILABLE_DOCS list. All paths must be absolute.
- 2. Load and analyze available design documents:
-diff --git a/templates/plan-template.md b/templates/plan-template.md
-index 4f9e401..e812b41 100644
---- a/templates/plan-template.md
-+++ b/templates/plan-template.md
-@@ -24,7 +24,7 @@ scripts:
-    → Update Progress Tracking: Initial Constitution Check
- 5. Execute Phase 0 → research.md
-    → If NEEDS CLARIFICATION remain: ERROR "Resolve unknowns"
--6. Execute Phase 1 → contracts, data-model.md, quickstart.md, agent-specific template file (e.g., `CLAUDE.md` for Claude Code, `.github/copilot-instructions.md` for GitHub Copilot, or `GEMINI.md` for Gemini CLI).
-+6. Execute Phase 1 → contracts, data-model.md, quickstart.md, agent-specific template file (e.g., `CLAUDE.md` for Claude Code, `.github/copilot-instructions.md` for GitHub Copilot, `GEMINI.md` for Gemini CLI, `QWEN.md` for Qwen Code or `AGENTS.md` for opencode).
- 7. Re-evaluate Constitution Check section
-    → If new violations: Refactor design, return to Phase 1
-    → Update Progress Tracking: Post-Design Constitution Check
-@@ -151,7 +151,8 @@ ios/ or android/
-    - Quickstart test = story validation steps
- 
- 5. **Update agent file incrementally** (O(1) operation):
--   - Run `{SCRIPT}` for your AI assistant
-+   - Run `{SCRIPT}`
-+     **IMPORTANT**: Execute it exactly as specified above. Do not add or remove any arguments.
-    - If exists: Add only NEW tech from current plan
-    - Preserve manual additions between markers
-    - Update recent changes (keep last 3)
-@@ -214,4 +215,4 @@ ios/ or android/
- - [ ] Complexity deviations documented
- 
- ---
--*Based on Constitution v2.1.1 - See `/memory/constitution.md`*
-\ No newline at end of file
-+*Based on Constitution v2.1.1 - See `/memory/constitution.md`*
diff --git a/update-notes/v0.0.4+b18ef20-v0.0.17+f3d55cf-update-notes.md b/update-notes/v0.0.4+b18ef20-v0.0.17+f3d55cf-update-notes.md
deleted file mode 100644
index 91d7535..0000000
--- a/update-notes/v0.0.4+b18ef20-v0.0.17+f3d55cf-update-notes.md
+++ /dev/null
@@ -1,225 +0,0 @@
-# Spec Kit 更新说明 v0.0.4 → v0.0.17
-
-## 版本信息
-- **当前版本**: v0.0.4 (commit: b18ef20)
-- **更新版本**: v0.0.17 (commit: f3d55cf)
-- **更新日期**: 2025-09-25
-
-## 更新概览
-
-本次更新是 Spec Kit 的一次重大版本升级，主要包含以下核心改进：
-
-### 🚀 核心功能增强
-- **AI代理支持扩展**: 新增7个AI代理支持，优化4个现有代理，涵盖阿里巴巴Qwen Code、开源opencode、Windsurf IDE、OpenAI Codex CLI、Kilo Code质量分析、Auggie CLI重构工具、Roo Code移动开发等专业工具，以及Anthropic Claude Code、Google Gemini CLI、GitHub Copilot、Cursor IDE等主流AI编程助手
-- **命令系统扩展**: 新增analyze跨工件一致性分析、clarify需求澄清、constitution项目宪法管理、implement任务执行四个核心命令，优化specify规范生成、plan项目规划、tasks任务分解三个现有命令
-- **脚本系统优化**: 统一脚本架构，支持Bash和PowerShell双平台
-- **CI/CD流程完善**: 重构GitHub Actions工作流，提升发布自动化
-
-### 📦 技术架构优化
-- **模块化脚本设计**: 将复杂工作流拆分为独立可复用的脚本组件
-- **跨平台兼容性**: 同时支持POSIX shell和PowerShell环境
-- **版本管理优化**: 改进版本号生成和发布检查机制
-
-### 🔧 问题修复
-- **依赖管理优化**: 更新项目依赖和Python版本要求
-- **文档结构完善**: 新增AGENTS.md等关键文档
-- **脚本错误处理**: 改进脚本的错误处理和输出格式
-
-## 主要更新内容
-
-### 🚀 核心功能增强
-
-#### 1. AI代理支持扩展
-
-**新增代理支持**:
-- **Qwen Code**: 阿里巴巴开发的大模型代码助手，基于通义千问技术，擅长中文代码理解和生成，使用TOML格式命令文件，适用于中文开发环境和企业级项目
-- **opencode**: 开源代码生成工具，提供轻量级代码补全和重构功能，使用Markdown格式命令文件，适合快速原型开发和小型项目
-- **Windsurf**: Windsurf IDE集成的AI工作流系统，提供可视化编程体验，使用Markdown格式命令文件，适合需要图形化界面的开发团队
-- **Codex CLI**: 基于OpenAI Codex技术的命令行工具，擅长代码生成和自然语言转代码，使用Markdown格式命令文件，适合快速代码原型和自动化脚本开发
-- **Kilo Code**: 专注于代码质量分析的AI工具，提供代码审查和优化建议，使用Markdown格式命令文件，适合大型项目的代码质量管控
-- **Auggie CLI**: 智能代码重构和优化工具，提供自动化代码改进功能，使用Markdown格式命令文件，适合代码维护和性能优化项目
-- **Roo Code**: 面向移动开发的AI代码助手，专门优化移动应用开发流程，使用Markdown格式命令文件，适合iOS和Android应用开发
-
-**优化现有代理**:
-- **Claude Code**: Anthropic开发的先进AI代码助手，基于Claude-3模型，擅长复杂逻辑推理和代码架构设计，优化了工具检测机制和安装指导流程，适合大型企业级项目开发
-- **Gemini CLI**: Google开发的多模态AI编程工具，集成Gemini Pro模型，支持代码生成和自然语言交互，改进了命令文件格式和参数传递机制，适合跨平台开发项目
-- **GitHub Copilot**: GitHub与OpenAI合作开发的AI编程助手，深度集成VS Code，提供智能代码补全和上下文感知，优化了提示文件管理和IDE集成，适合GitHub生态的协作开发
-- **Cursor**: Cursor IDE的AI编程助手，基于GPT-4技术，提供智能代码编辑和重构功能，改进了命令执行机制和响应速度，适合需要高效代码编辑的开发环境
-
-**多代理统一管理**: 通过AGENTS.md文档统一管理所有支持的AI代理
-
-**技术实现**:
-- 每个代理都有独立的目录结构（如`.qwen/commands/`、`.opencode/command/`、`.windsurf/workflows/`）
-- 支持不同格式的命令文件（Markdown、TOML）
-- 统一的命令参数传递机制（`$ARGUMENTS`、`{{args}}`等）
-
-#### 2. 命令系统扩展
-
-**新增核心命令**:
-- **analyze命令**: 执行跨工件一致性分析，检查spec.md、plan.md、tasks.md之间的不一致性，支持JSON输出格式，使用check-prerequisites.sh脚本进行前置条件验证，适用于项目质量管控和规范检查场景
-- **clarify命令**: 识别规范中的模糊区域，通过5个针对性问题澄清需求，支持路径验证和JSON输出，使用check-prerequisites.sh脚本进行路径检查，适用于需求不明确或需要进一步澄清的开发场景
-- **constitution命令**: 管理项目宪法和开发规范，支持交互式或命令行输入，确保所有依赖模板保持同步，适用于团队规范制定和项目治理场景
-- **implement命令**: 执行具体的实现任务，基于tasks.md中的任务定义进行处理和执行，支持前置条件检查，适用于自动化实现和任务执行场景
-
-**优化现有命令**:
-- **specify命令**: 改进用户输入处理机制，增强$ARGUMENTS参数传递，支持直接命令行输入和交互式输入，优化脚本执行逻辑，确保只执行一次脚本调用，适用于快速规范生成和需求文档化场景
-- **plan命令**: 新增澄清检查逻辑，在执行前检查FEATURE_SPEC中的Clarifications部分，避免模糊需求导致的返工，支持用户覆盖机制，使用setup-plan.sh脚本进行计划生成，适用于复杂项目的规划阶段
-- **tasks命令**: 统一脚本调用机制，从check-task-prerequisites.sh迁移到check-prerequisites.sh，支持JSON输出格式，改进前置条件检查逻辑，适用于任务分解和依赖管理场景
-
-#### 3. 脚本系统优化
-
-**统一脚本架构**:
-- **check-prerequisites.sh/ps1**: 统一的前置条件检查脚本，支持JSON输出
-- **模块化设计**: 将复杂工作流拆分为独立脚本组件
-- **跨平台支持**: 同时提供Bash和PowerShell版本
-
-**新增脚本功能**:
-- **JSON输出支持**: 脚本支持结构化输出，便于其他工具集成
-- **路径验证**: 增强文件路径和目录结构验证
-- **错误处理**: 改进错误报告和异常处理机制
-
-### 🔧 技术改进
-
-#### 1. CI/CD流程重构
-
-**GitHub Actions优化**:
-- **模块化脚本**: 将复杂的发布流程拆分为独立脚本（get-next-version.sh、check-release-exists.sh等）
-- **版本管理**: 改进版本号生成逻辑，支持自动版本递增
-- **发布检查**: 新增发布存在性检查，避免重复发布
-- **多平台支持**: 支持多种AI代理的模板包生成
-
-**新增脚本组件**:
-- **get-next-version.sh**: 自动计算下一个版本号
-- **check-release-exists.sh**: 检查发布是否已存在
-- **create-github-release.sh**: 创建GitHub发布
-- **generate-release-notes.sh**: 生成发布说明
-- **update-version.sh**: 更新版本信息
-
-#### 2. 项目结构优化
-
-**新增文档**:
-- **AGENTS.md**: 详细的AI代理支持文档，包含集成指南
-- **统一管理**: 集中管理所有支持的AI代理信息
-
-**文件组织**:
-- **脚本分类**: 按功能将脚本分类到不同目录
-- **模板扩展**: 新增多个命令模板文件
-- **配置优化**: 改进项目配置文件
-
-#### 3. 依赖和配置更新
-
-**Python版本要求**:
-- **最低版本**: 从Python 3.11开始支持
-- **依赖更新**: 更新所有项目依赖包
-
-**项目元数据**:
-- **版本号**: 从0.0.4升级到0.0.17
-- **描述更新**: 更准确的项目描述
-- **依赖管理**: 优化依赖包管理
-
-### 📁 文件变更详情
-
-#### 新增文件
-- `.github/workflows/scripts/check-release-exists.sh` - 发布存在性检查脚本
-- `.github/workflows/scripts/create-github-release.sh` - GitHub发布创建脚本
-- `.github/workflows/scripts/generate-release-notes.sh` - 发布说明生成脚本
-- `.github/workflows/scripts/get-next-version.sh` - 版本号生成脚本
-- `.github/workflows/scripts/update-version.sh` - 版本更新脚本
-- `AGENTS.md` - AI代理支持文档
-- `scripts/bash/check-prerequisites.sh` - Bash前置条件检查脚本
-- `scripts/powershell/check-prerequisites.ps1` - PowerShell前置条件检查脚本
-- `templates/commands/analyze.md` - 分析命令模板
-- `templates/commands/clarify.md` - 澄清命令模板
-- `templates/commands/constitution.md` - 宪法命令模板
-- `templates/commands/implement.md` - 实现命令模板
-
-#### 删除文件
-- `memory/constitution_update_checklist.md` - 宪法更新检查清单（功能整合到新的命令系统中）
-- `scripts/bash/check-task-prerequisites.sh` - 任务前置条件检查脚本（功能整合到统一的check-prerequisites.sh中）
-- `scripts/bash/get-feature-paths.sh` - 功能路径获取脚本（功能整合到新的脚本架构中）
-- `scripts/powershell/check-task-prerequisites.ps1` - PowerShell任务前置条件检查脚本（功能整合到统一的check-prerequisites.ps1中）
-- `scripts/powershell/get-feature-paths.ps1` - PowerShell功能路径获取脚本（功能整合到新的脚本架构中）
-
-#### 修改文件
-- `.github/workflows/release.yml`: 重构发布工作流，使用模块化脚本
-- `README.md`: 新增AI代理支持说明，改进安装指南
-- `pyproject.toml`: 更新版本号和项目描述
-- `scripts/bash/*.sh`: 优化现有脚本，改进错误处理
-- `scripts/powershell/*.ps1`: 优化现有脚本，改进错误处理
-- `templates/commands/*.md`: 更新现有命令模板
-- `src/specify_cli/__init__.py`: 更新CLI版本信息
-
-### 🎯 用户体验改进
-
-#### 1. 安装和使用体验
-- **多选项安装**: 提供持久化安装和临时安装两种方式
-- **AI代理选择**: 支持用户选择偏好的AI代理
-- **跨平台支持**: 同时支持Unix/Linux和Windows环境
-
-#### 2. 开发工作流优化
-- **命令系统**: 新增analyze、clarify等命令，提升开发效率
-- **脚本统一**: 统一脚本接口，降低学习成本
-- **错误处理**: 改进错误提示和异常处理
-
-#### 3. 文档和指导
-- **详细文档**: 新增AGENTS.md等关键文档
-- **集成指南**: 提供详细的AI代理集成指南
-- **最佳实践**: 包含开发最佳实践和规范
-
-### 🔒 安全性和稳定性
-
-#### 1. 脚本安全性
-- **权限检查**: 改进脚本执行权限检查
-- **路径验证**: 增强文件路径安全性验证
-- **错误处理**: 改进异常情况处理
-
-#### 2. 发布安全性
-- **版本检查**: 防止重复发布和版本冲突
-- **依赖验证**: 改进依赖包安全性检查
-- **发布验证**: 增强发布内容验证
-
-## 破坏性变更
-
-### 脚本接口变更
-- **脚本参数**: 部分脚本的参数格式有所调整
-- **输出格式**: 新增JSON输出格式支持，可能影响现有集成
-
-### 目录结构变更
-- **新增目录**: 新增多个AI代理支持目录
-- **脚本位置**: 部分脚本位置可能发生变化
-
-## 兼容性说明
-
-### 向后兼容
-- **核心功能**: 所有核心功能保持向后兼容
-- **现有项目**: 现有项目可以正常升级
-- **脚本接口**: 大部分脚本接口保持兼容
-
-### 升级建议
-1. **备份现有项目**: 升级前备份重要的项目文件
-2. **检查依赖**: 确保Python版本满足要求（>=3.11）
-3. **更新脚本**: 如有自定义脚本，需要检查与新版本的兼容性
-4. **测试新功能**: 建议在测试环境中先试用新的AI代理支持
-5. **阅读文档**: 仔细阅读AGENTS.md等新增文档
-
-## 总结
-
-**核心记忆点**：
-- 🚀 **多AI代理支持**：新增阿里巴巴Qwen Code、开源opencode、Windsurf IDE、OpenAI Codex CLI、Kilo Code质量分析、Auggie CLI重构、Roo Code移动开发七个专业AI代理，优化Anthropic Claude Code、Google Gemini CLI、GitHub Copilot、Cursor IDE四个主流编程助手
-- ⚡ **命令系统扩展**：新增analyze跨工件一致性分析、clarify需求澄清、constitution项目宪法管理、implement任务执行四个核心命令，优化specify规范生成、plan项目规划、tasks任务分解三个现有命令
-- 🔧 **脚本系统重构**：统一脚本架构，支持Bash和PowerShell双平台
-
-**关键改进**：AI代理扩展、命令系统扩展、脚本模块化、CI/CD优化、跨平台支持
-
-**升级建议**：建议所有用户升级到新版本，特别是需要使用多种AI代理的团队
-
----
-
-**更新统计**:
-- 新增文件: 12个
-- 删除文件: 5个  
-- 修改文件: 21个
-- 版本号: v0.0.4 → v0.0.17
-- 主要改进: AI代理支持、命令系统、脚本优化、CI/CD重构
-
-*本次更新是Spec Kit历史上最重要的版本之一，大幅扩展了AI代理支持范围，重构了核心命令系统，为Spec-Driven Development提供了更强大和灵活的工具链。*
